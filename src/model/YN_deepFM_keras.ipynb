{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/busesese/DeepFM_Keras/blob/master/DeepFM/deepfm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.layers import Input, Dense, Embedding, Add, Concatenate, RepeatVector,Multiply,Subtract,Lambda,Dropout,Reshape,Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from mylayers import MySumLayer\n",
    "from keras.optimizers import Adam\n",
    "# import config\n",
    "from keras.metrics import binary_accuracy\n",
    "# from metrics import auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from keras.optimizers import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>place.name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>is_fch</th>\n",
       "      <th>photonum</th>\n",
       "      <th>is_local</th>\n",
       "      <th>rated_count</th>\n",
       "      <th>average_photonum</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>user_reviewcount</th>\n",
       "      <th>userID</th>\n",
       "      <th>category_l</th>\n",
       "      <th>land.addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20180314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>11</td>\n",
       "      <td>14256</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20171207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>722</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20161110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>30372</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20160611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2116</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20151204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.095238</td>\n",
       "      <td>42</td>\n",
       "      <td>3208</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationId place.name category  rating  createdDate  is_fch  photonum  \\\n",
       "0      788542     마르코 폴로      EAT     5.0     20180314       0         0   \n",
       "1      788542     마르코 폴로      EAT     4.0     20171207       0         0   \n",
       "2      788542     마르코 폴로      EAT     5.0     20161110       0         0   \n",
       "3      788542     마르코 폴로      EAT     3.0     20160611       0         0   \n",
       "4      788542     마르코 폴로      EAT     4.0     20151204       0         0   \n",
       "\n",
       "   is_local  rated_count  average_photonum  average_rating  user_mean_rating  \\\n",
       "0         1           20              0.05            3.95          4.363636   \n",
       "1         1           20              0.05            3.95          4.000000   \n",
       "2         0           20              0.05            3.95          5.000000   \n",
       "3         0           20              0.05            3.95          4.250000   \n",
       "4         1           20              0.05            3.95          4.095238   \n",
       "\n",
       "   user_reviewcount  userID  category_l                    land.addr  \n",
       "0                11   14256           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "1                 6     722           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "2                 1   30372           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "3                 4    2116           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "4                42    3208           1  서울 강남구 삼성동 159-1 트레이드타워 52층  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "import gc\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"..\",\"..\",\"data\",\"YN_final_df.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬 / 글로벌 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_df shape: (459903, 16) global_df shape : (93722, 16)\n"
     ]
    }
   ],
   "source": [
    "# 로컬 / 글로벌 데이터 분리\n",
    "local_df = df.loc[df['is_local']==1]\n",
    "global_df = df.loc[df['is_local']==0]\n",
    "print('local_df shape:',local_df.shape, 'global_df shape :',global_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553625, 16)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "체인을 빼도ㅍ성능 나빠.... \n",
    "차라리 장소의 다양성을 위해 + 글로벌 데이터 추천 결과가 좋으므로\n",
    "글로벌 데이터 추가해서 전체 중에서\n",
    "체인 및 손수 전처리 체인 제거\n",
    "'''\n",
    "\n",
    "local_df = df.copy()\n",
    "local_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57122, 16) (496503, 16)\n",
      "(237052, 16)\n",
      "1527\n",
      "41784\n",
      "42382\n",
      "237052\n",
      "194670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>place.name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>is_fch</th>\n",
       "      <th>photonum</th>\n",
       "      <th>is_local</th>\n",
       "      <th>rated_count</th>\n",
       "      <th>average_photonum</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>user_reviewcount</th>\n",
       "      <th>userID</th>\n",
       "      <th>category_l</th>\n",
       "      <th>land.addr</th>\n",
       "      <th>lw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81114</th>\n",
       "      <td>1011796922</td>\n",
       "      <td>호텔더디자이너스동대문</td>\n",
       "      <td>ACM</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20191216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.417995</td>\n",
       "      <td>105</td>\n",
       "      <td>42122</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 중구 쌍림동 266-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81115</th>\n",
       "      <td>37903636</td>\n",
       "      <td>아만티호텔서울</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>20190722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.417995</td>\n",
       "      <td>105</td>\n",
       "      <td>42122</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 월드컵북로 31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81155</th>\n",
       "      <td>13217405</td>\n",
       "      <td>코트야드 메리어트 서울 타임스퀘어</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>20190621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>4.414649</td>\n",
       "      <td>40</td>\n",
       "      <td>101654</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 영등포구 영중로 15 타임스퀘어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81659</th>\n",
       "      <td>20315170</td>\n",
       "      <td>스탠포드호텔코리아</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>20191227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>4.395100</td>\n",
       "      <td>33</td>\n",
       "      <td>24205</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 상암동 1587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81660</th>\n",
       "      <td>20315170</td>\n",
       "      <td>스탠포드호텔코리아</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>20191209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>4.395100</td>\n",
       "      <td>33</td>\n",
       "      <td>24205</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 상암동 1587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       locationId          place.name category    rating  createdDate  is_fch  \\\n",
       "81114  1011796922         호텔더디자이너스동대문      ACM  5.000000     20191216       0   \n",
       "81115    37903636             아만티호텔서울      ACM  4.666667     20190722       0   \n",
       "81155    13217405  코트야드 메리어트 서울 타임스퀘어      ACM  4.270833     20190621       0   \n",
       "81659    20315170           스탠포드호텔코리아      ACM  4.184211     20191227       0   \n",
       "81660    20315170           스탠포드호텔코리아      ACM  4.184211     20191209       0   \n",
       "\n",
       "       photonum  is_local  rated_count  average_photonum  average_rating  \\\n",
       "81114         0         1            1               0.0        5.000000   \n",
       "81115         0         1            3               0.0        4.666667   \n",
       "81155         0         1           24               0.0        4.270833   \n",
       "81659         0         1           19               0.0        4.184211   \n",
       "81660         0         1           19               0.0        4.184211   \n",
       "\n",
       "       user_mean_rating  user_reviewcount  userID  category_l  \\\n",
       "81114          4.417995               105   42122           1   \n",
       "81115          4.417995               105   42122           1   \n",
       "81155          4.414649                40  101654           1   \n",
       "81659          4.395100                33   24205           1   \n",
       "81660          4.395100                33   24205           1   \n",
       "\n",
       "                     land.addr  lw  \n",
       "81114       서울특별시 중구 쌍림동 266-2   0  \n",
       "81115       서울특별시 마포구 월드컵북로 31   0  \n",
       "81155  서울특별시 영등포구 영중로 15 타임스퀘어   0  \n",
       "81659       서울특별시 마포구 상암동 1587   0  \n",
       "81660       서울특별시 마포구 상암동 1587   0  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_df_acm = local_df.loc[local_df['category'] == 'ACM']\n",
    "local_df_eat = local_df.loc[local_df['category'] == 'EAT']\n",
    "print(local_df_acm.shape, local_df_eat.shape)\n",
    "\n",
    "local_df_eat = local_df_eat.loc[local_df_eat['average_rating']>=local_df_eat['average_rating'].median()]\n",
    "local_df = pd.concat([local_df_acm, local_df_eat])\n",
    "\n",
    "# local이기에 global과 차이를 두기위해 최대한 의미없는 체인 제거 \n",
    "local_df = local_df.loc[local_df['is_fch']==0]\n",
    "print(local_df.shape)\n",
    "\n",
    "fch_lst = ['써브웨이', '던킨도너츠','노브랜드버거','바르다김선생',' 폴바셋',' 안동찜닭',' 속초코다리냉면',' 할매순대국&양선지해장국',' 노브랜드버거 남부터미널점','바르다김선생' ,'유가네','24시 중식당 취빈','매머드커피','압구정봉구비어','카페베네','쥬씨','피자스쿨','매머드익스프레스','김밥천국','한국맥도날드','메머드커피','신전떡볶이','어사또', '공차', '북촌손만두', '오징어세상' ,'사월에보리밥', '땡스브레드엔커피', '피자몰', '나주소나주곰탕', '새마을식당','싸다김밥', '교동짬뽕', '토마토김밥', '화화쿵주마라탕', '샐러데이즈', '더차이','뚜레쥬르','스쿨푸드','자연별곡','죠스떡볶이','국대떡볶이', '도쿄스테이크','이디야커피', '코스트코코리아양재점푸드코트', '불고기브라더스','알라딘중고서점카페','배스킨라빈스','할리스커피', '와플대학', '파리바게뜨공덕역사', '파리바게뜨','아웃백','설빙', '봉추찜닭', '하겐다즈','아라마크연세의료원종합관'\n",
    "]\n",
    "fch_idx = local_df[local_df['place.name'].apply(lambda x: any(i in x for i in fch_lst))].index.tolist()\n",
    "idx = local_df[local_df['place.name'].apply(lambda x: x[-1] == '점')].index.tolist()\n",
    "print(len(fch_idx))\n",
    "print(len(idx))\n",
    "\n",
    "for i in idx:\n",
    "    if i not in fch_idx:\n",
    "        fch_idx.append(i)\n",
    "        \n",
    "print(len(fch_idx))\n",
    "\n",
    "print(local_df.shape[0])\n",
    "local_df = local_df.drop(fch_idx)\n",
    "print(local_df.shape[0])\n",
    "\n",
    "local_df['lw'] = local_df['is_local'].apply(lambda x: 1 if x==0 else 0)\n",
    "local_df['lw'] = local_df['lw']*5\n",
    "local_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_df.to_csv(os.path.join(\"..\",\"realtime_model\",'local_df.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['locationId', 'place.name', 'category', 'rating', 'createdDate',\n",
       "       'is_fch', 'photonum', 'is_local', 'rated_count', 'average_photonum',\n",
       "       'average_rating', 'user_mean_rating', 'user_reviewcount', 'userID',\n",
       "       'category_l', 'land.addr', 'lw'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSTATE = 2018\n",
    "\n",
    "NUMERIC_COLS=[\n",
    "    'locationId',  'createdDate',\n",
    "    'photonum', 'rated_count', 'average_photonum',\n",
    "    'average_rating', 'user_mean_rating', 'user_reviewcount',\n",
    "    'userID'] #,'lw'\n",
    "\n",
    "\n",
    "IGNORE_COLS = [\"place.name\", \"land.addr\", 'rating','is_fch', 'category_l','lw']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(column, df) :\n",
    "    \n",
    "    vocab = {}\n",
    "    num = 0\n",
    "\n",
    "    for i in df[column]: # np.hstack([train[column], test[column]]): \n",
    "        if vocab.get(i) != None:\n",
    "            continue\n",
    "\n",
    "        vocab[i] = num\n",
    "        num += 1\n",
    "\n",
    "    encoded = [vocab[i] for i in df[column]]\n",
    "    # encoded_d = [vocab[i] for i in test[column]]\n",
    "    \n",
    "    return encoded, num, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continous\n",
    "encoded_locationId, num_locationId, vocab_locationId = get_data('locationId', local_df) \n",
    "encoded_createdDate,  num_createdDate, vocab_createdDate = get_data('createdDate', local_df) \n",
    "encoded_photonum,  num_photonum, vocab_photonum = get_data('photonum', local_df) \n",
    "encoded_rated_count,  num_rated_count, vocab_rated_count = get_data('rated_count', local_df) \n",
    "encoded_average_photonum,  num_average_photonum, vocab_average_photonum = get_data('average_photonum', local_df) \n",
    "encoded_average_rating,  num_average_rating, vocab_average_rating = get_data('average_rating', local_df) \n",
    "encoded_users_mean_rating, num_users_mean_rating, vocab_users_mean_rating = get_data('user_mean_rating', local_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', local_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', local_df) \n",
    "encoded_userID, num_userID, vocab_userID = get_data('userID', local_df) \n",
    "# encoded_lw,  num_lw, vocab_lw = get_data('lw', local_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locationId': 5601,\n",
       " 'createdDate': 4238,\n",
       " 'photonum': 39,\n",
       " 'rated_count': 226,\n",
       " 'average_photonum': 1084,\n",
       " 'average_rating': 1646,\n",
       " 'user_mean_rating': 30961,\n",
       " 'user_reviewcount': 176,\n",
       " 'userID': 85413}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_nu_dict = {}\n",
    "feat_nu_dict['locationId'] = num_locationId\n",
    "feat_nu_dict['createdDate'] = num_createdDate\n",
    "feat_nu_dict['photonum'] = num_photonum\n",
    "feat_nu_dict['rated_count'] = num_rated_count\n",
    "feat_nu_dict['average_photonum'] = num_average_photonum\n",
    "feat_nu_dict['average_rating'] = num_average_rating\n",
    "feat_nu_dict['user_mean_rating'] = num_users_mean_rating\n",
    "feat_nu_dict['user_reviewcount'] = num_user_reviewcount\n",
    "feat_nu_dict['userID'] = num_userID\n",
    "# feat_nu_dict['lw'] = num_lw\n",
    "feat_nu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8 #the number of embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = []\n",
    "numeric_cols = []\n",
    "embed_col = []\n",
    "for col in NUMERIC_COLS:\n",
    "    in_neu = Input(shape=(1,), name=col)\t\t\t#None*1\n",
    "    input_cols.append(in_neu)\n",
    "#     cate_embedding = Embedding(feat_nu_dict[col], 1)(in_neu)\t#None*1*1\n",
    "#     in_embed = Embedding(feat_nu_dict[col], k, name = 'FM_'+col)(in_neu)\t\t#None*1*k\n",
    "    in_embed = RepeatVector(1, name='FM_'+col)(Dense(k)(in_neu))\t#None*1*k\n",
    "    numeric_cols.append(in_neu)\n",
    "    embed_col.append(in_embed)\n",
    "con_numeric = Concatenate(axis=1)(numeric_cols)\t\t#None*len(config.NUMERIC_COLS)\n",
    "dense_numeric = RepeatVector(1)(Dense(1)(con_numeric))\t#None*1*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first order\n",
    "y_first_order = dense_numeric #Concatenate(axis=1)([dense_numeric, con_cate]) \t\t#None*len*1\n",
    "y_first_order = MySumLayer(axis=1)(y_first_order)\t\t\t\t#None*1\t\n",
    "\n",
    "#second order\n",
    "emb = Concatenate(axis=1)(embed_col)\t\t\t\t\t\t#None*s*k\n",
    "\n",
    "summed_feature_emb = MySumLayer(axis=1)(emb)\t\t\t\t#None*k\n",
    "summed_feature_emb_squred = Multiply()([summed_feature_emb,summed_feature_emb])\t#None*k\n",
    "\n",
    "squared_feature_emb = Multiply()([emb,emb])\t\t\t\t\t#None*s*k\n",
    "squared_sum_feature_emb = MySumLayer(axis=1)(squared_feature_emb)\t#None*k\n",
    "\n",
    "sub = Subtract()([summed_feature_emb_squred,squared_sum_feature_emb])\t#None*k\n",
    "sub = Lambda(lambda x: x*0.5)(sub)\t\t\t\t\t\t#None*k\n",
    "y_second_order = MySumLayer(axis=1)(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep order\n",
    "y_deep = Flatten()(emb)\t\t\t\t\t\t\t\t#None*(s*k)\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(1,activation='relu')(y_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep fm\n",
    "y = Concatenate()([y_first_order,y_second_order,y_deep])\t\t\t#None*3\n",
    "y = Dense(1)(y)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "\n",
    "lr = 1e-1\n",
    "epochs = 300\n",
    "batch_size = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(model_to_dot(model,show_shapes=True, show_layer_names=False).create(prog='dot', format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_save_path = os.path.join(\"..\",\"..\",\"data\",\"model_weights\")\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "    \n",
    "model_path = model_save_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 193696 samples, validate on 974 samples\n",
      "Epoch 1/300\n",
      "193696/193696 [==============================] - 2s 8us/step - loss: 52801374143008144.0000 - auc_25: 0.0000e+00 - val_loss: 15809734656.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 15809734656.00000, saving model to ../../data/model_weights01-15809734656.0000.hdf5\n",
      "Epoch 2/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 20379183676.1408 - auc_25: 0.0000e+00 - val_loss: 14686689280.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 15809734656.00000 to 14686689280.00000, saving model to ../../data/model_weights02-14686689280.0000.hdf5\n",
      "Epoch 3/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 19304158336.4018 - auc_25: 0.0000e+00 - val_loss: 13326541824.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 14686689280.00000 to 13326541824.00000, saving model to ../../data/model_weights03-13326541824.0000.hdf5\n",
      "Epoch 4/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 16754567058.8839 - auc_25: 0.0000e+00 - val_loss: 11797185536.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 13326541824.00000 to 11797185536.00000, saving model to ../../data/model_weights04-11797185536.0000.hdf5\n",
      "Epoch 5/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 14658043328.8141 - auc_25: 0.0000e+00 - val_loss: 10053288960.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 11797185536.00000 to 10053288960.00000, saving model to ../../data/model_weights05-10053288960.0000.hdf5\n",
      "Epoch 6/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 12015129891.9914 - auc_25: 0.0000e+00 - val_loss: 8293452288.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 10053288960.00000 to 8293452288.00000, saving model to ../../data/model_weights06-8293452288.0000.hdf5\n",
      "Epoch 7/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 10327803418.3063 - auc_25: 0.0000e+00 - val_loss: 6467345920.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 8293452288.00000 to 6467345920.00000, saving model to ../../data/model_weights07-6467345920.0000.hdf5\n",
      "Epoch 8/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 7508660156.5848 - auc_25: 0.0000e+00 - val_loss: 4502835712.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 6467345920.00000 to 4502835712.00000, saving model to ../../data/model_weights08-4502835712.0000.hdf5\n",
      "Epoch 9/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 4915487376.0502 - auc_25: 0.0000e+00 - val_loss: 2547481088.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 4502835712.00000 to 2547481088.00000, saving model to ../../data/model_weights09-2547481088.0000.hdf5\n",
      "Epoch 10/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 3039647657.1300 - auc_25: 0.0000e+00 - val_loss: 1563743744.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 2547481088.00000 to 1563743744.00000, saving model to ../../data/model_weights10-1563743744.0000.hdf5\n",
      "Epoch 11/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1428879685.6567 - auc_25: 0.0000e+00 - val_loss: 755643072.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss improved from 1563743744.00000 to 755643072.00000, saving model to ../../data/model_weights11-755643072.0000.hdf5\n",
      "Epoch 12/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 622175090.5878 - auc_25: 0.0000e+00 - val_loss: 314240608.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss improved from 755643072.00000 to 314240608.00000, saving model to ../../data/model_weights12-314240608.0000.hdf5\n",
      "Epoch 13/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 235045917.6025 - auc_25: 0.0000e+00 - val_loss: 102107336.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss improved from 314240608.00000 to 102107336.00000, saving model to ../../data/model_weights13-102107336.0000.hdf5\n",
      "Epoch 14/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 69788957.4935 - auc_25: 0.0000e+00 - val_loss: 24712690.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss improved from 102107336.00000 to 24712690.00000, saving model to ../../data/model_weights14-24712690.0000.hdf5\n",
      "Epoch 15/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 15673584.9973 - auc_25: 0.0000e+00 - val_loss: 4450463.5000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 24712690.00000 to 4450463.50000, saving model to ../../data/model_weights15-4450463.5000.hdf5\n",
      "Epoch 16/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2887854.9831 - auc_25: 0.0000e+00 - val_loss: 790822.2500 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 4450463.50000 to 790822.25000, saving model to ../../data/model_weights16-790822.2500.hdf5\n",
      "Epoch 17/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 532601.9974 - auc_25: 0.0000e+00 - val_loss: 274226.6562 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss improved from 790822.25000 to 274226.65625, saving model to ../../data/model_weights17-274226.6562.hdf5\n",
      "Epoch 18/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 125215.4219 - auc_25: 0.0000e+00 - val_loss: 198527.2656 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss improved from 274226.65625 to 198527.26562, saving model to ../../data/model_weights18-198527.2656.hdf5\n",
      "Epoch 19/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 60391.5298 - auc_25: 0.0000e+00 - val_loss: 184949.7969 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss improved from 198527.26562 to 184949.79688, saving model to ../../data/model_weights19-184949.7969.hdf5\n",
      "Epoch 20/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 53313.7353 - auc_25: 0.0000e+00 - val_loss: 181339.7812 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss improved from 184949.79688 to 181339.78125, saving model to ../../data/model_weights20-181339.7812.hdf5\n",
      "Epoch 21/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 52625.9684 - auc_25: 0.0000e+00 - val_loss: 179376.1250 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss improved from 181339.78125 to 179376.12500, saving model to ../../data/model_weights21-179376.1250.hdf5\n",
      "Epoch 22/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 52020.6436 - auc_25: 0.0000e+00 - val_loss: 177749.0469 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss improved from 179376.12500 to 177749.04688, saving model to ../../data/model_weights22-177749.0469.hdf5\n",
      "Epoch 23/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 51270.8124 - auc_25: 0.0000e+00 - val_loss: 174329.8750 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss improved from 177749.04688 to 174329.87500, saving model to ../../data/model_weights23-174329.8750.hdf5\n",
      "Epoch 24/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 50555.4758 - auc_25: 0.0000e+00 - val_loss: 168275.3125 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss improved from 174329.87500 to 168275.31250, saving model to ../../data/model_weights24-168275.3125.hdf5\n",
      "Epoch 25/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 851579.5063 - auc_25: 0.0000e+00 - val_loss: 19117372.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 168275.31250\n",
      "Epoch 26/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 35275527431.1462 - auc_25: 0.0000e+00 - val_loss: 1509084758016.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 168275.31250\n",
      "Epoch 27/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 7443894545442913.0000 - auc_25: 0.0000e+00 - val_loss: 45752919261184.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 168275.31250\n",
      "Epoch 28/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 23022677153473.3750 - auc_25: 0.0000e+00 - val_loss: 169007.4531 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 168275.31250\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193696/193696 [==============================] - 1s 5us/step - loss: 426263.4399 - auc_25: 0.0000e+00 - val_loss: 161807.0781 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss improved from 168275.31250 to 161807.07812, saving model to ../../data/model_weights29-161807.0781.hdf5\n",
      "Epoch 30/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 412171.1056 - auc_25: 0.0000e+00 - val_loss: 156603.2656 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss improved from 161807.07812 to 156603.26562, saving model to ../../data/model_weights30-156603.2656.hdf5\n",
      "Epoch 31/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 393132.2253 - auc_25: 0.0000e+00 - val_loss: 171764.8750 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 156603.26562\n",
      "Epoch 32/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 421289.1548 - auc_25: 0.0000e+00 - val_loss: 74042.5703 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss improved from 156603.26562 to 74042.57031, saving model to ../../data/model_weights32-74042.5703.hdf5\n",
      "Epoch 33/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 6856327.2675 - auc_25: 0.0000e+00 - val_loss: 90353000.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 74042.57031\n",
      "Epoch 34/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 400858959717.6514 - auc_25: 0.0000e+00 - val_loss: 11669714501632.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 74042.57031\n",
      "Epoch 35/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 877848641769582.2500 - auc_25: 0.0000e+00 - val_loss: 369149284974592.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 74042.57031\n",
      "Epoch 36/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 533262648624844.5000 - auc_25: 0.0000e+00 - val_loss: 184518673694720.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 74042.57031\n",
      "Epoch 37/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 20780813605559.9766 - auc_25: 0.0000e+00 - val_loss: 79240888320000.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 74042.57031\n",
      "Epoch 38/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 10268788897731.4355 - auc_25: 0.0000e+00 - val_loss: 37755979563008.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 74042.57031\n",
      "Epoch 39/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 5540666727404.5449 - auc_25: 0.0000e+00 - val_loss: 19047341096960.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 74042.57031\n",
      "Epoch 40/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 3148475212343.0654 - auc_25: 0.0000e+00 - val_loss: 9974292938752.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 74042.57031\n",
      "Epoch 41/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1851913344261.0330 - auc_25: 0.0000e+00 - val_loss: 5316823482368.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 74042.57031\n",
      "Epoch 42/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1116287690870.7590 - auc_25: 0.0000e+00 - val_loss: 2904785420288.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 74042.57031\n",
      "Epoch 43/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 685637951164.5425 - auc_25: 0.0000e+00 - val_loss: 1623988371456.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 74042.57031\n",
      "Epoch 44/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 426971173039.2625 - auc_25: 0.0000e+00 - val_loss: 930534457344.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 74042.57031\n",
      "Epoch 45/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 267741068413.3567 - auc_25: 0.0000e+00 - val_loss: 545328496640.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 74042.57031\n",
      "Epoch 46/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 167542239089.2186 - auc_25: 0.0000e+00 - val_loss: 323093889024.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 74042.57031\n",
      "Epoch 47/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 103330260434.0697 - auc_25: 0.0000e+00 - val_loss: 190532911104.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 74042.57031\n",
      "Epoch 48/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 61708206811.5011 - auc_25: 0.0000e+00 - val_loss: 108759572480.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 74042.57031\n",
      "Epoch 49/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 34783614555.4376 - auc_25: 0.0000e+00 - val_loss: 57908895744.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 74042.57031\n",
      "Epoch 50/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 17931494829.8668 - auc_25: 0.0000e+00 - val_loss: 27514900480.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 74042.57031\n",
      "Epoch 51/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 8099818867.5024 - auc_25: 0.0000e+00 - val_loss: 11051044864.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 74042.57031\n",
      "Epoch 52/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 3056553902.3532 - auc_25: 0.0000e+00 - val_loss: 3614855424.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 74042.57031\n",
      "Epoch 53/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 957521433.5979 - auc_25: 0.0000e+00 - val_loss: 1053360320.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 74042.57031\n",
      "Epoch 54/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 302370251.6200 - auc_25: 0.0000e+00 - val_loss: 399180576.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 74042.57031\n",
      "Epoch 55/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 140046427.5050 - auc_25: 0.0000e+00 - val_loss: 226434512.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 74042.57031\n",
      "Epoch 56/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 86085074.8759 - auc_25: 0.0000e+00 - val_loss: 145565712.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 74042.57031\n",
      "Epoch 57/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 54911640.7018 - auc_25: 0.0000e+00 - val_loss: 94113120.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 74042.57031\n",
      "Epoch 58/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 34480426.0938 - auc_25: 0.0000e+00 - val_loss: 60074672.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 74042.57031\n",
      "Epoch 59/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 21240738.9853 - auc_25: 0.0000e+00 - val_loss: 37721260.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 74042.57031\n",
      "Epoch 60/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 12804438.8381 - auc_25: 0.0000e+00 - val_loss: 23330092.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 74042.57031\n",
      "Epoch 61/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 7527850.9842 - auc_25: 0.0000e+00 - val_loss: 14140431.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 74042.57031\n",
      "Epoch 62/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4286642.4826 - auc_25: 0.0000e+00 - val_loss: 8363283.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 74042.57031\n",
      "Epoch 63/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2348259.3626 - auc_25: 0.0000e+00 - val_loss: 4795647.5000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 74042.57031\n",
      "Epoch 64/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193696/193696 [==============================] - 1s 5us/step - loss: 1326419.3000 - auc_25: 0.0000e+00 - val_loss: 8555844.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 74042.57031\n",
      "Epoch 65/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1418891707.7362 - auc_25: 0.0000e+00 - val_loss: 106100301824.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 74042.57031\n",
      "Epoch 66/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 6983914054248377.0000 - auc_25: 0.0000e+00 - val_loss: 13552966434816.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 74042.57031\n",
      "Epoch 67/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 6919521688205.4424 - auc_25: 0.0000e+00 - val_loss: 82782968.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 74042.57031\n",
      "Epoch 68/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 20861901.7456 - auc_25: 0.0000e+00 - val_loss: 83037008.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 74042.57031\n",
      "Epoch 69/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 20854504.0396 - auc_25: 0.0000e+00 - val_loss: 82332112.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 74042.57031\n",
      "Epoch 70/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 20843549.6042 - auc_25: 0.0000e+00 - val_loss: 79870880.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 74042.57031\n",
      "Epoch 71/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 21002919.7119 - auc_25: 0.0000e+00 - val_loss: 100904728.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 74042.57031\n",
      "Epoch 72/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 310264854.2138 - auc_25: 0.0000e+00 - val_loss: 2832701440.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 74042.57031\n",
      "Epoch 73/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 16827946010280.9180 - auc_25: 0.0000e+00 - val_loss: 371741062856704.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 74042.57031\n",
      "Epoch 74/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 568277407915968.3750 - auc_25: 0.0000e+00 - val_loss: 1071106621440.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 74042.57031\n",
      "Epoch 75/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 6766404167111.2422 - auc_25: 0.0000e+00 - val_loss: 491482611712.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 74042.57031\n",
      "Epoch 76/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1055083798867.6980 - auc_25: 0.0000e+00 - val_loss: 519831977984.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 74042.57031\n",
      "Epoch 77/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 393725986053.7095 - auc_25: 0.0000e+00 - val_loss: 460513050624.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 74042.57031\n",
      "Epoch 78/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 194751440403.0319 - auc_25: 0.0000e+00 - val_loss: 370752815104.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 74042.57031\n",
      "Epoch 79/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 110200103274.7054 - auc_25: 0.0000e+00 - val_loss: 274337021952.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 74042.57031\n",
      "Epoch 80/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 65412442033.8424 - auc_25: 0.0000e+00 - val_loss: 185090129920.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 74042.57031\n",
      "Epoch 81/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 38145852902.0321 - auc_25: 0.0000e+00 - val_loss: 111796051968.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 74042.57031\n",
      "Epoch 82/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 20690315224.2445 - auc_25: 0.0000e+00 - val_loss: 58658430976.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 74042.57031\n",
      "Epoch 83/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 9891292354.0406 - auc_25: 0.0000e+00 - val_loss: 25644640256.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 74042.57031\n",
      "Epoch 84/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 3929249665.9666 - auc_25: 0.0000e+00 - val_loss: 8789035008.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 74042.57031\n",
      "Epoch 85/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1202294956.2914 - auc_25: 0.0000e+00 - val_loss: 2186979328.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 74042.57031\n",
      "Epoch 86/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 258023410.6737 - auc_25: 0.0000e+00 - val_loss: 364218400.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 74042.57031\n",
      "Epoch 87/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 35265136.1650 - auc_25: 0.0000e+00 - val_loss: 42584256.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 74042.57031\n",
      "Epoch 88/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4088323.6183 - auc_25: 0.0000e+00 - val_loss: 6724263.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 74042.57031\n",
      "Epoch 89/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1878353.2602 - auc_25: 0.0000e+00 - val_loss: 3455899.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 74042.57031\n",
      "Epoch 90/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1768139.2400 - auc_25: 0.0000e+00 - val_loss: 3131792.7500 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 74042.57031\n",
      "Epoch 91/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1704327.5994 - auc_25: 0.0000e+00 - val_loss: 2898961.2500 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 74042.57031\n",
      "Epoch 92/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1626833.5818 - auc_25: 0.0000e+00 - val_loss: 2795821.7500 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 74042.57031\n",
      "Epoch 93/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1533344.5260 - auc_25: 0.0000e+00 - val_loss: 2567512.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 74042.57031\n",
      "Epoch 94/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1423210.0547 - auc_25: 0.0000e+00 - val_loss: 2466992.2500 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 74042.57031\n",
      "Epoch 95/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1298487.7147 - auc_25: 0.0000e+00 - val_loss: 2498612.2500 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 74042.57031\n",
      "Epoch 96/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1159136.5293 - auc_25: 0.0000e+00 - val_loss: 1456598.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 74042.57031\n",
      "Epoch 97/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1794590.9594 - auc_25: 0.0000e+00 - val_loss: 122400456.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 74042.57031\n",
      "Epoch 98/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 19002138516.9820 - auc_25: 0.0000e+00 - val_loss: 325615648768.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 74042.57031\n",
      "Epoch 99/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 8140842235119238.0000 - auc_25: 0.0000e+00 - val_loss: 32245591048192.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 74042.57031\n",
      "Epoch 100/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193696/193696 [==============================] - 1s 5us/step - loss: 54505160336162.5469 - auc_25: 0.0000e+00 - val_loss: 5017121587200.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 74042.57031\n",
      "Epoch 101/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 10615492139617.3594 - auc_25: 0.0000e+00 - val_loss: 862465884160.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 74042.57031\n",
      "Epoch 102/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1880852260565.9185 - auc_25: 0.0000e+00 - val_loss: 625762828288.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 74042.57031\n",
      "Epoch 103/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 391930242265.0480 - auc_25: 0.0000e+00 - val_loss: 799866355712.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 74042.57031\n",
      "Epoch 104/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 227190292363.6094 - auc_25: 0.0000e+00 - val_loss: 824254136320.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 74042.57031\n",
      "Epoch 105/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 204192615299.6584 - auc_25: 0.0000e+00 - val_loss: 771916562432.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 74042.57031\n",
      "Epoch 106/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 186177792151.2401 - auc_25: 0.0000e+00 - val_loss: 694296772608.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 74042.57031\n",
      "Epoch 107/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 166739525645.5338 - auc_25: 0.0000e+00 - val_loss: 612575674368.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 74042.57031\n",
      "Epoch 108/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 146621291324.6060 - auc_25: 0.0000e+00 - val_loss: 531479953408.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 74042.57031\n",
      "Epoch 109/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 126956653779.2962 - auc_25: 0.0000e+00 - val_loss: 450803040256.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 74042.57031\n",
      "Epoch 110/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 108954323666.3658 - auc_25: 0.0000e+00 - val_loss: 379473231872.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 74042.57031\n",
      "Epoch 111/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 93516888883.1323 - auc_25: 0.0000e+00 - val_loss: 313825099776.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 74042.57031\n",
      "Epoch 112/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 82325700165.4452 - auc_25: 0.0000e+00 - val_loss: 317032497152.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 74042.57031\n",
      "Epoch 113/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 2293607754769.7632 - auc_25: 0.0000e+00 - val_loss: 16670156390400.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 74042.57031\n",
      "Epoch 114/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 9586326601668.2852 - auc_25: 0.0000e+00 - val_loss: 7332512.5000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 74042.57031\n",
      "Epoch 115/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1954933.0668 - auc_25: 0.0000e+00 - val_loss: 7209773.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 74042.57031\n",
      "Epoch 116/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1951387.9814 - auc_25: 0.0000e+00 - val_loss: 7152911.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 74042.57031\n",
      "Epoch 117/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1948064.3789 - auc_25: 0.0000e+00 - val_loss: 7232423.5000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 74042.57031\n",
      "Epoch 118/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1961545.3901 - auc_25: 0.0000e+00 - val_loss: 5498529.5000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 74042.57031\n",
      "Epoch 119/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 35011243.1829 - auc_25: 0.0000e+00 - val_loss: 595907904.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 74042.57031\n",
      "Epoch 120/300\n",
      "193696/193696 [==============================] - 1s 6us/step - loss: 1198487118289.4775 - auc_25: 0.0000e+00 - val_loss: 7993255526400.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 74042.57031\n",
      "Epoch 121/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 2857195512258956.5000 - auc_25: 0.0000e+00 - val_loss: 647620267606016.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 74042.57031\n",
      "Epoch 122/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 376395670678202.0625 - auc_25: 0.0000e+00 - val_loss: 12999054065664.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 74042.57031\n",
      "Epoch 123/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1740352374828.3230 - auc_25: 0.0000e+00 - val_loss: 5420064702464.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 74042.57031\n",
      "Epoch 124/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 918418649291.6835 - auc_25: 0.0000e+00 - val_loss: 3100217966592.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 74042.57031\n",
      "Epoch 125/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 539357676229.1703 - auc_25: 0.0000e+00 - val_loss: 848038985728.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 74042.57031\n",
      "Epoch 126/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 3452151256565.9341 - auc_25: 0.0000e+00 - val_loss: 23674956546048.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 74042.57031\n",
      "Epoch 127/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 24221135114972.1758 - auc_25: 0.0000e+00 - val_loss: 156247851008.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 74042.57031\n",
      "Epoch 128/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 53262791607.4251 - auc_25: 0.0000e+00 - val_loss: 108506038272.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 74042.57031\n",
      "Epoch 129/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 42828077308.0667 - auc_25: 0.0000e+00 - val_loss: 81171496960.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 74042.57031\n",
      "Epoch 130/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 35888637399.8216 - auc_25: 0.0000e+00 - val_loss: 61002272768.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 74042.57031\n",
      "Epoch 131/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 34696117177.1168 - auc_25: 0.0000e+00 - val_loss: 141087064064.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 74042.57031\n",
      "Epoch 132/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 8275833913002.9482 - auc_25: 0.0000e+00 - val_loss: 672145216.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 74042.57031\n",
      "Epoch 133/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 548949090.9314 - auc_25: 0.0000e+00 - val_loss: 9884397.0000 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 74042.57031\n",
      "Epoch 134/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 44441157.6669 - auc_25: 0.0000e+00 - val_loss: 46994.1016 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00134: val_loss improved from 74042.57031 to 46994.10156, saving model to ../../data/model_weights134-46994.1016.hdf5\n",
      "Epoch 135/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193696/193696 [==============================] - 1s 5us/step - loss: 22086797.3362 - auc_25: 0.0000e+00 - val_loss: 41007.3555 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00135: val_loss improved from 46994.10156 to 41007.35547, saving model to ../../data/model_weights135-41007.3555.hdf5\n",
      "Epoch 136/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 12622160.5630 - auc_25: 0.0000e+00 - val_loss: 20764.1934 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00136: val_loss improved from 41007.35547 to 20764.19336, saving model to ../../data/model_weights136-20764.1934.hdf5\n",
      "Epoch 137/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 7791613.4922 - auc_25: 0.0000e+00 - val_loss: 10860.2998 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00137: val_loss improved from 20764.19336 to 10860.29980, saving model to ../../data/model_weights137-10860.2998.hdf5\n",
      "Epoch 138/300\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 5509149.1899 - auc_25: 0.0000e+00 - val_loss: 8201.9932 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00138: val_loss improved from 10860.29980 to 8201.99316, saving model to ../../data/model_weights138-8201.9932.hdf5\n",
      "Epoch 139/300\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 3429651.5790 - auc_25: 0.0000e+00 - val_loss: 6404.4077 - val_auc_25: 0.0000e+00\n",
      "\n",
      "Epoch 00139: val_loss improved from 8201.99316 to 6404.40771, saving model to ../../data/model_weights139-6404.4077.hdf5\n",
      "Epoch 140/300\n",
      " 80000/193696 [===========>..................] - ETA: 0s - loss: 2368278.5000 - auc_25: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_cols, outputs=[y])\n",
    "\n",
    "# model.summary()\n",
    "model.compile(loss=\"mse\", optimizer=RMSprop(lr=lr), metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit([encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                       encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating], local_df['rating'], \n",
    "          batch_size=batch_size, epochs=epochs, validation_split=0.005,\n",
    "                   callbacks = [cb_checkpoint])\n",
    "# encoded_fch, encoded_category_l, encoded_lw\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.legend() \n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = os.listdir(model_save_path)\n",
    "print('file_list: {}'.format(file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유사도 아이템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_to_vec(feature, model, location_df, h_size, input_features):\n",
    "    layer_name = feature\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "    test = input_features\n",
    "                             \n",
    "    locationId_latent_vector = intermediate_layer_model.predict(test)\n",
    "    \n",
    "    locationId_latent_vector = locationId_latent_vector.T.reshape(-1, h_size)\n",
    "    vec = pd.DataFrame(locationId_latent_vector)\n",
    "    location_df = location_df.reset_index()\n",
    "    vec['locationId'] = location_df['locationId']\n",
    "    \n",
    "    # 아이템별 의미 벡터 생성 \n",
    "    vec = vec.groupby('locationId').agg([('0','mean')]).reset_index()\n",
    "\n",
    "    vec = pd.DataFrame(vec.iloc[:,1:].values)\n",
    "    vec['locationId'] = location_df['locationId'].unique()\n",
    "    vec = vec.set_index('locationId')\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locationId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788542</th>\n",
       "      <td>-1537.253174</td>\n",
       "      <td>-1537.266357</td>\n",
       "      <td>-1537.279541</td>\n",
       "      <td>-1537.314453</td>\n",
       "      <td>-1447.767334</td>\n",
       "      <td>-1447.767334</td>\n",
       "      <td>-1447.780518</td>\n",
       "      <td>-1447.780518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077917</th>\n",
       "      <td>-830.337341</td>\n",
       "      <td>-871.947632</td>\n",
       "      <td>-871.627380</td>\n",
       "      <td>-765.864197</td>\n",
       "      <td>-765.837524</td>\n",
       "      <td>-750.090576</td>\n",
       "      <td>-662.776184</td>\n",
       "      <td>-685.335754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732387</th>\n",
       "      <td>-1109.489136</td>\n",
       "      <td>-1388.345825</td>\n",
       "      <td>-1144.588257</td>\n",
       "      <td>-1388.380493</td>\n",
       "      <td>-1137.427734</td>\n",
       "      <td>-1388.411743</td>\n",
       "      <td>-1388.431519</td>\n",
       "      <td>-1388.451294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13833720</th>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977925</th>\n",
       "      <td>-804.521362</td>\n",
       "      <td>-1029.487427</td>\n",
       "      <td>-1029.499146</td>\n",
       "      <td>-1029.504883</td>\n",
       "      <td>-1029.516602</td>\n",
       "      <td>-1029.529663</td>\n",
       "      <td>-1029.542847</td>\n",
       "      <td>-1029.557495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597806</th>\n",
       "      <td>-148.596954</td>\n",
       "      <td>-153.404205</td>\n",
       "      <td>-153.406769</td>\n",
       "      <td>-35.644745</td>\n",
       "      <td>-153.408722</td>\n",
       "      <td>-153.411285</td>\n",
       "      <td>-148.605774</td>\n",
       "      <td>-200.125015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149130</th>\n",
       "      <td>-265.883179</td>\n",
       "      <td>-266.655426</td>\n",
       "      <td>-266.654724</td>\n",
       "      <td>-264.719025</td>\n",
       "      <td>-272.489685</td>\n",
       "      <td>-273.921692</td>\n",
       "      <td>-271.398651</td>\n",
       "      <td>-271.191956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595040</th>\n",
       "      <td>-184.902512</td>\n",
       "      <td>-172.722931</td>\n",
       "      <td>-172.722931</td>\n",
       "      <td>-172.728180</td>\n",
       "      <td>-172.728180</td>\n",
       "      <td>-172.726868</td>\n",
       "      <td>-223.797028</td>\n",
       "      <td>-172.732117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13369640</th>\n",
       "      <td>-539.402954</td>\n",
       "      <td>-539.408813</td>\n",
       "      <td>-543.603333</td>\n",
       "      <td>-548.325012</td>\n",
       "      <td>-601.862061</td>\n",
       "      <td>-601.862549</td>\n",
       "      <td>-601.864868</td>\n",
       "      <td>-601.870300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043495</th>\n",
       "      <td>-285.754547</td>\n",
       "      <td>-274.807343</td>\n",
       "      <td>-375.382904</td>\n",
       "      <td>-375.460602</td>\n",
       "      <td>-375.839478</td>\n",
       "      <td>-376.107117</td>\n",
       "      <td>-376.171600</td>\n",
       "      <td>-377.835449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15934 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1            2            3            4  \\\n",
       "locationId                                                                    \n",
       "788542     -1537.253174 -1537.266357 -1537.279541 -1537.314453 -1447.767334   \n",
       "4077917     -830.337341  -871.947632  -871.627380  -765.864197  -765.837524   \n",
       "9732387    -1109.489136 -1388.345825 -1144.588257 -1388.380493 -1137.427734   \n",
       "13833720    -385.016907  -385.016907  -385.016907  -385.016907  -385.016907   \n",
       "8977925     -804.521362 -1029.487427 -1029.499146 -1029.504883 -1029.516602   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "9597806     -148.596954  -153.404205  -153.406769   -35.644745  -153.408722   \n",
       "1149130     -265.883179  -266.655426  -266.654724  -264.719025  -272.489685   \n",
       "3595040     -184.902512  -172.722931  -172.722931  -172.728180  -172.728180   \n",
       "13369640    -539.402954  -539.408813  -543.603333  -548.325012  -601.862061   \n",
       "7043495     -285.754547  -274.807343  -375.382904  -375.460602  -375.839478   \n",
       "\n",
       "                      5            6            7  \n",
       "locationId                                         \n",
       "788542     -1447.767334 -1447.780518 -1447.780518  \n",
       "4077917     -750.090576  -662.776184  -685.335754  \n",
       "9732387    -1388.411743 -1388.431519 -1388.451294  \n",
       "13833720    -385.016907  -385.016907  -385.016907  \n",
       "8977925    -1029.529663 -1029.542847 -1029.557495  \n",
       "...                 ...          ...          ...  \n",
       "9597806     -153.411285  -148.605774  -200.125015  \n",
       "1149130     -273.921692  -271.398651  -271.191956  \n",
       "3595040     -172.726868  -223.797028  -172.732117  \n",
       "13369640    -601.862549  -601.864868  -601.870300  \n",
       "7043495     -376.107117  -376.171600  -377.835449  \n",
       "\n",
       "[15934 rows x 8 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = latent_to_vec('FM_locationId', model, local_df, 8, [encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                        encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.to_csv(os.path.join(\"..\",\"realtime_model\",'deepFM_local_vec.csv'))#, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosim_id(df, vec, item_id):\n",
    "    def cos_sim(A, B):\n",
    "           return dot(A, B)/(norm(A)*norm(B)) \n",
    "    new_vec = vec.copy() \n",
    "    sim = []\n",
    "    \n",
    "    # 인풋 호텔 정보 데이터에 없는 경우 종료 \n",
    "    if item_id not in vec.index.tolist():\n",
    "        return \n",
    "        \n",
    "    for i in range(len(vec)):\n",
    "        sim.append(cos_sim(vec.loc[item_id,:], vec.iloc[i,:]))\n",
    "\n",
    "    new_vec['sim'] = sim\n",
    "    # sim 높은 순 \n",
    "    new_vec = new_vec['sim'].reset_index().sort_values('sim', ascending=False)\n",
    "    sim_sorted = new_vec['locationId'].tolist()\n",
    "    # 인풋 호텔정보 빼고 유사도 높은 순대로 id \n",
    "    if item_id in sim_sorted:\n",
    "        sim_sorted.remove(item_id) \n",
    "    return sim_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sim_item(vec, df, item_id, top):\n",
    "    top_id = cosim_id(df, vec, item_id)\n",
    "    \n",
    "    if type(top_id) == list :\n",
    "        df = df.drop_duplicates(['locationId'], keep='last')\n",
    "        recommend_rst = []\n",
    "        for x in top_id:\n",
    "            if df.loc[df['locationId']==x].category.values[0]== 'EAT':\n",
    "                recommend_rst.append([df.loc[df['locationId']==x][['place.name', 'land.addr']]])\n",
    "\n",
    "        print('input hotel:', local_df.loc[local_df['locationId']==item_id]['place.name'].unique()[0])\n",
    "        print('-'*10)\n",
    "        for i in range(len(recommend_rst[:top])):\n",
    "            print('top', i+1, recommend_rst[i][0]['place.name'].values[0])\n",
    "            print('  주소', recommend_rst[i][0]['land.addr'].values[0])\n",
    "        \n",
    "    else:\n",
    "        answer_lst = ['해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.', '해당 호텔 정보가 없습니다. 다른 호텔을 추천받아보세요.']\n",
    "        x = random.randint(0, len(answer_lst)-1)\n",
    "        return answer_lst[x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Conrad Seoul\n",
      "----------\n",
      "top 1 김경애 떡방\n",
      "  주소 서울특별시 강남구 대치동 316 은마아파트\n",
      "top 2 오리올\n",
      "  주소 서울특별시 용산구 후암동 406-99\n",
      "top 3 블랑제리 더 플라자\n",
      "  주소 서울특별시 중구 태평로2가 23 더 플라자\n",
      "top 4 버거킹 센트럴시티점\n",
      "  주소 서울특별시 서초구 반포동 19-3 센트럴시티\n",
      "top 5 피자스쿨 신풍역점\n",
      "  주소 서울특별시 영등포구 신길동 3894\n",
      "top 6 라밥 노량진2호점\n",
      "  주소 서울특별시 동작구 노량진동 119-166\n",
      "top 7 영미네 곱창\n",
      "  주소 서울특별시 중구 황학동 1783\n",
      "top 8 삼미식당 홍대점\n",
      "  주소 서울특별시 마포구 서교동 347-24\n",
      "top 9 인생닭강정 장승백이점\n",
      "  주소 서울특별시 동작구 상도동 364-23\n",
      "top 10 성수동 대림창고\n",
      "  주소 서울특별시 성동구 성수동2가 322-32 대림창고\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 3477158, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item(vec, local_df, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis styles Ambassador Seoul Gangnam\n",
      "----------\n",
      "top 1 감동식당\n",
      "  주소 서울특별시 노원구 상계동 434-49\n",
      "top 2 인하순대국\n",
      "  주소 서울특별시 서초구 서초동 1555-16\n",
      "top 3 라떼또뜨\n",
      "  주소 서울특별시 서초구 방배동 875-1\n",
      "top 4 상도늘보리 본점\n",
      "  주소 서울특별시 동작구 상도2동 367-6\n",
      "top 5 비파티세리\n",
      "  주소 서울특별시 강남구 신사동 546-17 인자빌딩\n",
      "top 6 매화반점\n",
      "  주소 서울특별시 광진구 자양4동 4-11\n",
      "top 7 등촌샤브칼국수\n",
      "  주소 서울특별시 송파구 문정동 76-3\n",
      "top 8 원조양평해장국직영점\n",
      "  주소 서울특별시 은평구 갈현동 460-18\n",
      "top 9 우리집김밥 서초점\n",
      "  주소 서울특별시 서초구 서초동 1330-11 금성상가\n",
      "top 10 일상밥상\n",
      "  주소 서울특별시 양천구 목동 905-22 목동트윈빌\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 299533, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Best Western Premier Seoul Garden Hotel\n",
      "----------\n",
      "top 1 미추원주추어탕서울본점\n",
      "  주소 서울특별시 관악구 봉천동 1595-8\n",
      "top 2 빠리가옥\n",
      "  주소 서울특별시 종로구 익선동 166-26\n",
      "top 3 다담\n",
      "  주소 서울특별시 강남구 청담동 97-1 M빌딩\n",
      "top 4 깐부치킨 신사역점\n",
      "  주소 서울특별시 강남구 신사동 514-5\n",
      "top 5 스위트스페이스 현대시티아루렛동대문점\n",
      "  주소 서울특별시 중구 을지로6가 17-2 현대시티타워\n",
      "top 6 크앙분식 - 혜화본점\n",
      "  주소 서울특별시 종로구 연건동 195-38\n",
      "top 7 호치킨 창동역점\n",
      "  주소 서울특별시 도봉구 창동 75-13\n",
      "top 8 Guksuga\n",
      "  주소 서울특별시 중구 충무로5가 86-3\n",
      "top 9 인생닭강정\n",
      "  주소 서울특별시 성북구 동선동1가 85-97\n",
      "top 10 소피스티케이크\n",
      "  주소 서울특별시 마포구 서교동 396-54\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 299152, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis budget Ambassador Seoul Dongdaemun\n",
      "----------\n",
      "top 1 바나프레소 길동역점\n",
      "  주소 서울특별시 강동구 길동 366-5\n",
      "top 2 진대포\n",
      "  주소 서울특별시 용산구 갈월동 98-1\n",
      "top 3 충무로쭈꾸미불고기\n",
      "  주소 서울특별시 중구 필동1가 3-20\n",
      "top 4 마녀김밥 노들점\n",
      "  주소 서울특별시 용산구 이촌동 302-146\n",
      "top 5 홀리차우\n",
      "  주소 서울특별시 중구 명동1가 8-1\n",
      "top 6 스타벅스 쌍문역점\n",
      "  주소 서울특별시 도봉구 창동 659-5\n",
      "top 7 김밥천국\n",
      "  주소 서울특별시 마포구 망원동 395-4\n",
      "top 8 내고향횡성한우정육점식당\n",
      "  주소 서울특별시 송파구 방이동 66-3 석촌씨티빌딩\n",
      "top 9 가야랑\n",
      "  주소 서울특별시 용산구 이태원2동 239-4\n",
      "top 10 돈수작 건대점\n",
      "  주소 서울특별시 광진구 화양동 9-19\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 6998634, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Banyan Tree Club & Spa Seoul\n",
      "----------\n",
      "top 1 조아저씨김치찌개와막겹구이\n",
      "  주소 서울특별시 중구 서소문동 23\n",
      "top 2 탐앤탐스\n",
      "  주소 서울특별시 서초구 반포동 20-45 반포자이플라자\n",
      "top 3 황소고집\n",
      "  주소 서울특별시 종로구 관철동 11-11\n",
      "top 4 서울감자탕\n",
      "  주소 서울특별시 강동구 성내동 199-11\n",
      "top 5 써브웨이 상암DMC푸르지오시티점\n",
      "  주소 서울특별시 마포구 상암동 1596 상암DMC푸르지오시티, S-City\n",
      "top 6 밥이답이다 신촌세브란스병원점\n",
      "  주소 서울특별시 서대문구 신촌동 134 신촌세브란스병원\n",
      "top 7 모힝\n",
      "  주소 서울특별시 관악구 봉천동 1598-6\n",
      "top 8 푸주옥\n",
      "  주소 서울특별시 양천구 신정동 1290-2\n",
      "top 9 마포 갈매기\n",
      "  주소 서울특별시 마포구 도화동 194-8\n",
      "top 10 돈암동찌개\n",
      "  주소 서울특별시 강북구 수유동 191-66\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 1796658, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Grand InterContinental Seoul Parnas\n",
      "----------\n",
      "top 1 곳온니플레이스\n",
      "  주소 서울특별시 영등포구 여의도동 17 여의도더샵아일랜드파크\n",
      "top 2 풀향기\n",
      "  주소 서울특별시 용산구 한남동 726-54 풀향기(음식점)\n",
      "top 3 센터커피\n",
      "  주소 서울 성동구 서울숲2길 28-11 2층\n",
      "top 4 그랜드뮤즈\n",
      "  주소 서울특별시 용산구 한남동 726-419\n",
      "top 5 달구벌반점\n",
      "  주소 서울특별시 성동구 성수동2가 278-25\n",
      "top 6 정성본 샤브수끼 칼국수 강남역점\n",
      "  주소 서울특별시 서초구 서초동 1321-9 풍림아이원매직\n",
      "top 7 브릭하우스76\n",
      "  주소 서울특별시 은평구 역촌동 35-29\n",
      "top 8 장군갈비\n",
      "  주소 서울특별시 영등포구 문래동3가 55-5 로데오 왘 쇼핑몰\n",
      "top 9 담소소사골순대육개장 가산디지털점\n",
      "  주소 서울특별시 금천구 가산동 60-11 스타밸리\n",
      "top 10 평양냉면\n",
      "  주소 서울특별시 구로구 오류동 13-55\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 306118, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
