{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/busesese/DeepFM_Keras/blob/master/DeepFM/deepfm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.layers import Input, Dense, Embedding, Add, Concatenate, RepeatVector,Multiply,Subtract,Lambda,Dropout,Reshape,Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from mylayers import MySumLayer\n",
    "from keras.optimizers import Adam\n",
    "# import config\n",
    "from keras.metrics import binary_accuracy\n",
    "# from metrics import auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from keras.optimizers import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>place.name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>is_fch</th>\n",
       "      <th>photonum</th>\n",
       "      <th>is_local</th>\n",
       "      <th>rated_count</th>\n",
       "      <th>average_photonum</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>user_reviewcount</th>\n",
       "      <th>userID</th>\n",
       "      <th>category_l</th>\n",
       "      <th>land.addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20180314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>11</td>\n",
       "      <td>14256</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20171207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>722</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20161110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>30372</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20160611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2116</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20151204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.095238</td>\n",
       "      <td>42</td>\n",
       "      <td>3208</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationId place.name category  rating  createdDate  is_fch  photonum  \\\n",
       "0      788542     마르코 폴로      EAT     5.0     20180314       0         0   \n",
       "1      788542     마르코 폴로      EAT     4.0     20171207       0         0   \n",
       "2      788542     마르코 폴로      EAT     5.0     20161110       0         0   \n",
       "3      788542     마르코 폴로      EAT     3.0     20160611       0         0   \n",
       "4      788542     마르코 폴로      EAT     4.0     20151204       0         0   \n",
       "\n",
       "   is_local  rated_count  average_photonum  average_rating  user_mean_rating  \\\n",
       "0         1           20              0.05            3.95          4.363636   \n",
       "1         1           20              0.05            3.95          4.000000   \n",
       "2         0           20              0.05            3.95          5.000000   \n",
       "3         0           20              0.05            3.95          4.250000   \n",
       "4         1           20              0.05            3.95          4.095238   \n",
       "\n",
       "   user_reviewcount  userID  category_l                    land.addr  \n",
       "0                11   14256           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "1                 6     722           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "2                 1   30372           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "3                 4    2116           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "4                42    3208           1  서울 강남구 삼성동 159-1 트레이드타워 52층  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "import gc\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"..\",\"..\",\"data\",\"YN_final_df.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬 / 글로벌 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_df shape: (459903, 16) global_df shape : (93722, 16)\n"
     ]
    }
   ],
   "source": [
    "# 로컬 / 글로벌 데이터 분리\n",
    "local_df = df.loc[df['is_local']==1]\n",
    "global_df = df.loc[df['is_local']==0]\n",
    "print('local_df shape:',local_df.shape, 'global_df shape :',global_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553625, 16)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "체인을 빼도ㅍ성능 나빠.... \n",
    "차라리 장소의 다양성을 위해 + 글로벌 데이터 추천 결과가 좋으므로\n",
    "글로벌 데이터 추가해서 전체 중에서\n",
    "체인 및 손수 전처리 체인 제거\n",
    "'''\n",
    "\n",
    "local_df = df.copy()\n",
    "local_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57122, 16) (496503, 16)\n",
      "(237052, 16)\n",
      "1527\n",
      "41784\n",
      "42382\n",
      "237052\n",
      "194670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>place.name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>is_fch</th>\n",
       "      <th>photonum</th>\n",
       "      <th>is_local</th>\n",
       "      <th>rated_count</th>\n",
       "      <th>average_photonum</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>user_reviewcount</th>\n",
       "      <th>userID</th>\n",
       "      <th>category_l</th>\n",
       "      <th>land.addr</th>\n",
       "      <th>lw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81114</th>\n",
       "      <td>1011796922</td>\n",
       "      <td>호텔더디자이너스동대문</td>\n",
       "      <td>ACM</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20191216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.417995</td>\n",
       "      <td>105</td>\n",
       "      <td>42122</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 중구 쌍림동 266-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81115</th>\n",
       "      <td>37903636</td>\n",
       "      <td>아만티호텔서울</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>20190722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.417995</td>\n",
       "      <td>105</td>\n",
       "      <td>42122</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 월드컵북로 31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81155</th>\n",
       "      <td>13217405</td>\n",
       "      <td>코트야드 메리어트 서울 타임스퀘어</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>20190621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>4.414649</td>\n",
       "      <td>40</td>\n",
       "      <td>101654</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 영등포구 영중로 15 타임스퀘어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81659</th>\n",
       "      <td>20315170</td>\n",
       "      <td>스탠포드호텔코리아</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>20191227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>4.395100</td>\n",
       "      <td>33</td>\n",
       "      <td>24205</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 상암동 1587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81660</th>\n",
       "      <td>20315170</td>\n",
       "      <td>스탠포드호텔코리아</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>20191209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>4.395100</td>\n",
       "      <td>33</td>\n",
       "      <td>24205</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 상암동 1587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       locationId          place.name category    rating  createdDate  is_fch  \\\n",
       "81114  1011796922         호텔더디자이너스동대문      ACM  5.000000     20191216       0   \n",
       "81115    37903636             아만티호텔서울      ACM  4.666667     20190722       0   \n",
       "81155    13217405  코트야드 메리어트 서울 타임스퀘어      ACM  4.270833     20190621       0   \n",
       "81659    20315170           스탠포드호텔코리아      ACM  4.184211     20191227       0   \n",
       "81660    20315170           스탠포드호텔코리아      ACM  4.184211     20191209       0   \n",
       "\n",
       "       photonum  is_local  rated_count  average_photonum  average_rating  \\\n",
       "81114         0         1            1               0.0        5.000000   \n",
       "81115         0         1            3               0.0        4.666667   \n",
       "81155         0         1           24               0.0        4.270833   \n",
       "81659         0         1           19               0.0        4.184211   \n",
       "81660         0         1           19               0.0        4.184211   \n",
       "\n",
       "       user_mean_rating  user_reviewcount  userID  category_l  \\\n",
       "81114          4.417995               105   42122           1   \n",
       "81115          4.417995               105   42122           1   \n",
       "81155          4.414649                40  101654           1   \n",
       "81659          4.395100                33   24205           1   \n",
       "81660          4.395100                33   24205           1   \n",
       "\n",
       "                     land.addr  lw  \n",
       "81114       서울특별시 중구 쌍림동 266-2   0  \n",
       "81115       서울특별시 마포구 월드컵북로 31   0  \n",
       "81155  서울특별시 영등포구 영중로 15 타임스퀘어   0  \n",
       "81659       서울특별시 마포구 상암동 1587   0  \n",
       "81660       서울특별시 마포구 상암동 1587   0  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_df_acm = local_df.loc[local_df['category'] == 'ACM']\n",
    "local_df_eat = local_df.loc[local_df['category'] == 'EAT']\n",
    "print(local_df_acm.shape, local_df_eat.shape)\n",
    "\n",
    "local_df_eat = local_df_eat.loc[local_df_eat['average_rating']>=local_df_eat['average_rating'].median()]\n",
    "local_df = pd.concat([local_df_acm, local_df_eat])\n",
    "\n",
    "# local이기에 global과 차이를 두기위해 최대한 의미없는 체인 제거 \n",
    "local_df = local_df.loc[local_df['is_fch']==0]\n",
    "print(local_df.shape)\n",
    "\n",
    "fch_lst = ['써브웨이', '던킨도너츠','노브랜드버거','바르다김선생',' 폴바셋',' 안동찜닭',' 속초코다리냉면',' 할매순대국&양선지해장국',' 노브랜드버거 남부터미널점','바르다김선생' ,'유가네','24시 중식당 취빈','매머드커피','압구정봉구비어','카페베네','쥬씨','피자스쿨','매머드익스프레스','김밥천국','한국맥도날드','메머드커피','신전떡볶이','어사또', '공차', '북촌손만두', '오징어세상' ,'사월에보리밥', '땡스브레드엔커피', '피자몰', '나주소나주곰탕', '새마을식당','싸다김밥', '교동짬뽕', '토마토김밥', '화화쿵주마라탕', '샐러데이즈', '더차이','뚜레쥬르','스쿨푸드','자연별곡','죠스떡볶이','국대떡볶이', '도쿄스테이크','이디야커피', '코스트코코리아양재점푸드코트', '불고기브라더스','알라딘중고서점카페','배스킨라빈스','할리스커피', '와플대학', '파리바게뜨공덕역사', '파리바게뜨','아웃백','설빙', '봉추찜닭', '하겐다즈','아라마크연세의료원종합관'\n",
    "]\n",
    "fch_idx = local_df[local_df['place.name'].apply(lambda x: any(i in x for i in fch_lst))].index.tolist()\n",
    "idx = local_df[local_df['place.name'].apply(lambda x: x[-1] == '점')].index.tolist()\n",
    "print(len(fch_idx))\n",
    "print(len(idx))\n",
    "\n",
    "for i in idx:\n",
    "    if i not in fch_idx:\n",
    "        fch_idx.append(i)\n",
    "        \n",
    "print(len(fch_idx))\n",
    "\n",
    "print(local_df.shape[0])\n",
    "local_df = local_df.drop(fch_idx)\n",
    "print(local_df.shape[0])\n",
    "\n",
    "local_df['lw'] = local_df['is_local'].apply(lambda x: 1 if x==0 else 0)\n",
    "local_df['lw'] = local_df['lw']*5\n",
    "local_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_df.to_csv(os.path.join(\"..\",\"realtime_model\",'local_df.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSTATE = 2018\n",
    "\n",
    "NUMERIC_COLS=[\n",
    "    'locationId',  'createdDate',\n",
    "    'photonum', 'rated_count', 'average_photonum',\n",
    "    'average_rating', 'user_mean_rating', 'user_reviewcount',\n",
    "    'userID'] #,'lw'\n",
    "\n",
    "\n",
    "IGNORE_COLS = [\"place.name\", \"land.addr\", 'rating','is_fch', 'category_l','lw']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(column, df) :\n",
    "    \n",
    "    vocab = {}\n",
    "    num = 0\n",
    "\n",
    "    for i in df[column]: # np.hstack([train[column], test[column]]): \n",
    "        if vocab.get(i) != None:\n",
    "            continue\n",
    "\n",
    "        vocab[i] = num\n",
    "        num += 1\n",
    "\n",
    "    encoded = [vocab[i] for i in df[column]]\n",
    "    # encoded_d = [vocab[i] for i in test[column]]\n",
    "    \n",
    "    return encoded, num, vocab\n",
    "\n",
    "# continous\n",
    "encoded_locationId, num_locationId, vocab_locationId = get_data('locationId', local_df) \n",
    "encoded_createdDate,  num_createdDate, vocab_createdDate = get_data('createdDate', local_df) \n",
    "encoded_photonum,  num_photonum, vocab_photonum = get_data('photonum', local_df) \n",
    "encoded_rated_count,  num_rated_count, vocab_rated_count = get_data('rated_count', local_df) \n",
    "encoded_average_photonum,  num_average_photonum, vocab_average_photonum = get_data('average_photonum', local_df) \n",
    "encoded_average_rating,  num_average_rating, vocab_average_rating = get_data('average_rating', local_df) \n",
    "encoded_users_mean_rating, num_users_mean_rating, vocab_users_mean_rating = get_data('user_mean_rating', local_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', local_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', local_df) \n",
    "encoded_userID, num_userID, vocab_userID = get_data('userID', local_df) \n",
    "# encoded_lw,  num_lw, vocab_lw = get_data('lw', local_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locationId': 5601,\n",
       " 'createdDate': 4238,\n",
       " 'photonum': 39,\n",
       " 'rated_count': 226,\n",
       " 'average_photonum': 1084,\n",
       " 'average_rating': 1646,\n",
       " 'user_mean_rating': 30961,\n",
       " 'user_reviewcount': 176,\n",
       " 'userID': 85413}"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_nu_dict = {}\n",
    "feat_nu_dict['locationId'] = num_locationId\n",
    "feat_nu_dict['createdDate'] = num_createdDate\n",
    "feat_nu_dict['photonum'] = num_photonum\n",
    "feat_nu_dict['rated_count'] = num_rated_count\n",
    "feat_nu_dict['average_photonum'] = num_average_photonum\n",
    "feat_nu_dict['average_rating'] = num_average_rating\n",
    "feat_nu_dict['user_mean_rating'] = num_users_mean_rating\n",
    "feat_nu_dict['user_reviewcount'] = num_user_reviewcount\n",
    "feat_nu_dict['userID'] = num_userID\n",
    "# feat_nu_dict['lw'] = num_lw\n",
    "feat_nu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8 #the number of embedding dim\n",
    "\n",
    "input_cols = []\n",
    "numeric_cols = []\n",
    "embed_col = []\n",
    "for col in NUMERIC_COLS:\n",
    "    in_neu = Input(shape=(1,), name=col)\t\t\t#None*1\n",
    "    input_cols.append(in_neu)\n",
    "#     cate_embedding = Embedding(feat_nu_dict[col], 1)(in_neu)\t#None*1*1\n",
    "#     in_embed = Embedding(feat_nu_dict[col], k, name = 'FM_'+col)(in_neu)\t\t#None*1*k\n",
    "    in_embed = RepeatVector(1, name='FM_'+col)(Dense(k)(in_neu))\t#None*1*k\n",
    "    numeric_cols.append(in_neu)\n",
    "    embed_col.append(in_embed)\n",
    "con_numeric = Concatenate(axis=1)(numeric_cols)\t\t#None*len(config.NUMERIC_COLS)\n",
    "dense_numeric = RepeatVector(1)(Dense(1)(con_numeric))\t#None*1*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first order\n",
    "y_first_order = dense_numeric #Concatenate(axis=1)([dense_numeric, con_cate]) \t\t#None*len*1\n",
    "y_first_order = MySumLayer(axis=1)(y_first_order)\t\t\t\t#None*1\t\n",
    "\n",
    "#second order\n",
    "emb = Concatenate(axis=1)(embed_col)\t\t\t\t\t\t#None*s*k\n",
    "\n",
    "summed_feature_emb = MySumLayer(axis=1)(emb)\t\t\t\t#None*k\n",
    "summed_feature_emb_squred = Multiply()([summed_feature_emb,summed_feature_emb])\t#None*k\n",
    "\n",
    "squared_feature_emb = Multiply()([emb,emb])\t\t\t\t\t#None*s*k\n",
    "squared_sum_feature_emb = MySumLayer(axis=1)(squared_feature_emb)\t#None*k\n",
    "\n",
    "sub = Subtract()([summed_feature_emb_squred,squared_sum_feature_emb])\t#None*k\n",
    "sub = Lambda(lambda x: x*0.5)(sub)\t\t\t\t\t\t#None*k\n",
    "y_second_order = MySumLayer(axis=1)(sub)\n",
    "\n",
    "#deep order\n",
    "y_deep = Flatten()(emb)\t\t\t\t\t\t\t\t#None*(s*k)\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(1,activation='relu')(y_deep))\t\t\t#None*1\n",
    "\n",
    "\n",
    "#deep fm\n",
    "y = Concatenate()([y_first_order,y_second_order,y_deep])\t\t\t#None*3\n",
    "y = Dense(1,activation='sigmoid')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 800\n",
    "batch_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(model_to_dot(model,show_shapes=True, show_layer_names=False).create(prog='dot', format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model_save_path = os.path.join(\"..\",\"..\",\"data\",\"model_weights\")\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "    \n",
    "model_path = os.path.join(model_save_path , 'local_deepFM_{epoch:02d}-{val_loss:.4f}.hdf5')\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', \n",
    "                                verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# earlystopping = EarlyStopping(monitor='val_loss', patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_cols, outputs=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-10\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=RMSprop(lr=lr), metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 193696 samples, validate on 974 samples\n",
      "Epoch 1/800\n",
      "193696/193696 [==============================] - 2s 9us/step - loss: 97.9182 - auc_30: 0.0000e+00 - val_loss: 18.4633 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.93828\n",
      "Epoch 2/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 97.6400 - auc_30: 0.0000e+00 - val_loss: 18.4626 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.93828\n",
      "Epoch 3/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 97.8015 - auc_30: 0.0000e+00 - val_loss: 18.4628 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.93828\n",
      "Epoch 4/800\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 97.8820 - auc_30: 0.0000e+00 - val_loss: 18.4621 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.93828\n",
      "Epoch 5/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 97.6853 - auc_30: 0.0000e+00 - val_loss: 18.4620 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.93828\n",
      "Epoch 6/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 98.2339 - auc_30: 0.0000e+00 - val_loss: 18.4622 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.93828\n",
      "Epoch 7/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 98.2749 - auc_30: 0.0000e+00 - val_loss: 18.4623 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.93828\n",
      "Epoch 8/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 95.9112 - auc_30: 0.0000e+00 - val_loss: 18.4614 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.93828\n",
      "Epoch 9/800\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 98.4733 - auc_30: 0.0000e+00 - val_loss: 18.4622 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.93828\n",
      "Epoch 10/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 96.8216 - auc_30: 0.0000e+00 - val_loss: 18.4620 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.93828\n",
      "Epoch 11/800\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 97.9351 - auc_30: 0.0000e+00 - val_loss: 18.4625 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.93828\n",
      "Epoch 12/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 97.9953 - auc_30: 0.0000e+00 - val_loss: 18.4619 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.93828\n",
      "Epoch 13/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 96.1809 - auc_30: 0.0000e+00 - val_loss: 18.4613 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.93828\n",
      "Epoch 14/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 98.0879 - auc_30: 0.0000e+00 - val_loss: 18.4616 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.93828\n",
      "Epoch 15/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 97.2901 - auc_30: 0.0000e+00 - val_loss: 18.4620 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.93828\n",
      "Epoch 16/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 96.3606 - auc_30: 0.0000e+00 - val_loss: 18.4614 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.93828\n",
      "Epoch 17/800\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 98.4809 - auc_30: 0.0000e+00 - val_loss: 18.4614 - val_auc_30: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.93828\n",
      "Epoch 18/800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-325-afcdf1848a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   encoded_average_photonum, encoded_average_rating], local_df['rating'], \n\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                    callbacks = [cb_checkpoint])\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                       encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating], local_df['rating'], \n",
    "          batch_size=batch_size, epochs=epochs, validation_split=0.005,\n",
    "                   callbacks = [cb_checkpoint])\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.legend() \n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유사도 아이템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_to_vec(feature, model, location_df, h_size, input_features):\n",
    "    layer_name = feature\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "    test = input_features\n",
    "                             \n",
    "    locationId_latent_vector = intermediate_layer_model.predict(test)\n",
    "    \n",
    "    locationId_latent_vector = locationId_latent_vector.T.reshape(-1, h_size)\n",
    "    vec = pd.DataFrame(locationId_latent_vector)\n",
    "    location_df = location_df.reset_index()\n",
    "    vec['locationId'] = location_df['locationId']\n",
    "    \n",
    "    # 아이템별 의미 벡터 생성 \n",
    "    vec = vec.groupby('locationId').agg([('0','mean')]).reset_index()\n",
    "\n",
    "    vec = pd.DataFrame(vec.iloc[:,1:].values)\n",
    "    vec['locationId'] = location_df['locationId'].unique()\n",
    "    vec = vec.set_index('locationId')\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locationId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011796922</th>\n",
       "      <td>-1591.948853</td>\n",
       "      <td>-1764.590576</td>\n",
       "      <td>-1764.605591</td>\n",
       "      <td>-1764.614502</td>\n",
       "      <td>-1764.626587</td>\n",
       "      <td>-1764.635620</td>\n",
       "      <td>-1764.647583</td>\n",
       "      <td>-1764.662598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37903636</th>\n",
       "      <td>-1213.981567</td>\n",
       "      <td>-1205.876709</td>\n",
       "      <td>-1180.816406</td>\n",
       "      <td>-1182.152954</td>\n",
       "      <td>-1181.658691</td>\n",
       "      <td>-1189.380737</td>\n",
       "      <td>-1165.646973</td>\n",
       "      <td>-1153.326416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13217405</th>\n",
       "      <td>-373.306152</td>\n",
       "      <td>-369.998199</td>\n",
       "      <td>-358.292908</td>\n",
       "      <td>-374.359711</td>\n",
       "      <td>-359.352814</td>\n",
       "      <td>-358.451721</td>\n",
       "      <td>-350.410065</td>\n",
       "      <td>-354.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20315170</th>\n",
       "      <td>-221.339493</td>\n",
       "      <td>-221.378540</td>\n",
       "      <td>-221.417603</td>\n",
       "      <td>-221.417603</td>\n",
       "      <td>-221.417603</td>\n",
       "      <td>-221.417603</td>\n",
       "      <td>-221.456665</td>\n",
       "      <td>-221.495712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20509127</th>\n",
       "      <td>-1486.157715</td>\n",
       "      <td>-2112.266846</td>\n",
       "      <td>-1654.587646</td>\n",
       "      <td>-2112.342041</td>\n",
       "      <td>-2112.384277</td>\n",
       "      <td>-2112.435303</td>\n",
       "      <td>-2112.480469</td>\n",
       "      <td>-2112.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129031</th>\n",
       "      <td>-6586.104980</td>\n",
       "      <td>-6644.750488</td>\n",
       "      <td>-6217.422852</td>\n",
       "      <td>-6566.066406</td>\n",
       "      <td>-6891.367676</td>\n",
       "      <td>-6929.129883</td>\n",
       "      <td>-6141.178223</td>\n",
       "      <td>-6470.263672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12816960</th>\n",
       "      <td>-3583.235840</td>\n",
       "      <td>-3098.814697</td>\n",
       "      <td>-3334.675293</td>\n",
       "      <td>-3141.650879</td>\n",
       "      <td>-3203.452393</td>\n",
       "      <td>-3658.818604</td>\n",
       "      <td>-3936.301025</td>\n",
       "      <td>-4152.042969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16656485</th>\n",
       "      <td>-3032.288574</td>\n",
       "      <td>-3026.968018</td>\n",
       "      <td>-3468.062012</td>\n",
       "      <td>-3216.107910</td>\n",
       "      <td>-3216.196045</td>\n",
       "      <td>-3248.051514</td>\n",
       "      <td>-3558.815186</td>\n",
       "      <td>-3505.575195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030185</th>\n",
       "      <td>-2310.744385</td>\n",
       "      <td>-1859.068237</td>\n",
       "      <td>-1783.842041</td>\n",
       "      <td>-1692.007690</td>\n",
       "      <td>-2262.783447</td>\n",
       "      <td>-2144.507812</td>\n",
       "      <td>-2292.930176</td>\n",
       "      <td>-2268.537354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9382578</th>\n",
       "      <td>-3983.697998</td>\n",
       "      <td>-4028.791016</td>\n",
       "      <td>-3983.839355</td>\n",
       "      <td>-3876.505859</td>\n",
       "      <td>-4122.409180</td>\n",
       "      <td>-3737.442139</td>\n",
       "      <td>-4122.533691</td>\n",
       "      <td>-4122.617188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5601 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1            2            3            4  \\\n",
       "locationId                                                                    \n",
       "1011796922 -1591.948853 -1764.590576 -1764.605591 -1764.614502 -1764.626587   \n",
       "37903636   -1213.981567 -1205.876709 -1180.816406 -1182.152954 -1181.658691   \n",
       "13217405    -373.306152  -369.998199  -358.292908  -374.359711  -359.352814   \n",
       "20315170    -221.339493  -221.378540  -221.417603  -221.417603  -221.417603   \n",
       "20509127   -1486.157715 -2112.266846 -1654.587646 -2112.342041 -2112.384277   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "9129031    -6586.104980 -6644.750488 -6217.422852 -6566.066406 -6891.367676   \n",
       "12816960   -3583.235840 -3098.814697 -3334.675293 -3141.650879 -3203.452393   \n",
       "16656485   -3032.288574 -3026.968018 -3468.062012 -3216.107910 -3216.196045   \n",
       "4030185    -2310.744385 -1859.068237 -1783.842041 -1692.007690 -2262.783447   \n",
       "9382578    -3983.697998 -4028.791016 -3983.839355 -3876.505859 -4122.409180   \n",
       "\n",
       "                      5            6            7  \n",
       "locationId                                         \n",
       "1011796922 -1764.635620 -1764.647583 -1764.662598  \n",
       "37903636   -1189.380737 -1165.646973 -1153.326416  \n",
       "13217405    -358.451721  -350.410065  -354.332031  \n",
       "20315170    -221.417603  -221.456665  -221.495712  \n",
       "20509127   -2112.435303 -2112.480469 -2112.531250  \n",
       "...                 ...          ...          ...  \n",
       "9129031    -6929.129883 -6141.178223 -6470.263672  \n",
       "12816960   -3658.818604 -3936.301025 -4152.042969  \n",
       "16656485   -3248.051514 -3558.815186 -3505.575195  \n",
       "4030185    -2144.507812 -2292.930176 -2268.537354  \n",
       "9382578    -3737.442139 -4122.533691 -4122.617188  \n",
       "\n",
       "[5601 rows x 8 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = latent_to_vec('FM_locationId', model, local_df, 8, [encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                        encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.to_csv(os.path.join(\"..\",\"realtime_model\",'deepFM_local_vec.csv'))#, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosim_id(df, vec, item_id):\n",
    "    def cos_sim(A, B):\n",
    "           return dot(A, B)/(norm(A)*norm(B)) \n",
    "    new_vec = vec.copy() \n",
    "    sim = []\n",
    "    \n",
    "    # 인풋 호텔 정보 데이터에 없는 경우 종료 \n",
    "    if item_id not in vec.index.tolist():\n",
    "        return \n",
    "        \n",
    "    for i in range(len(vec)):\n",
    "        sim.append(cos_sim(vec.loc[item_id,:], vec.iloc[i,:]))\n",
    "\n",
    "    new_vec['sim'] = sim\n",
    "    # sim 높은 순 \n",
    "    new_vec = new_vec['sim'].reset_index().sort_values('sim', ascending=False)\n",
    "    sim_sorted = new_vec['locationId'].tolist()\n",
    "    # 인풋 호텔정보 빼고 유사도 높은 순대로 id \n",
    "    if item_id in sim_sorted:\n",
    "        sim_sorted.remove(item_id) \n",
    "    return sim_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sim_item(vec, df, item_id, top):\n",
    "    top_id = cosim_id(df, vec, item_id)\n",
    "    \n",
    "    if type(top_id) == list :\n",
    "        df = df.drop_duplicates(['locationId'], keep='last')\n",
    "        recommend_rst = []\n",
    "        for x in top_id:\n",
    "            if df.loc[df['locationId']==x].category.values[0]== 'EAT':\n",
    "                recommend_rst.append([df.loc[df['locationId']==x][['place.name', 'land.addr']]])\n",
    "\n",
    "        print('input hotel:', local_df.loc[local_df['locationId']==item_id]['place.name'].unique()[0])\n",
    "        print('-'*10)\n",
    "        for i in range(len(recommend_rst[:top])):\n",
    "            print('top', i+1, recommend_rst[i][0]['place.name'].values[0])\n",
    "            print('  주소', recommend_rst[i][0]['land.addr'].values[0])\n",
    "        \n",
    "    else:\n",
    "        answer_lst = ['해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.', '해당 호텔 정보가 없습니다. 다른 호텔을 추천받아보세요.']\n",
    "        x = random.randint(0, len(answer_lst)-1)\n",
    "        return answer_lst[x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Conrad Seoul\n",
      "----------\n",
      "top 1 테이블스타\n",
      "  주소 서울특별시 강남구 신사동 545-22\n",
      "top 2 대동문\n",
      "  주소 서울특별시 영등포구 여의도동 35-2 백상빌딩\n",
      "top 3 Parmi Italiano\n",
      "  주소 error\n",
      "top 4 올레김밥\n",
      "  주소 서울특별시 송파구 잠실동 35-2 트리지움\n",
      "top 5 Jogaechon\n",
      "  주소 error\n",
      "top 6 슌미\n",
      "  주소 서울특별시 강남구 역삼동 603 노보텔 앰배서더 강남 서울\n",
      "top 7 초반식당\n",
      "  주소 서울 중구 수표로6길 8-1\n",
      "top 8 문립\n",
      "  주소 서울특별시 동대문구 이문동 305-59\n",
      "top 9 하늘빛우렁쌈밥\n",
      "  주소 서울특별시 광진구 구의동 234-9\n",
      "top 10 라운드오프\n",
      "  주소 서울 종로구 인사동5길 26\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 3477158, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item(vec, local_df, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis styles Ambassador Seoul Gangnam\n",
      "----------\n",
      "top 1 오양회참치\n",
      "  주소 서울특별시 중구 정동 2-1 오양수산빌딩\n",
      "top 2 삐싱궈\n",
      "  주소 서울특별시 강북구 미아동 54-138\n",
      "top 3 연남동질리\n",
      "  주소 서울특별시 마포구 연남동 390-24 j2빌딩\n",
      "top 4 찜닭상륙작전\n",
      "  주소 서울특별시 강남구 역삼동 637-36\n",
      "top 5 중화요리온\n",
      "  주소 서울특별시 양천구 목동 514-18 어바니엘\n",
      "top 6 백암왕순대\n",
      "  주소 서울특별시 송파구 방이동 206-3 삼영빌딩\n",
      "top 7 돈돼랑\n",
      "  주소 서울특별시 강서구 화곡동 1072-1\n",
      "top 8 돈짱\n",
      "  주소 서울특별시 강동구 길동 359-23\n",
      "top 9 오근내2닭구이&닭갈비\n",
      "  주소 서울특별시 용산구 한강로3가 40-9 용일빌딩\n",
      "top 10 케이크하우스밀레\n",
      "  주소 서울특별시 중랑구 중화동 288-27 차돌체육관\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 299533, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Best Western Premier Seoul Garden Hotel\n",
      "----------\n",
      "top 1 미추원주추어탕서울본점\n",
      "  주소 서울특별시 관악구 봉천동 1595-8\n",
      "top 2 빠리가옥\n",
      "  주소 서울특별시 종로구 익선동 166-26\n",
      "top 3 다담\n",
      "  주소 서울특별시 강남구 청담동 97-1 M빌딩\n",
      "top 4 깐부치킨 신사역점\n",
      "  주소 서울특별시 강남구 신사동 514-5\n",
      "top 5 스위트스페이스 현대시티아루렛동대문점\n",
      "  주소 서울특별시 중구 을지로6가 17-2 현대시티타워\n",
      "top 6 크앙분식 - 혜화본점\n",
      "  주소 서울특별시 종로구 연건동 195-38\n",
      "top 7 호치킨 창동역점\n",
      "  주소 서울특별시 도봉구 창동 75-13\n",
      "top 8 Guksuga\n",
      "  주소 서울특별시 중구 충무로5가 86-3\n",
      "top 9 인생닭강정\n",
      "  주소 서울특별시 성북구 동선동1가 85-97\n",
      "top 10 소피스티케이크\n",
      "  주소 서울특별시 마포구 서교동 396-54\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 299152, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis budget Ambassador Seoul Dongdaemun\n",
      "----------\n",
      "top 1 바나프레소 길동역점\n",
      "  주소 서울특별시 강동구 길동 366-5\n",
      "top 2 진대포\n",
      "  주소 서울특별시 용산구 갈월동 98-1\n",
      "top 3 충무로쭈꾸미불고기\n",
      "  주소 서울특별시 중구 필동1가 3-20\n",
      "top 4 마녀김밥 노들점\n",
      "  주소 서울특별시 용산구 이촌동 302-146\n",
      "top 5 홀리차우\n",
      "  주소 서울특별시 중구 명동1가 8-1\n",
      "top 6 스타벅스 쌍문역점\n",
      "  주소 서울특별시 도봉구 창동 659-5\n",
      "top 7 김밥천국\n",
      "  주소 서울특별시 마포구 망원동 395-4\n",
      "top 8 내고향횡성한우정육점식당\n",
      "  주소 서울특별시 송파구 방이동 66-3 석촌씨티빌딩\n",
      "top 9 가야랑\n",
      "  주소 서울특별시 용산구 이태원2동 239-4\n",
      "top 10 돈수작 건대점\n",
      "  주소 서울특별시 광진구 화양동 9-19\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 6998634, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Banyan Tree Club & Spa Seoul\n",
      "----------\n",
      "top 1 조아저씨김치찌개와막겹구이\n",
      "  주소 서울특별시 중구 서소문동 23\n",
      "top 2 탐앤탐스\n",
      "  주소 서울특별시 서초구 반포동 20-45 반포자이플라자\n",
      "top 3 황소고집\n",
      "  주소 서울특별시 종로구 관철동 11-11\n",
      "top 4 서울감자탕\n",
      "  주소 서울특별시 강동구 성내동 199-11\n",
      "top 5 써브웨이 상암DMC푸르지오시티점\n",
      "  주소 서울특별시 마포구 상암동 1596 상암DMC푸르지오시티, S-City\n",
      "top 6 밥이답이다 신촌세브란스병원점\n",
      "  주소 서울특별시 서대문구 신촌동 134 신촌세브란스병원\n",
      "top 7 모힝\n",
      "  주소 서울특별시 관악구 봉천동 1598-6\n",
      "top 8 푸주옥\n",
      "  주소 서울특별시 양천구 신정동 1290-2\n",
      "top 9 마포 갈매기\n",
      "  주소 서울특별시 마포구 도화동 194-8\n",
      "top 10 돈암동찌개\n",
      "  주소 서울특별시 강북구 수유동 191-66\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 1796658, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Grand InterContinental Seoul Parnas\n",
      "----------\n",
      "top 1 곳온니플레이스\n",
      "  주소 서울특별시 영등포구 여의도동 17 여의도더샵아일랜드파크\n",
      "top 2 풀향기\n",
      "  주소 서울특별시 용산구 한남동 726-54 풀향기(음식점)\n",
      "top 3 센터커피\n",
      "  주소 서울 성동구 서울숲2길 28-11 2층\n",
      "top 4 그랜드뮤즈\n",
      "  주소 서울특별시 용산구 한남동 726-419\n",
      "top 5 달구벌반점\n",
      "  주소 서울특별시 성동구 성수동2가 278-25\n",
      "top 6 정성본 샤브수끼 칼국수 강남역점\n",
      "  주소 서울특별시 서초구 서초동 1321-9 풍림아이원매직\n",
      "top 7 브릭하우스76\n",
      "  주소 서울특별시 은평구 역촌동 35-29\n",
      "top 8 장군갈비\n",
      "  주소 서울특별시 영등포구 문래동3가 55-5 로데오 왘 쇼핑몰\n",
      "top 9 담소소사골순대육개장 가산디지털점\n",
      "  주소 서울특별시 금천구 가산동 60-11 스타밸리\n",
      "top 10 평양냉면\n",
      "  주소 서울특별시 구로구 오류동 13-55\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 306118, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(column, df) :\n",
    "    \n",
    "    vocab = {}\n",
    "    num = 0\n",
    "\n",
    "    for i in df[column]: # np.hstack([train[column], test[column]]): \n",
    "        if vocab.get(i) != None:\n",
    "            continue\n",
    "\n",
    "        vocab[i] = num\n",
    "        num += 1\n",
    "\n",
    "    encoded = [vocab[i] for i in df[column]]\n",
    "    # encoded_d = [vocab[i] for i in test[column]]\n",
    "    \n",
    "    return encoded, num, vocab\n",
    "\n",
    "# continous\n",
    "encoded_locationId, num_locationId, vocab_locationId = get_data('locationId', global_df) \n",
    "encoded_createdDate,  num_createdDate, vocab_createdDate = get_data('createdDate', global_df) \n",
    "encoded_photonum,  num_photonum, vocab_photonum = get_data('photonum', global_df) \n",
    "encoded_rated_count,  num_rated_count, vocab_rated_count = get_data('rated_count', global_df) \n",
    "encoded_average_photonum,  num_average_photonum, vocab_average_photonum = get_data('average_photonum', global_df) \n",
    "encoded_average_rating,  num_average_rating, vocab_average_rating = get_data('average_rating', global_df) \n",
    "encoded_users_mean_rating, num_users_mean_rating, vocab_users_mean_rating = get_data('user_mean_rating', global_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', global_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', global_df) \n",
    "encoded_userID, num_userID, vocab_userID = get_data('userID', global_df) \n",
    "# encoded_lw,  num_lw, vocab_lw = get_data('lw', global_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locationId': 3180,\n",
       " 'createdDate': 4213,\n",
       " 'photonum': 38,\n",
       " 'rated_count': 174,\n",
       " 'average_photonum': 672,\n",
       " 'average_rating': 623,\n",
       " 'user_mean_rating': 4893,\n",
       " 'user_reviewcount': 73,\n",
       " 'userID': 57332}"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_nu_dict = {}\n",
    "feat_nu_dict['locationId'] = num_locationId\n",
    "feat_nu_dict['createdDate'] = num_createdDate\n",
    "feat_nu_dict['photonum'] = num_photonum\n",
    "feat_nu_dict['rated_count'] = num_rated_count\n",
    "feat_nu_dict['average_photonum'] = num_average_photonum\n",
    "feat_nu_dict['average_rating'] = num_average_rating\n",
    "feat_nu_dict['user_mean_rating'] = num_users_mean_rating\n",
    "feat_nu_dict['user_reviewcount'] = num_user_reviewcount\n",
    "feat_nu_dict['userID'] = num_userID\n",
    "# feat_nu_dict['lw'] = num_lw\n",
    "feat_nu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8 #the number of embedding dim\n",
    "\n",
    "input_cols = []\n",
    "numeric_cols = []\n",
    "embed_col = []\n",
    "for col in NUMERIC_COLS:\n",
    "    in_neu = Input(shape=(1,), name=col)\t\t\t#None*1\n",
    "    input_cols.append(in_neu)\n",
    "#     cate_embedding = Embedding(feat_nu_dict[col], 1)(in_neu)\t#None*1*1\n",
    "#     in_embed = Embedding(feat_nu_dict[col], k, name = 'FM_'+col)(in_neu)\t\t#None*1*k\n",
    "    in_embed = RepeatVector(1, name='FM_'+col)(Dense(k)(in_neu))\t#None*1*k\n",
    "    numeric_cols.append(in_neu)\n",
    "    embed_col.append(in_embed)\n",
    "con_numeric = Concatenate(axis=1)(numeric_cols)\t\t#None*len(config.NUMERIC_COLS)\n",
    "dense_numeric = RepeatVector(1)(Dense(1)(con_numeric))\t#None*1*1\n",
    "\n",
    "#first order\n",
    "y_first_order = dense_numeric #Concatenate(axis=1)([dense_numeric, con_cate]) \t\t#None*len*1\n",
    "y_first_order = MySumLayer(axis=1)(y_first_order)\t\t\t\t#None*1\t\n",
    "\n",
    "#second order\n",
    "emb = Concatenate(axis=1)(embed_col)\t\t\t\t\t\t#None*s*k\n",
    "\n",
    "summed_feature_emb = MySumLayer(axis=1)(emb)\t\t\t\t#None*k\n",
    "summed_feature_emb_squred = Multiply()([summed_feature_emb,summed_feature_emb])\t#None*k\n",
    "\n",
    "squared_feature_emb = Multiply()([emb,emb])\t\t\t\t\t#None*s*k\n",
    "squared_sum_feature_emb = MySumLayer(axis=1)(squared_feature_emb)\t#None*k\n",
    "\n",
    "sub = Subtract()([summed_feature_emb_squred,squared_sum_feature_emb])\t#None*k\n",
    "sub = Lambda(lambda x: x*0.5)(sub)\t\t\t\t\t\t#None*k\n",
    "y_second_order = MySumLayer(axis=1)(sub)\n",
    "\n",
    "#deep order\n",
    "y_deep = Flatten()(emb)\t\t\t\t\t\t\t\t#None*(s*k)\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(1,activation='relu')(y_deep))\n",
    "\n",
    "#deep fm\n",
    "y = Concatenate()([y_first_order,y_second_order,y_deep])\t\t\t#None*3\n",
    "y = Dense(1)(y)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "\n",
    "# lr = 1e-4\n",
    "# epochs = 300\n",
    "# batch_size = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(model_to_dot(model,show_shapes=True, show_layer_names=False).create(prog='dot', format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_save_path = os.path.join(\"..\",\"..\",\"data\",\"model_weights\")\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "    \n",
    "model_path = model_save_path+ 'global' + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_cols, outputs=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93253 samples, validate on 469 samples\n",
      "Epoch 1/300\n",
      "93253/93253 [==============================] - 1s 13us/step - loss: 162675.6250 - auc_35: 0.0000e+00 - val_loss: 1096486016.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 79587.86719\n",
      "Epoch 2/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 347692992.0000 - auc_35: 0.0000e+00 - val_loss: 1248089.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 79587.86719\n",
      "Epoch 3/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 161853.6094 - auc_35: 0.0000e+00 - val_loss: 1299931.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 79587.86719\n",
      "Epoch 4/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 149983.9062 - auc_35: 0.0000e+00 - val_loss: 1346990.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 79587.86719\n",
      "Epoch 5/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 142546.0312 - auc_35: 0.0000e+00 - val_loss: 1387742.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 79587.86719\n",
      "Epoch 6/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 137991.1094 - auc_35: 0.0000e+00 - val_loss: 1421573.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 79587.86719\n",
      "Epoch 7/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 135325.0312 - auc_35: 0.0000e+00 - val_loss: 1448582.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 79587.86719\n",
      "Epoch 8/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 133757.2812 - auc_35: 0.0000e+00 - val_loss: 1469464.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 79587.86719\n",
      "Epoch 9/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 132920.9844 - auc_35: 0.0000e+00 - val_loss: 1484955.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 79587.86719\n",
      "Epoch 10/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 132408.4375 - auc_35: 0.0000e+00 - val_loss: 1495990.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 79587.86719\n",
      "Epoch 11/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 132107.0938 - auc_35: 0.0000e+00 - val_loss: 1503387.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 79587.86719\n",
      "Epoch 12/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 131965.5156 - auc_35: 0.0000e+00 - val_loss: 1508133.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 79587.86719\n",
      "Epoch 13/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 131818.2969 - auc_35: 0.0000e+00 - val_loss: 1510801.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 79587.86719\n",
      "Epoch 14/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 131674.3906 - auc_35: 0.0000e+00 - val_loss: 1512046.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 79587.86719\n",
      "Epoch 15/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 131536.5938 - auc_35: 0.0000e+00 - val_loss: 1512300.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 79587.86719\n",
      "Epoch 16/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 131428.7656 - auc_35: 0.0000e+00 - val_loss: 1511798.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 79587.86719\n",
      "Epoch 17/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 131295.0469 - auc_35: 0.0000e+00 - val_loss: 1510786.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 79587.86719\n",
      "Epoch 18/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 131172.5938 - auc_35: 0.0000e+00 - val_loss: 1509514.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 79587.86719\n",
      "Epoch 19/300\n",
      "93253/93253 [==============================] - 1s 5us/step - loss: 131046.5703 - auc_35: 0.0000e+00 - val_loss: 1508093.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 79587.86719\n",
      "Epoch 20/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 130896.5703 - auc_35: 0.0000e+00 - val_loss: 1506440.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 79587.86719\n",
      "Epoch 21/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 130717.6328 - auc_35: 0.0000e+00 - val_loss: 1504637.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 79587.86719\n",
      "Epoch 22/300\n",
      "93253/93253 [==============================] - 1s 6us/step - loss: 130596.6406 - auc_35: 0.0000e+00 - val_loss: 1502744.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 79587.86719\n",
      "Epoch 23/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 130436.2266 - auc_35: 0.0000e+00 - val_loss: 1500689.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 79587.86719\n",
      "Epoch 24/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 130301.8594 - auc_35: 0.0000e+00 - val_loss: 1498584.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 79587.86719\n",
      "Epoch 25/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 130090.3125 - auc_35: 0.0000e+00 - val_loss: 1496423.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 79587.86719\n",
      "Epoch 26/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 129930.9531 - auc_35: 0.0000e+00 - val_loss: 1494084.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 79587.86719\n",
      "Epoch 27/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 129714.2578 - auc_35: 0.0000e+00 - val_loss: 1491675.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 79587.86719\n",
      "Epoch 28/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 129517.2500 - auc_35: 0.0000e+00 - val_loss: 1489184.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 79587.86719\n",
      "Epoch 29/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 129318.3203 - auc_35: 0.0000e+00 - val_loss: 1486546.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 79587.86719\n",
      "Epoch 30/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 129140.4219 - auc_35: 0.0000e+00 - val_loss: 1483727.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 79587.86719\n",
      "Epoch 31/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 128859.2891 - auc_35: 0.0000e+00 - val_loss: 1480880.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 79587.86719\n",
      "Epoch 32/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 128668.2969 - auc_35: 0.0000e+00 - val_loss: 1477842.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 79587.86719\n",
      "Epoch 33/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 128463.1641 - auc_35: 0.0000e+00 - val_loss: 1474605.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 79587.86719\n",
      "Epoch 34/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 128210.3594 - auc_35: 0.0000e+00 - val_loss: 1471325.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 79587.86719\n",
      "Epoch 35/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 127956.4297 - auc_35: 0.0000e+00 - val_loss: 1467783.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 79587.86719\n",
      "Epoch 36/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 127685.2188 - auc_35: 0.0000e+00 - val_loss: 1464220.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 79587.86719\n",
      "Epoch 37/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 127440.0703 - auc_35: 0.0000e+00 - val_loss: 1460398.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 79587.86719\n",
      "Epoch 38/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 127158.3594 - auc_35: 0.0000e+00 - val_loss: 1456607.8750 - val_auc_35: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss did not improve from 79587.86719\n",
      "Epoch 39/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 126892.6797 - auc_35: 0.0000e+00 - val_loss: 1452318.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 79587.86719\n",
      "Epoch 40/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 126586.1016 - auc_35: 0.0000e+00 - val_loss: 1448275.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 79587.86719\n",
      "Epoch 41/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 126299.8203 - auc_35: 0.0000e+00 - val_loss: 1443586.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 79587.86719\n",
      "Epoch 42/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 125972.6094 - auc_35: 0.0000e+00 - val_loss: 1439288.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 79587.86719\n",
      "Epoch 43/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 125682.2734 - auc_35: 0.0000e+00 - val_loss: 1434040.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 79587.86719\n",
      "Epoch 44/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 125352.4844 - auc_35: 0.0000e+00 - val_loss: 1429497.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 79587.86719\n",
      "Epoch 45/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 125022.6875 - auc_35: 0.0000e+00 - val_loss: 1423984.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 79587.86719\n",
      "Epoch 46/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 124665.0312 - auc_35: 0.0000e+00 - val_loss: 1419217.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 79587.86719\n",
      "Epoch 47/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 124300.7500 - auc_35: 0.0000e+00 - val_loss: 1412869.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 79587.86719\n",
      "Epoch 48/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 123957.8203 - auc_35: 0.0000e+00 - val_loss: 1408314.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 79587.86719\n",
      "Epoch 49/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 123563.8984 - auc_35: 0.0000e+00 - val_loss: 1400644.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 79587.86719\n",
      "Epoch 50/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 123228.3359 - auc_35: 0.0000e+00 - val_loss: 1397858.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 79587.86719\n",
      "Epoch 51/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 122802.0469 - auc_35: 0.0000e+00 - val_loss: 1385616.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 79587.86719\n",
      "Epoch 52/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 122378.6094 - auc_35: 0.0000e+00 - val_loss: 1392111.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 79587.86719\n",
      "Epoch 53/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 121982.2266 - auc_35: 0.0000e+00 - val_loss: 1356028.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 79587.86719\n",
      "Epoch 54/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 121655.5469 - auc_35: 0.0000e+00 - val_loss: 1424678.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 79587.86719\n",
      "Epoch 55/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 121883.0234 - auc_35: 0.0000e+00 - val_loss: 1231753.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 79587.86719\n",
      "Epoch 56/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 126449.3594 - auc_35: 0.0000e+00 - val_loss: 1888578.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 79587.86719\n",
      "Epoch 57/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 170389.9688 - auc_35: 0.0000e+00 - val_loss: 1093899.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 79587.86719\n",
      "Epoch 58/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 605219.0000 - auc_35: 0.0000e+00 - val_loss: 14783825.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 79587.86719\n",
      "Epoch 59/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 4415859.0000 - auc_35: 0.0000e+00 - val_loss: 11694434.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 79587.86719\n",
      "Epoch 60/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 7629481.0000 - auc_35: 0.0000e+00 - val_loss: 9448191.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 79587.86719\n",
      "Epoch 61/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2017580.1250 - auc_35: 0.0000e+00 - val_loss: 2060570.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 79587.86719\n",
      "Epoch 62/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1478560.5000 - auc_35: 0.0000e+00 - val_loss: 3871523.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 79587.86719\n",
      "Epoch 63/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1262765.5000 - auc_35: 0.0000e+00 - val_loss: 3594956.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 79587.86719\n",
      "Epoch 64/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1079330.8750 - auc_35: 0.0000e+00 - val_loss: 3906307.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 79587.86719\n",
      "Epoch 65/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 816478.5000 - auc_35: 0.0000e+00 - val_loss: 3733747.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 79587.86719\n",
      "Epoch 66/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 507316.0938 - auc_35: 0.0000e+00 - val_loss: 3298650.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 79587.86719\n",
      "Epoch 67/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 296948.7188 - auc_35: 0.0000e+00 - val_loss: 2610155.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 79587.86719\n",
      "Epoch 68/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 210921.1406 - auc_35: 0.0000e+00 - val_loss: 2185028.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 79587.86719\n",
      "Epoch 69/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 172091.0156 - auc_35: 0.0000e+00 - val_loss: 1956136.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 79587.86719\n",
      "Epoch 70/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 151006.6875 - auc_35: 0.0000e+00 - val_loss: 1750156.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 79587.86719\n",
      "Epoch 71/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 138509.8750 - auc_35: 0.0000e+00 - val_loss: 1698446.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 79587.86719\n",
      "Epoch 72/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 130688.5469 - auc_35: 0.0000e+00 - val_loss: 1451917.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 79587.86719\n",
      "Epoch 73/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 127800.9922 - auc_35: 0.0000e+00 - val_loss: 1831239.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 79587.86719\n",
      "Epoch 74/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 144382.8125 - auc_35: 0.0000e+00 - val_loss: 974821.0625 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 79587.86719\n",
      "Epoch 75/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 338455.7812 - auc_35: 0.0000e+00 - val_loss: 8718281.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 79587.86719\n",
      "Epoch 76/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2260941.5000 - auc_35: 0.0000e+00 - val_loss: 10216077.0000 - val_auc_35: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00076: val_loss did not improve from 79587.86719\n",
      "Epoch 77/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 5484878.0000 - auc_35: 0.0000e+00 - val_loss: 17331218.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 79587.86719\n",
      "Epoch 78/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 3170868.7500 - auc_35: 0.0000e+00 - val_loss: 5515100.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 79587.86719\n",
      "Epoch 79/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 3726164.2500 - auc_35: 0.0000e+00 - val_loss: 7666747.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 79587.86719\n",
      "Epoch 80/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1592363.6250 - auc_35: 0.0000e+00 - val_loss: 1324557.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 79587.86719\n",
      "Epoch 81/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1280019.7500 - auc_35: 0.0000e+00 - val_loss: 4229986.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 79587.86719\n",
      "Epoch 82/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 860065.6250 - auc_35: 0.0000e+00 - val_loss: 2289339.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 79587.86719\n",
      "Epoch 83/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 527376.6875 - auc_35: 0.0000e+00 - val_loss: 2881818.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 79587.86719\n",
      "Epoch 84/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 262515.0312 - auc_35: 0.0000e+00 - val_loss: 2010604.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 79587.86719\n",
      "Epoch 85/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 167792.1562 - auc_35: 0.0000e+00 - val_loss: 1730908.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 79587.86719\n",
      "Epoch 86/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 139119.6406 - auc_35: 0.0000e+00 - val_loss: 1473192.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 79587.86719\n",
      "Epoch 87/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 125946.8203 - auc_35: 0.0000e+00 - val_loss: 1500694.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 79587.86719\n",
      "Epoch 88/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 119929.4609 - auc_35: 0.0000e+00 - val_loss: 1132035.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 79587.86719\n",
      "Epoch 89/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 126529.9922 - auc_35: 0.0000e+00 - val_loss: 2070643.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 79587.86719\n",
      "Epoch 90/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 211646.1250 - auc_35: 0.0000e+00 - val_loss: 1175821.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 79587.86719\n",
      "Epoch 91/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 971080.5625 - auc_35: 0.0000e+00 - val_loss: 12974525.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 79587.86719\n",
      "Epoch 92/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 3556743.2500 - auc_35: 0.0000e+00 - val_loss: 10230699.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 79587.86719\n",
      "Epoch 93/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2747817.5000 - auc_35: 0.0000e+00 - val_loss: 11851003.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 79587.86719\n",
      "Epoch 94/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2151746.5000 - auc_35: 0.0000e+00 - val_loss: 2384752.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 79587.86719\n",
      "Epoch 95/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2158045.0000 - auc_35: 0.0000e+00 - val_loss: 6252147.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 79587.86719\n",
      "Epoch 96/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1024574.9375 - auc_35: 0.0000e+00 - val_loss: 1317671.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 79587.86719\n",
      "Epoch 97/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 565377.6875 - auc_35: 0.0000e+00 - val_loss: 2907984.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 79587.86719\n",
      "Epoch 98/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 255445.8906 - auc_35: 0.0000e+00 - val_loss: 1637941.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 79587.86719\n",
      "Epoch 99/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 158814.8125 - auc_35: 0.0000e+00 - val_loss: 1660099.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 79587.86719\n",
      "Epoch 100/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 135214.8594 - auc_35: 0.0000e+00 - val_loss: 1136094.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 79587.86719\n",
      "Epoch 101/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 132966.4688 - auc_35: 0.0000e+00 - val_loss: 1769747.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 79587.86719\n",
      "Epoch 102/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 162566.4219 - auc_35: 0.0000e+00 - val_loss: 747457.4375 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 79587.86719\n",
      "Epoch 103/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 354243.1562 - auc_35: 0.0000e+00 - val_loss: 5309898.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 79587.86719\n",
      "Epoch 104/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1146452.1250 - auc_35: 0.0000e+00 - val_loss: 3486746.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 79587.86719\n",
      "Epoch 105/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2434803.7500 - auc_35: 0.0000e+00 - val_loss: 13188260.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 79587.86719\n",
      "Epoch 106/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2068002.6250 - auc_35: 0.0000e+00 - val_loss: 3396426.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 79587.86719\n",
      "Epoch 107/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2819712.0000 - auc_35: 0.0000e+00 - val_loss: 14642757.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 79587.86719\n",
      "Epoch 108/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1660535.8750 - auc_35: 0.0000e+00 - val_loss: 590896.9375 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 79587.86719\n",
      "Epoch 109/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 172282.1562 - auc_35: 0.0000e+00 - val_loss: 2102144.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 79587.86719\n",
      "Epoch 110/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 299021.6250 - auc_35: 0.0000e+00 - val_loss: 826346.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 79587.86719\n",
      "Epoch 111/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 769392.6875 - auc_35: 0.0000e+00 - val_loss: 4882859.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 79587.86719\n",
      "Epoch 112/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 899470.3125 - auc_35: 0.0000e+00 - val_loss: 904726.8125 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 79587.86719\n",
      "Epoch 113/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 953737.9375 - auc_35: 0.0000e+00 - val_loss: 3873102.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 79587.86719\n",
      "Epoch 114/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93253/93253 [==============================] - 0s 4us/step - loss: 509361.3750 - auc_35: 0.0000e+00 - val_loss: 1111149.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 79587.86719\n",
      "Epoch 115/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 187993.5625 - auc_35: 0.0000e+00 - val_loss: 1842921.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 79587.86719\n",
      "Epoch 116/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 167644.3906 - auc_35: 0.0000e+00 - val_loss: 742951.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 79587.86719\n",
      "Epoch 117/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 219225.8750 - auc_35: 0.0000e+00 - val_loss: 2677749.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 79587.86719\n",
      "Epoch 118/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 362501.1562 - auc_35: 0.0000e+00 - val_loss: 887081.0625 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 79587.86719\n",
      "Epoch 119/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 912408.1875 - auc_35: 0.0000e+00 - val_loss: 6146855.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 79587.86719\n",
      "Epoch 120/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 689986.3125 - auc_35: 0.0000e+00 - val_loss: 680544.9375 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 79587.86719\n",
      "Epoch 121/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 456254.1562 - auc_35: 0.0000e+00 - val_loss: 3586998.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 79587.86719\n",
      "Epoch 122/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 450295.3125 - auc_35: 0.0000e+00 - val_loss: 710456.3125 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 79587.86719\n",
      "Epoch 123/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 687055.3125 - auc_35: 0.0000e+00 - val_loss: 4468335.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 79587.86719\n",
      "Epoch 124/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 435160.9375 - auc_35: 0.0000e+00 - val_loss: 557301.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 79587.86719\n",
      "Epoch 125/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 243108.7812 - auc_35: 0.0000e+00 - val_loss: 3672422.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 79587.86719\n",
      "Epoch 126/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 679417.9375 - auc_35: 0.0000e+00 - val_loss: 2746930.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 79587.86719\n",
      "Epoch 127/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1659658.6250 - auc_35: 0.0000e+00 - val_loss: 13547321.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 79587.86719\n",
      "Epoch 128/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2115211.0000 - auc_35: 0.0000e+00 - val_loss: 8125623.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 79587.86719\n",
      "Epoch 129/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 5569191.0000 - auc_35: 0.0000e+00 - val_loss: 47271208.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 79587.86719\n",
      "Epoch 130/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 6419424.5000 - auc_35: 0.0000e+00 - val_loss: 1138681.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 79587.86719\n",
      "Epoch 131/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1161679.1250 - auc_35: 0.0000e+00 - val_loss: 6856662.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 79587.86719\n",
      "Epoch 132/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1873574.1250 - auc_35: 0.0000e+00 - val_loss: 1847144.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 79587.86719\n",
      "Epoch 133/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1657939.0000 - auc_35: 0.0000e+00 - val_loss: 1170083.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 79587.86719\n",
      "Epoch 134/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 159759.2344 - auc_35: 0.0000e+00 - val_loss: 1157825.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 79587.86719\n",
      "Epoch 135/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 142564.0469 - auc_35: 0.0000e+00 - val_loss: 1102604.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 79587.86719\n",
      "Epoch 136/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 131465.5938 - auc_35: 0.0000e+00 - val_loss: 1049737.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 79587.86719\n",
      "Epoch 137/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 124186.1875 - auc_35: 0.0000e+00 - val_loss: 1009080.3125 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 79587.86719\n",
      "Epoch 138/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 117953.5391 - auc_35: 0.0000e+00 - val_loss: 978445.0625 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 79587.86719\n",
      "Epoch 139/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 114122.1562 - auc_35: 0.0000e+00 - val_loss: 954645.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 79587.86719\n",
      "Epoch 140/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 110663.7500 - auc_35: 0.0000e+00 - val_loss: 937276.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 79587.86719\n",
      "Epoch 141/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 108444.3281 - auc_35: 0.0000e+00 - val_loss: 917200.0625 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 79587.86719\n",
      "Epoch 142/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 106472.4375 - auc_35: 0.0000e+00 - val_loss: 908702.9375 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 79587.86719\n",
      "Epoch 143/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 104305.9609 - auc_35: 0.0000e+00 - val_loss: 894339.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 79587.86719\n",
      "Epoch 144/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 103082.1016 - auc_35: 0.0000e+00 - val_loss: 890786.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 79587.86719\n",
      "Epoch 145/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 100935.7188 - auc_35: 0.0000e+00 - val_loss: 878544.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 79587.86719\n",
      "Epoch 146/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 99678.6719 - auc_35: 0.0000e+00 - val_loss: 878496.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 79587.86719\n",
      "Epoch 147/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 98173.5391 - auc_35: 0.0000e+00 - val_loss: 864254.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 79587.86719\n",
      "Epoch 148/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 96775.4375 - auc_35: 0.0000e+00 - val_loss: 876855.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 79587.86719\n",
      "Epoch 149/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 96200.7734 - auc_35: 0.0000e+00 - val_loss: 831844.6875 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 79587.86719\n",
      "Epoch 150/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 95166.2656 - auc_35: 0.0000e+00 - val_loss: 919171.9375 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 79587.86719\n",
      "Epoch 151/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 95005.2344 - auc_35: 0.0000e+00 - val_loss: 710919.6875 - val_auc_35: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00151: val_loss did not improve from 79587.86719\n",
      "Epoch 152/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 98775.6094 - auc_35: 0.0000e+00 - val_loss: 1351446.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 79587.86719\n",
      "Epoch 153/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 135898.2344 - auc_35: 0.0000e+00 - val_loss: 429099.6562 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 79587.86719\n",
      "Epoch 154/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 438946.8125 - auc_35: 0.0000e+00 - val_loss: 7763749.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 79587.86719\n",
      "Epoch 155/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1807549.8750 - auc_35: 0.0000e+00 - val_loss: 15436688.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 79587.86719\n",
      "Epoch 156/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2944193.0000 - auc_35: 0.0000e+00 - val_loss: 12133057.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 79587.86719\n",
      "Epoch 157/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 1411668.0000 - auc_35: 0.0000e+00 - val_loss: 352080.0312 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 79587.86719\n",
      "Epoch 158/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 193575.5625 - auc_35: 0.0000e+00 - val_loss: 2369163.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 79587.86719\n",
      "Epoch 159/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 453059.0000 - auc_35: 0.0000e+00 - val_loss: 1282789.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 79587.86719\n",
      "Epoch 160/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1206243.7500 - auc_35: 0.0000e+00 - val_loss: 4968969.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 79587.86719\n",
      "Epoch 161/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 535463.3125 - auc_35: 0.0000e+00 - val_loss: 588686.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 79587.86719\n",
      "Epoch 162/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 154608.9844 - auc_35: 0.0000e+00 - val_loss: 1380072.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 79587.86719\n",
      "Epoch 163/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 139879.5938 - auc_35: 0.0000e+00 - val_loss: 507150.9062 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 79587.86719\n",
      "Epoch 164/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 163144.4219 - auc_35: 0.0000e+00 - val_loss: 1672554.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 79587.86719\n",
      "Epoch 165/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 194214.2500 - auc_35: 0.0000e+00 - val_loss: 409972.9375 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 79587.86719\n",
      "Epoch 166/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 333760.9062 - auc_35: 0.0000e+00 - val_loss: 2802611.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 79587.86719\n",
      "Epoch 167/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 370298.6875 - auc_35: 0.0000e+00 - val_loss: 484451.7812 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 79587.86719\n",
      "Epoch 168/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 526550.2500 - auc_35: 0.0000e+00 - val_loss: 3557040.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 79587.86719\n",
      "Epoch 169/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 351415.1562 - auc_35: 0.0000e+00 - val_loss: 381541.2812 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 79587.86719\n",
      "Epoch 170/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 197427.1719 - auc_35: 0.0000e+00 - val_loss: 2692239.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 79587.86719\n",
      "Epoch 171/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 464975.3125 - auc_35: 0.0000e+00 - val_loss: 1698552.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 79587.86719\n",
      "Epoch 172/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 1080533.3750 - auc_35: 0.0000e+00 - val_loss: 9482766.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 79587.86719\n",
      "Epoch 173/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 1259138.8750 - auc_35: 0.0000e+00 - val_loss: 3487759.2500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 79587.86719\n",
      "Epoch 174/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 2591247.2500 - auc_35: 0.0000e+00 - val_loss: 21918342.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 79587.86719\n",
      "Epoch 175/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 3319120.2500 - auc_35: 0.0000e+00 - val_loss: 685083.1250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 79587.86719\n",
      "Epoch 176/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 98830.6328 - auc_35: 0.0000e+00 - val_loss: 667780.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 79587.86719\n",
      "Epoch 177/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 97228.1797 - auc_35: 0.0000e+00 - val_loss: 685451.6875 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 79587.86719\n",
      "Epoch 178/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 95356.3281 - auc_35: 0.0000e+00 - val_loss: 672811.0625 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 79587.86719\n",
      "Epoch 179/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 93336.1328 - auc_35: 0.0000e+00 - val_loss: 690057.5000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 79587.86719\n",
      "Epoch 180/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 92497.5703 - auc_35: 0.0000e+00 - val_loss: 669791.3750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 79587.86719\n",
      "Epoch 181/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 91255.8203 - auc_35: 0.0000e+00 - val_loss: 695350.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 79587.86719\n",
      "Epoch 182/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 90114.4453 - auc_35: 0.0000e+00 - val_loss: 661642.5625 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 79587.86719\n",
      "Epoch 183/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 88792.7344 - auc_35: 0.0000e+00 - val_loss: 715414.5625 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 79587.86719\n",
      "Epoch 184/300\n",
      "93253/93253 [==============================] - 0s 4us/step - loss: 88035.2656 - auc_35: 0.0000e+00 - val_loss: 626688.8750 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 79587.86719\n",
      "Epoch 185/300\n",
      "93253/93253 [==============================] - 1s 6us/step - loss: 87919.0703 - auc_35: 0.0000e+00 - val_loss: 795668.6250 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 79587.86719\n",
      "Epoch 186/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 89565.8906 - auc_35: 0.0000e+00 - val_loss: 497753.0000 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 79587.86719\n",
      "Epoch 187/300\n",
      "93253/93253 [==============================] - 0s 5us/step - loss: 101477.8516 - auc_35: 0.0000e+00 - val_loss: 1302124.7500 - val_auc_35: 0.0000e+00\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 79587.86719\n",
      "Epoch 188/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-363-368aa5d665f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                   encoded_average_photonum, encoded_average_rating], global_df['rating'], \n\u001b[1;32m     12\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                    callbacks = [cb_checkpoint])\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# encoded_fch, encoded_category_l, encoded_lw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 184\u001b[0;31m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 300\n",
    "batch_size = 100000\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=RMSprop(lr=lr), metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit([encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                       encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating], global_df['rating'], \n",
    "          batch_size=batch_size, epochs=epochs, validation_split=0.005,\n",
    "                   callbacks = [cb_checkpoint])\n",
    "# encoded_fch, encoded_category_l, encoded_lw\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.legend() \n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유사도 아이템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_to_vec(feature, model, location_df, h_size, input_features):\n",
    "    layer_name = feature\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "    test = input_features\n",
    "                             \n",
    "    locationId_latent_vector = intermediate_layer_model.predict(test)\n",
    "    \n",
    "    locationId_latent_vector = locationId_latent_vector.T.reshape(-1, h_size)\n",
    "    vec = pd.DataFrame(locationId_latent_vector)\n",
    "    location_df = location_df.reset_index()\n",
    "    vec['locationId'] = location_df['locationId']\n",
    "    \n",
    "    # 아이템별 의미 벡터 생성 \n",
    "    vec = vec.groupby('locationId').agg([('0','mean')]).reset_index()\n",
    "\n",
    "    vec = pd.DataFrame(vec.iloc[:,1:].values)\n",
    "    vec['locationId'] = location_df['locationId'].unique()\n",
    "    vec = vec.set_index('locationId')\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locationId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788542</th>\n",
       "      <td>-1537.253174</td>\n",
       "      <td>-1537.266357</td>\n",
       "      <td>-1537.279541</td>\n",
       "      <td>-1537.314453</td>\n",
       "      <td>-1447.767334</td>\n",
       "      <td>-1447.767334</td>\n",
       "      <td>-1447.780518</td>\n",
       "      <td>-1447.780518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077917</th>\n",
       "      <td>-830.337341</td>\n",
       "      <td>-871.947632</td>\n",
       "      <td>-871.627380</td>\n",
       "      <td>-765.864197</td>\n",
       "      <td>-765.837524</td>\n",
       "      <td>-750.090576</td>\n",
       "      <td>-662.776184</td>\n",
       "      <td>-685.335754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732387</th>\n",
       "      <td>-1109.489136</td>\n",
       "      <td>-1388.345825</td>\n",
       "      <td>-1144.588257</td>\n",
       "      <td>-1388.380493</td>\n",
       "      <td>-1137.427734</td>\n",
       "      <td>-1388.411743</td>\n",
       "      <td>-1388.431519</td>\n",
       "      <td>-1388.451294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13833720</th>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977925</th>\n",
       "      <td>-804.521362</td>\n",
       "      <td>-1029.487427</td>\n",
       "      <td>-1029.499146</td>\n",
       "      <td>-1029.504883</td>\n",
       "      <td>-1029.516602</td>\n",
       "      <td>-1029.529663</td>\n",
       "      <td>-1029.542847</td>\n",
       "      <td>-1029.557495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597806</th>\n",
       "      <td>-148.596954</td>\n",
       "      <td>-153.404205</td>\n",
       "      <td>-153.406769</td>\n",
       "      <td>-35.644745</td>\n",
       "      <td>-153.408722</td>\n",
       "      <td>-153.411285</td>\n",
       "      <td>-148.605774</td>\n",
       "      <td>-200.125015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149130</th>\n",
       "      <td>-265.883179</td>\n",
       "      <td>-266.655426</td>\n",
       "      <td>-266.654724</td>\n",
       "      <td>-264.719025</td>\n",
       "      <td>-272.489685</td>\n",
       "      <td>-273.921692</td>\n",
       "      <td>-271.398651</td>\n",
       "      <td>-271.191956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595040</th>\n",
       "      <td>-184.902512</td>\n",
       "      <td>-172.722931</td>\n",
       "      <td>-172.722931</td>\n",
       "      <td>-172.728180</td>\n",
       "      <td>-172.728180</td>\n",
       "      <td>-172.726868</td>\n",
       "      <td>-223.797028</td>\n",
       "      <td>-172.732117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13369640</th>\n",
       "      <td>-539.402954</td>\n",
       "      <td>-539.408813</td>\n",
       "      <td>-543.603333</td>\n",
       "      <td>-548.325012</td>\n",
       "      <td>-601.862061</td>\n",
       "      <td>-601.862549</td>\n",
       "      <td>-601.864868</td>\n",
       "      <td>-601.870300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043495</th>\n",
       "      <td>-285.754547</td>\n",
       "      <td>-274.807343</td>\n",
       "      <td>-375.382904</td>\n",
       "      <td>-375.460602</td>\n",
       "      <td>-375.839478</td>\n",
       "      <td>-376.107117</td>\n",
       "      <td>-376.171600</td>\n",
       "      <td>-377.835449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15934 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1            2            3            4  \\\n",
       "locationId                                                                    \n",
       "788542     -1537.253174 -1537.266357 -1537.279541 -1537.314453 -1447.767334   \n",
       "4077917     -830.337341  -871.947632  -871.627380  -765.864197  -765.837524   \n",
       "9732387    -1109.489136 -1388.345825 -1144.588257 -1388.380493 -1137.427734   \n",
       "13833720    -385.016907  -385.016907  -385.016907  -385.016907  -385.016907   \n",
       "8977925     -804.521362 -1029.487427 -1029.499146 -1029.504883 -1029.516602   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "9597806     -148.596954  -153.404205  -153.406769   -35.644745  -153.408722   \n",
       "1149130     -265.883179  -266.655426  -266.654724  -264.719025  -272.489685   \n",
       "3595040     -184.902512  -172.722931  -172.722931  -172.728180  -172.728180   \n",
       "13369640    -539.402954  -539.408813  -543.603333  -548.325012  -601.862061   \n",
       "7043495     -285.754547  -274.807343  -375.382904  -375.460602  -375.839478   \n",
       "\n",
       "                      5            6            7  \n",
       "locationId                                         \n",
       "788542     -1447.767334 -1447.780518 -1447.780518  \n",
       "4077917     -750.090576  -662.776184  -685.335754  \n",
       "9732387    -1388.411743 -1388.431519 -1388.451294  \n",
       "13833720    -385.016907  -385.016907  -385.016907  \n",
       "8977925    -1029.529663 -1029.542847 -1029.557495  \n",
       "...                 ...          ...          ...  \n",
       "9597806     -153.411285  -148.605774  -200.125015  \n",
       "1149130     -273.921692  -271.398651  -271.191956  \n",
       "3595040     -172.726868  -223.797028  -172.732117  \n",
       "13369640    -601.862549  -601.864868  -601.870300  \n",
       "7043495     -376.107117  -376.171600  -377.835449  \n",
       "\n",
       "[15934 rows x 8 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = latent_to_vec('FM_locationId', model, global_df, 8, [encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                        encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.to_csv(os.path.join(\"..\",\"realtime_model\",'deepFM_global_vec.csv'))#, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosim_id(df, vec, item_id):\n",
    "    def cos_sim(A, B):\n",
    "           return dot(A, B)/(norm(A)*norm(B)) \n",
    "    new_vec = vec.copy() \n",
    "    sim = []\n",
    "    \n",
    "    # 인풋 호텔 정보 데이터에 없는 경우 종료 \n",
    "    if item_id not in vec.index.tolist():\n",
    "        return \n",
    "        \n",
    "    for i in range(len(vec)):\n",
    "        sim.append(cos_sim(vec.loc[item_id,:], vec.iloc[i,:]))\n",
    "\n",
    "    new_vec['sim'] = sim\n",
    "    # sim 높은 순 \n",
    "    new_vec = new_vec['sim'].reset_index().sort_values('sim', ascending=False)\n",
    "    sim_sorted = new_vec['locationId'].tolist()\n",
    "    # 인풋 호텔정보 빼고 유사도 높은 순대로 id \n",
    "    if item_id in sim_sorted:\n",
    "        sim_sorted.remove(item_id) \n",
    "    return sim_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sim_item(vec, df, item_id, top):\n",
    "    top_id = cosim_id(df, vec, item_id)\n",
    "    \n",
    "    if type(top_id) == list :\n",
    "        df = df.drop_duplicates(['locationId'], keep='last')\n",
    "        recommend_rst = []\n",
    "        for x in top_id:\n",
    "            if df.loc[df['locationId']==x].category.values[0]== 'EAT':\n",
    "                recommend_rst.append([df.loc[df['locationId']==x][['place.name', 'land.addr']]])\n",
    "\n",
    "        print('input hotel:', local_df.loc[local_df['locationId']==item_id]['place.name'].unique()[0])\n",
    "        print('-'*10)\n",
    "        for i in range(len(recommend_rst[:top])):\n",
    "            print('top', i+1, recommend_rst[i][0]['place.name'].values[0])\n",
    "            print('  주소', recommend_rst[i][0]['land.addr'].values[0])\n",
    "        \n",
    "    else:\n",
    "        answer_lst = ['해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.', '해당 호텔 정보가 없습니다. 다른 호텔을 추천받아보세요.']\n",
    "        x = random.randint(0, len(answer_lst)-1)\n",
    "        return answer_lst[x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Conrad Seoul\n",
      "----------\n",
      "top 1 김경애 떡방\n",
      "  주소 서울특별시 강남구 대치동 316 은마아파트\n",
      "top 2 오리올\n",
      "  주소 서울특별시 용산구 후암동 406-99\n",
      "top 3 블랑제리 더 플라자\n",
      "  주소 서울특별시 중구 태평로2가 23 더 플라자\n",
      "top 4 버거킹 센트럴시티점\n",
      "  주소 서울특별시 서초구 반포동 19-3 센트럴시티\n",
      "top 5 피자스쿨 신풍역점\n",
      "  주소 서울특별시 영등포구 신길동 3894\n",
      "top 6 라밥 노량진2호점\n",
      "  주소 서울특별시 동작구 노량진동 119-166\n",
      "top 7 영미네 곱창\n",
      "  주소 서울특별시 중구 황학동 1783\n",
      "top 8 삼미식당 홍대점\n",
      "  주소 서울특별시 마포구 서교동 347-24\n",
      "top 9 인생닭강정 장승백이점\n",
      "  주소 서울특별시 동작구 상도동 364-23\n",
      "top 10 성수동 대림창고\n",
      "  주소 서울특별시 성동구 성수동2가 322-32 대림창고\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, global_df, 3477158, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item(vec, global_df, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis styles Ambassador Seoul Gangnam\n",
      "----------\n",
      "top 1 감동식당\n",
      "  주소 서울특별시 노원구 상계동 434-49\n",
      "top 2 인하순대국\n",
      "  주소 서울특별시 서초구 서초동 1555-16\n",
      "top 3 라떼또뜨\n",
      "  주소 서울특별시 서초구 방배동 875-1\n",
      "top 4 상도늘보리 본점\n",
      "  주소 서울특별시 동작구 상도2동 367-6\n",
      "top 5 비파티세리\n",
      "  주소 서울특별시 강남구 신사동 546-17 인자빌딩\n",
      "top 6 매화반점\n",
      "  주소 서울특별시 광진구 자양4동 4-11\n",
      "top 7 등촌샤브칼국수\n",
      "  주소 서울특별시 송파구 문정동 76-3\n",
      "top 8 원조양평해장국직영점\n",
      "  주소 서울특별시 은평구 갈현동 460-18\n",
      "top 9 우리집김밥 서초점\n",
      "  주소 서울특별시 서초구 서초동 1330-11 금성상가\n",
      "top 10 일상밥상\n",
      "  주소 서울특별시 양천구 목동 905-22 목동트윈빌\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, global_df, 299533, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Best Western Premier Seoul Garden Hotel\n",
      "----------\n",
      "top 1 미추원주추어탕서울본점\n",
      "  주소 서울특별시 관악구 봉천동 1595-8\n",
      "top 2 빠리가옥\n",
      "  주소 서울특별시 종로구 익선동 166-26\n",
      "top 3 다담\n",
      "  주소 서울특별시 강남구 청담동 97-1 M빌딩\n",
      "top 4 깐부치킨 신사역점\n",
      "  주소 서울특별시 강남구 신사동 514-5\n",
      "top 5 스위트스페이스 현대시티아루렛동대문점\n",
      "  주소 서울특별시 중구 을지로6가 17-2 현대시티타워\n",
      "top 6 크앙분식 - 혜화본점\n",
      "  주소 서울특별시 종로구 연건동 195-38\n",
      "top 7 호치킨 창동역점\n",
      "  주소 서울특별시 도봉구 창동 75-13\n",
      "top 8 Guksuga\n",
      "  주소 서울특별시 중구 충무로5가 86-3\n",
      "top 9 인생닭강정\n",
      "  주소 서울특별시 성북구 동선동1가 85-97\n",
      "top 10 소피스티케이크\n",
      "  주소 서울특별시 마포구 서교동 396-54\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, global_df, 299152, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis budget Ambassador Seoul Dongdaemun\n",
      "----------\n",
      "top 1 바나프레소 길동역점\n",
      "  주소 서울특별시 강동구 길동 366-5\n",
      "top 2 진대포\n",
      "  주소 서울특별시 용산구 갈월동 98-1\n",
      "top 3 충무로쭈꾸미불고기\n",
      "  주소 서울특별시 중구 필동1가 3-20\n",
      "top 4 마녀김밥 노들점\n",
      "  주소 서울특별시 용산구 이촌동 302-146\n",
      "top 5 홀리차우\n",
      "  주소 서울특별시 중구 명동1가 8-1\n",
      "top 6 스타벅스 쌍문역점\n",
      "  주소 서울특별시 도봉구 창동 659-5\n",
      "top 7 김밥천국\n",
      "  주소 서울특별시 마포구 망원동 395-4\n",
      "top 8 내고향횡성한우정육점식당\n",
      "  주소 서울특별시 송파구 방이동 66-3 석촌씨티빌딩\n",
      "top 9 가야랑\n",
      "  주소 서울특별시 용산구 이태원2동 239-4\n",
      "top 10 돈수작 건대점\n",
      "  주소 서울특별시 광진구 화양동 9-19\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, global_df, 6998634, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Banyan Tree Club & Spa Seoul\n",
      "----------\n",
      "top 1 조아저씨김치찌개와막겹구이\n",
      "  주소 서울특별시 중구 서소문동 23\n",
      "top 2 탐앤탐스\n",
      "  주소 서울특별시 서초구 반포동 20-45 반포자이플라자\n",
      "top 3 황소고집\n",
      "  주소 서울특별시 종로구 관철동 11-11\n",
      "top 4 서울감자탕\n",
      "  주소 서울특별시 강동구 성내동 199-11\n",
      "top 5 써브웨이 상암DMC푸르지오시티점\n",
      "  주소 서울특별시 마포구 상암동 1596 상암DMC푸르지오시티, S-City\n",
      "top 6 밥이답이다 신촌세브란스병원점\n",
      "  주소 서울특별시 서대문구 신촌동 134 신촌세브란스병원\n",
      "top 7 모힝\n",
      "  주소 서울특별시 관악구 봉천동 1598-6\n",
      "top 8 푸주옥\n",
      "  주소 서울특별시 양천구 신정동 1290-2\n",
      "top 9 마포 갈매기\n",
      "  주소 서울특별시 마포구 도화동 194-8\n",
      "top 10 돈암동찌개\n",
      "  주소 서울특별시 강북구 수유동 191-66\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, global_df, 1796658, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Grand InterContinental Seoul Parnas\n",
      "----------\n",
      "top 1 곳온니플레이스\n",
      "  주소 서울특별시 영등포구 여의도동 17 여의도더샵아일랜드파크\n",
      "top 2 풀향기\n",
      "  주소 서울특별시 용산구 한남동 726-54 풀향기(음식점)\n",
      "top 3 센터커피\n",
      "  주소 서울 성동구 서울숲2길 28-11 2층\n",
      "top 4 그랜드뮤즈\n",
      "  주소 서울특별시 용산구 한남동 726-419\n",
      "top 5 달구벌반점\n",
      "  주소 서울특별시 성동구 성수동2가 278-25\n",
      "top 6 정성본 샤브수끼 칼국수 강남역점\n",
      "  주소 서울특별시 서초구 서초동 1321-9 풍림아이원매직\n",
      "top 7 브릭하우스76\n",
      "  주소 서울특별시 은평구 역촌동 35-29\n",
      "top 8 장군갈비\n",
      "  주소 서울특별시 영등포구 문래동3가 55-5 로데오 왘 쇼핑몰\n",
      "top 9 담소소사골순대육개장 가산디지털점\n",
      "  주소 서울특별시 금천구 가산동 60-11 스타밸리\n",
      "top 10 평양냉면\n",
      "  주소 서울특별시 구로구 오류동 13-55\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, global_df, 306118, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
