{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/busesese/DeepFM_Keras/blob/master/DeepFM/deepfm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.layers import Input, Dense, Embedding, Add, Concatenate, RepeatVector,Multiply,Subtract,Lambda,Dropout,Reshape,Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from mylayers import MySumLayer\n",
    "from keras.optimizers import Adam\n",
    "# import config\n",
    "from keras.metrics import binary_accuracy\n",
    "# from metrics import auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from keras.optimizers import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>place.name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>is_fch</th>\n",
       "      <th>photonum</th>\n",
       "      <th>is_local</th>\n",
       "      <th>rated_count</th>\n",
       "      <th>average_photonum</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>user_reviewcount</th>\n",
       "      <th>userID</th>\n",
       "      <th>category_l</th>\n",
       "      <th>land.addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20180314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>11</td>\n",
       "      <td>14256</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20171207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>722</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20161110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>30372</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20160611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2116</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>788542</td>\n",
       "      <td>마르코 폴로</td>\n",
       "      <td>EAT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20151204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.095238</td>\n",
       "      <td>42</td>\n",
       "      <td>3208</td>\n",
       "      <td>1</td>\n",
       "      <td>서울 강남구 삼성동 159-1 트레이드타워 52층</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationId place.name category  rating  createdDate  is_fch  photonum  \\\n",
       "0      788542     마르코 폴로      EAT     5.0     20180314       0         0   \n",
       "1      788542     마르코 폴로      EAT     4.0     20171207       0         0   \n",
       "2      788542     마르코 폴로      EAT     5.0     20161110       0         0   \n",
       "3      788542     마르코 폴로      EAT     3.0     20160611       0         0   \n",
       "4      788542     마르코 폴로      EAT     4.0     20151204       0         0   \n",
       "\n",
       "   is_local  rated_count  average_photonum  average_rating  user_mean_rating  \\\n",
       "0         1           20              0.05            3.95          4.363636   \n",
       "1         1           20              0.05            3.95          4.000000   \n",
       "2         0           20              0.05            3.95          5.000000   \n",
       "3         0           20              0.05            3.95          4.250000   \n",
       "4         1           20              0.05            3.95          4.095238   \n",
       "\n",
       "   user_reviewcount  userID  category_l                    land.addr  \n",
       "0                11   14256           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "1                 6     722           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "2                 1   30372           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "3                 4    2116           1  서울 강남구 삼성동 159-1 트레이드타워 52층  \n",
       "4                42    3208           1  서울 강남구 삼성동 159-1 트레이드타워 52층  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "import gc\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"..\",\"..\",\"data\",\"YN_final_df.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬 / 글로벌 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_df shape: (459903, 16) global_df shape : (93722, 16)\n"
     ]
    }
   ],
   "source": [
    "# 로컬 / 글로벌 데이터 분리\n",
    "local_df = df.loc[df['is_local']==1]\n",
    "global_df = df.loc[df['is_local']==0]\n",
    "print('local_df shape:',local_df.shape, 'global_df shape :',global_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553625, 16)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "체인을 빼도ㅍ성능 나빠.... \n",
    "차라리 장소의 다양성을 위해 + 글로벌 데이터 추천 결과가 좋으므로\n",
    "글로벌 데이터 추가해서 전체 중에서\n",
    "체인 및 손수 전처리 체인 제거\n",
    "'''\n",
    "\n",
    "local_df = df.copy()\n",
    "local_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57122, 16) (496503, 16)\n",
      "(237052, 16)\n",
      "1527\n",
      "41784\n",
      "42382\n",
      "237052\n",
      "194670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>place.name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>is_fch</th>\n",
       "      <th>photonum</th>\n",
       "      <th>is_local</th>\n",
       "      <th>rated_count</th>\n",
       "      <th>average_photonum</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>user_reviewcount</th>\n",
       "      <th>userID</th>\n",
       "      <th>category_l</th>\n",
       "      <th>land.addr</th>\n",
       "      <th>lw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81114</th>\n",
       "      <td>1011796922</td>\n",
       "      <td>호텔더디자이너스동대문</td>\n",
       "      <td>ACM</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20191216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.417995</td>\n",
       "      <td>105</td>\n",
       "      <td>42122</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 중구 쌍림동 266-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81115</th>\n",
       "      <td>37903636</td>\n",
       "      <td>아만티호텔서울</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>20190722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.417995</td>\n",
       "      <td>105</td>\n",
       "      <td>42122</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 월드컵북로 31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81155</th>\n",
       "      <td>13217405</td>\n",
       "      <td>코트야드 메리어트 서울 타임스퀘어</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>20190621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.270833</td>\n",
       "      <td>4.414649</td>\n",
       "      <td>40</td>\n",
       "      <td>101654</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 영등포구 영중로 15 타임스퀘어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81659</th>\n",
       "      <td>20315170</td>\n",
       "      <td>스탠포드호텔코리아</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>20191227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>4.395100</td>\n",
       "      <td>33</td>\n",
       "      <td>24205</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 상암동 1587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81660</th>\n",
       "      <td>20315170</td>\n",
       "      <td>스탠포드호텔코리아</td>\n",
       "      <td>ACM</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>20191209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>4.395100</td>\n",
       "      <td>33</td>\n",
       "      <td>24205</td>\n",
       "      <td>1</td>\n",
       "      <td>서울특별시 마포구 상암동 1587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       locationId          place.name category    rating  createdDate  is_fch  \\\n",
       "81114  1011796922         호텔더디자이너스동대문      ACM  5.000000     20191216       0   \n",
       "81115    37903636             아만티호텔서울      ACM  4.666667     20190722       0   \n",
       "81155    13217405  코트야드 메리어트 서울 타임스퀘어      ACM  4.270833     20190621       0   \n",
       "81659    20315170           스탠포드호텔코리아      ACM  4.184211     20191227       0   \n",
       "81660    20315170           스탠포드호텔코리아      ACM  4.184211     20191209       0   \n",
       "\n",
       "       photonum  is_local  rated_count  average_photonum  average_rating  \\\n",
       "81114         0         1            1               0.0        5.000000   \n",
       "81115         0         1            3               0.0        4.666667   \n",
       "81155         0         1           24               0.0        4.270833   \n",
       "81659         0         1           19               0.0        4.184211   \n",
       "81660         0         1           19               0.0        4.184211   \n",
       "\n",
       "       user_mean_rating  user_reviewcount  userID  category_l  \\\n",
       "81114          4.417995               105   42122           1   \n",
       "81115          4.417995               105   42122           1   \n",
       "81155          4.414649                40  101654           1   \n",
       "81659          4.395100                33   24205           1   \n",
       "81660          4.395100                33   24205           1   \n",
       "\n",
       "                     land.addr  lw  \n",
       "81114       서울특별시 중구 쌍림동 266-2   0  \n",
       "81115       서울특별시 마포구 월드컵북로 31   0  \n",
       "81155  서울특별시 영등포구 영중로 15 타임스퀘어   0  \n",
       "81659       서울특별시 마포구 상암동 1587   0  \n",
       "81660       서울특별시 마포구 상암동 1587   0  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_df_acm = local_df.loc[local_df['category'] == 'ACM']\n",
    "local_df_eat = local_df.loc[local_df['category'] == 'EAT']\n",
    "print(local_df_acm.shape, local_df_eat.shape)\n",
    "\n",
    "local_df_eat = local_df_eat.loc[local_df_eat['average_rating']>=local_df_eat['average_rating'].median()]\n",
    "local_df = pd.concat([local_df_acm, local_df_eat])\n",
    "\n",
    "# local이기에 global과 차이를 두기위해 최대한 의미없는 체인 제거 \n",
    "local_df = local_df.loc[local_df['is_fch']==0]\n",
    "print(local_df.shape)\n",
    "\n",
    "fch_lst = ['써브웨이', '던킨도너츠','노브랜드버거','바르다김선생',' 폴바셋',' 안동찜닭',' 속초코다리냉면',' 할매순대국&양선지해장국',' 노브랜드버거 남부터미널점','바르다김선생' ,'유가네','24시 중식당 취빈','매머드커피','압구정봉구비어','카페베네','쥬씨','피자스쿨','매머드익스프레스','김밥천국','한국맥도날드','메머드커피','신전떡볶이','어사또', '공차', '북촌손만두', '오징어세상' ,'사월에보리밥', '땡스브레드엔커피', '피자몰', '나주소나주곰탕', '새마을식당','싸다김밥', '교동짬뽕', '토마토김밥', '화화쿵주마라탕', '샐러데이즈', '더차이','뚜레쥬르','스쿨푸드','자연별곡','죠스떡볶이','국대떡볶이', '도쿄스테이크','이디야커피', '코스트코코리아양재점푸드코트', '불고기브라더스','알라딘중고서점카페','배스킨라빈스','할리스커피', '와플대학', '파리바게뜨공덕역사', '파리바게뜨','아웃백','설빙', '봉추찜닭', '하겐다즈','아라마크연세의료원종합관'\n",
    "]\n",
    "fch_idx = local_df[local_df['place.name'].apply(lambda x: any(i in x for i in fch_lst))].index.tolist()\n",
    "idx = local_df[local_df['place.name'].apply(lambda x: x[-1] == '점')].index.tolist()\n",
    "print(len(fch_idx))\n",
    "print(len(idx))\n",
    "\n",
    "for i in idx:\n",
    "    if i not in fch_idx:\n",
    "        fch_idx.append(i)\n",
    "        \n",
    "print(len(fch_idx))\n",
    "\n",
    "print(local_df.shape[0])\n",
    "local_df = local_df.drop(fch_idx)\n",
    "print(local_df.shape[0])\n",
    "\n",
    "local_df['lw'] = local_df['is_local'].apply(lambda x: 1 if x==0 else 0)\n",
    "local_df['lw'] = local_df['lw']*5\n",
    "local_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_df.to_csv(os.path.join(\"..\",\"realtime_model\",'local_df.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['locationId', 'place.name', 'category', 'rating', 'createdDate',\n",
       "       'is_fch', 'photonum', 'is_local', 'rated_count', 'average_photonum',\n",
       "       'average_rating', 'user_mean_rating', 'user_reviewcount', 'userID',\n",
       "       'category_l', 'land.addr', 'lw'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSTATE = 2018\n",
    "\n",
    "NUMERIC_COLS=[\n",
    "    'locationId',  'createdDate',\n",
    "    'photonum', 'rated_count', 'average_photonum',\n",
    "    'average_rating', 'user_mean_rating', 'user_reviewcount',\n",
    "    'userID'] #,'lw'\n",
    "\n",
    "\n",
    "IGNORE_COLS = [\"place.name\", \"land.addr\", 'rating','is_fch', 'category_l','lw']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(column, df) :\n",
    "    \n",
    "    vocab = {}\n",
    "    num = 0\n",
    "\n",
    "    for i in df[column]: # np.hstack([train[column], test[column]]): \n",
    "        if vocab.get(i) != None:\n",
    "            continue\n",
    "\n",
    "        vocab[i] = num\n",
    "        num += 1\n",
    "\n",
    "    encoded = [vocab[i] for i in df[column]]\n",
    "    # encoded_d = [vocab[i] for i in test[column]]\n",
    "    \n",
    "    return encoded, num, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continous\n",
    "encoded_locationId, num_locationId, vocab_locationId = get_data('locationId', local_df) \n",
    "encoded_createdDate,  num_createdDate, vocab_createdDate = get_data('createdDate', local_df) \n",
    "encoded_photonum,  num_photonum, vocab_photonum = get_data('photonum', local_df) \n",
    "encoded_rated_count,  num_rated_count, vocab_rated_count = get_data('rated_count', local_df) \n",
    "encoded_average_photonum,  num_average_photonum, vocab_average_photonum = get_data('average_photonum', local_df) \n",
    "encoded_average_rating,  num_average_rating, vocab_average_rating = get_data('average_rating', local_df) \n",
    "encoded_users_mean_rating, num_users_mean_rating, vocab_users_mean_rating = get_data('user_mean_rating', local_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', local_df) \n",
    "encoded_user_reviewcount,  num_user_reviewcount, vocab_user_reviewcount = get_data('user_reviewcount', local_df) \n",
    "encoded_userID, num_userID, vocab_userID = get_data('userID', local_df) \n",
    "# encoded_lw,  num_lw, vocab_lw = get_data('lw', local_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locationId': 5601,\n",
       " 'createdDate': 4238,\n",
       " 'photonum': 39,\n",
       " 'rated_count': 226,\n",
       " 'average_photonum': 1084,\n",
       " 'average_rating': 1646,\n",
       " 'user_mean_rating': 30961,\n",
       " 'user_reviewcount': 176,\n",
       " 'userID': 85413}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_nu_dict = {}\n",
    "feat_nu_dict['locationId'] = num_locationId\n",
    "feat_nu_dict['createdDate'] = num_createdDate\n",
    "feat_nu_dict['photonum'] = num_photonum\n",
    "feat_nu_dict['rated_count'] = num_rated_count\n",
    "feat_nu_dict['average_photonum'] = num_average_photonum\n",
    "feat_nu_dict['average_rating'] = num_average_rating\n",
    "feat_nu_dict['user_mean_rating'] = num_users_mean_rating\n",
    "feat_nu_dict['user_reviewcount'] = num_user_reviewcount\n",
    "feat_nu_dict['userID'] = num_userID\n",
    "# feat_nu_dict['lw'] = num_lw\n",
    "feat_nu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8 #the number of embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = []\n",
    "numeric_cols = []\n",
    "embed_col = []\n",
    "for col in NUMERIC_COLS:\n",
    "    in_neu = Input(shape=(1,), name=col)\t\t\t#None*1\n",
    "    input_cols.append(in_neu)\n",
    "#     cate_embedding = Embedding(feat_nu_dict[col], 1)(in_neu)\t#None*1*1\n",
    "#     in_embed = Embedding(feat_nu_dict[col], k, name = 'FM_'+col)(in_neu)\t\t#None*1*k\n",
    "    in_embed = RepeatVector(1, name='FM_'+col)(Dense(k)(in_neu))\t#None*1*k\n",
    "    numeric_cols.append(in_neu)\n",
    "    embed_col.append(in_embed)\n",
    "con_numeric = Concatenate(axis=1)(numeric_cols)\t\t#None*len(config.NUMERIC_COLS)\n",
    "dense_numeric = RepeatVector(1)(Dense(1)(con_numeric))\t#None*1*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first order\n",
    "y_first_order = dense_numeric #Concatenate(axis=1)([dense_numeric, con_cate]) \t\t#None*len*1\n",
    "y_first_order = MySumLayer(axis=1)(y_first_order)\t\t\t\t#None*1\t\n",
    "\n",
    "#second order\n",
    "emb = Concatenate(axis=1)(embed_col)\t\t\t\t\t\t#None*s*k\n",
    "\n",
    "summed_feature_emb = MySumLayer(axis=1)(emb)\t\t\t\t#None*k\n",
    "summed_feature_emb_squred = Multiply()([summed_feature_emb,summed_feature_emb])\t#None*k\n",
    "\n",
    "squared_feature_emb = Multiply()([emb,emb])\t\t\t\t\t#None*s*k\n",
    "squared_sum_feature_emb = MySumLayer(axis=1)(squared_feature_emb)\t#None*k\n",
    "\n",
    "sub = Subtract()([summed_feature_emb_squred,squared_sum_feature_emb])\t#None*k\n",
    "sub = Lambda(lambda x: x*0.5)(sub)\t\t\t\t\t\t#None*k\n",
    "y_second_order = MySumLayer(axis=1)(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep order\n",
    "y_deep = Flatten()(emb)\t\t\t\t\t\t\t\t#None*(s*k)\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(32,activation='relu')(y_deep))\t\t\t#None*32\n",
    "y_deep = Dropout(0.5)(Dense(1,activation='relu')(y_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep fm\n",
    "y = Concatenate()([y_first_order,y_second_order,y_deep])\t\t\t#None*3\n",
    "y = Dense(1)(y)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "\n",
    "lr = 1e-1\n",
    "epochs = 300\n",
    "batch_size = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(model_to_dot(model,show_shapes=True, show_layer_names=False).create(prog='dot', format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_save_path = os.path.join('..',\"model_weights\")\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "    \n",
    "model_path = model_save_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 193696 samples, validate on 974 samples\n",
      "Epoch 1/144\n",
      "193696/193696 [==============================] - 2s 8us/step - loss: 1508511851562928.0000 - auc_23: 0.0000e+00 - val_loss: 22846017372160.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 22846017372160.00000, saving model to ../model_weights01-22846017372160.0000.hdf5\n",
      "Epoch 2/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 53745450694752.4297 - auc_23: 0.0000e+00 - val_loss: 14908414492672.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 22846017372160.00000 to 14908414492672.00000, saving model to ../model_weights02-14908414492672.0000.hdf5\n",
      "Epoch 3/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 7210257576161.3379 - auc_23: 0.0000e+00 - val_loss: 21642048700416.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 14908414492672.00000\n",
      "Epoch 4/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 3843444341392.7266 - auc_23: 0.0000e+00 - val_loss: 20851839729664.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 14908414492672.00000\n",
      "Epoch 5/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 3272022412044.5610 - auc_23: 0.0000e+00 - val_loss: 18391681204224.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 14908414492672.00000\n",
      "Epoch 6/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 2843460463869.2510 - auc_23: 0.0000e+00 - val_loss: 15737669287936.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 14908414492672.00000\n",
      "Epoch 7/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 2435937634545.9165 - auc_23: 0.0000e+00 - val_loss: 13134091780096.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 14908414492672.00000 to 13134091780096.00000, saving model to ../model_weights07-13134091780096.0000.hdf5\n",
      "Epoch 8/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2062006765043.9043 - auc_23: 0.0000e+00 - val_loss: 10677960835072.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 13134091780096.00000 to 10677960835072.00000, saving model to ../model_weights08-10677960835072.0000.hdf5\n",
      "Epoch 9/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1717317384196.3984 - auc_23: 0.0000e+00 - val_loss: 8416400506880.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 10677960835072.00000 to 8416400506880.00000, saving model to ../model_weights09-8416400506880.0000.hdf5\n",
      "Epoch 10/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1421352991041.0889 - auc_23: 0.0000e+00 - val_loss: 6522746175488.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 8416400506880.00000 to 6522746175488.00000, saving model to ../model_weights10-6522746175488.0000.hdf5\n",
      "Epoch 11/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1175390388851.9675 - auc_23: 0.0000e+00 - val_loss: 5023857639424.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss improved from 6522746175488.00000 to 5023857639424.00000, saving model to ../model_weights11-5023857639424.0000.hdf5\n",
      "Epoch 12/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 975511874797.0104 - auc_23: 0.0000e+00 - val_loss: 3555791470592.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss improved from 5023857639424.00000 to 3555791470592.00000, saving model to ../model_weights12-3555791470592.0000.hdf5\n",
      "Epoch 13/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1984336880315.6965 - auc_23: 0.0000e+00 - val_loss: 19728324100096.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3555791470592.00000\n",
      "Epoch 14/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 14311929415407.6328 - auc_23: 0.0000e+00 - val_loss: 1267794313216.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss improved from 3555791470592.00000 to 1267794313216.00000, saving model to ../model_weights14-1267794313216.0000.hdf5\n",
      "Epoch 15/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 319024442802.6036 - auc_23: 0.0000e+00 - val_loss: 1150997364736.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 1267794313216.00000 to 1150997364736.00000, saving model to ../model_weights15-1150997364736.0000.hdf5\n",
      "Epoch 16/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 289181096945.9587 - auc_23: 0.0000e+00 - val_loss: 1001127870464.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 1150997364736.00000 to 1001127870464.00000, saving model to ../model_weights16-1001127870464.0000.hdf5\n",
      "Epoch 17/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 256836872151.0603 - auc_23: 0.0000e+00 - val_loss: 832509575168.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss improved from 1001127870464.00000 to 832509575168.00000, saving model to ../model_weights17-832509575168.0000.hdf5\n",
      "Epoch 18/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 226964039373.7981 - auc_23: 0.0000e+00 - val_loss: 897085341696.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 832509575168.00000\n",
      "Epoch 19/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2056621031115.4297 - auc_23: 0.0000e+00 - val_loss: 899506503680.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 832509575168.00000\n",
      "Epoch 20/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 715723858085.1122 - auc_23: 0.0000e+00 - val_loss: 113067311104.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss improved from 832509575168.00000 to 113067311104.00000, saving model to ../model_weights20-113067311104.0000.hdf5\n",
      "Epoch 21/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 33019521081.5186 - auc_23: 0.0000e+00 - val_loss: 101108940800.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss improved from 113067311104.00000 to 101108940800.00000, saving model to ../model_weights21-101108940800.0000.hdf5\n",
      "Epoch 22/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 29459871025.0177 - auc_23: 0.0000e+00 - val_loss: 88463867904.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss improved from 101108940800.00000 to 88463867904.00000, saving model to ../model_weights22-88463867904.0000.hdf5\n",
      "Epoch 23/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 25519191441.7842 - auc_23: 0.0000e+00 - val_loss: 75274297344.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss improved from 88463867904.00000 to 75274297344.00000, saving model to ../model_weights23-75274297344.0000.hdf5\n",
      "Epoch 24/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 21478552577.1842 - auc_23: 0.0000e+00 - val_loss: 61196128256.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss improved from 75274297344.00000 to 61196128256.00000, saving model to ../model_weights24-61196128256.0000.hdf5\n",
      "Epoch 25/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 17414554236.2571 - auc_23: 0.0000e+00 - val_loss: 47625416704.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss improved from 61196128256.00000 to 47625416704.00000, saving model to ../model_weights25-47625416704.0000.hdf5\n",
      "Epoch 26/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 13524814235.9346 - auc_23: 0.0000e+00 - val_loss: 35216236544.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss improved from 47625416704.00000 to 35216236544.00000, saving model to ../model_weights26-35216236544.0000.hdf5\n",
      "Epoch 27/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 9977645936.7111 - auc_23: 0.0000e+00 - val_loss: 25049829376.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss improved from 35216236544.00000 to 25049829376.00000, saving model to ../model_weights27-25049829376.0000.hdf5\n",
      "Epoch 28/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 6969956341.5113 - auc_23: 0.0000e+00 - val_loss: 16364756992.0000 - val_auc_23: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss improved from 25049829376.00000 to 16364756992.00000, saving model to ../model_weights28-16364756992.0000.hdf5\n",
      "Epoch 29/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4556370233.5609 - auc_23: 0.0000e+00 - val_loss: 9806779392.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss improved from 16364756992.00000 to 9806779392.00000, saving model to ../model_weights29-9806779392.0000.hdf5\n",
      "Epoch 30/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 2731080793.7882 - auc_23: 0.0000e+00 - val_loss: 5046660608.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss improved from 9806779392.00000 to 5046660608.00000, saving model to ../model_weights30-5046660608.0000.hdf5\n",
      "Epoch 31/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1481359419.3160 - auc_23: 0.0000e+00 - val_loss: 2150200064.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss improved from 5046660608.00000 to 2150200064.00000, saving model to ../model_weights31-2150200064.0000.hdf5\n",
      "Epoch 32/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 743026092.3549 - auc_23: 0.0000e+00 - val_loss: 809860032.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss improved from 2150200064.00000 to 809860032.00000, saving model to ../model_weights32-809860032.0000.hdf5\n",
      "Epoch 33/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 379482026.0816 - auc_23: 0.0000e+00 - val_loss: 368291488.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss improved from 809860032.00000 to 368291488.00000, saving model to ../model_weights33-368291488.0000.hdf5\n",
      "Epoch 34/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 231584846.0783 - auc_23: 0.0000e+00 - val_loss: 233155856.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss improved from 368291488.00000 to 233155856.00000, saving model to ../model_weights34-233155856.0000.hdf5\n",
      "Epoch 35/144\n",
      "193696/193696 [==============================] - 1s 6us/step - loss: 168948298.3830 - auc_23: 0.0000e+00 - val_loss: 189092832.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss improved from 233155856.00000 to 189092832.00000, saving model to ../model_weights35-189092832.0000.hdf5\n",
      "Epoch 36/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 134068465.7961 - auc_23: 0.0000e+00 - val_loss: 152459344.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss improved from 189092832.00000 to 152459344.00000, saving model to ../model_weights36-152459344.0000.hdf5\n",
      "Epoch 37/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 107813527.6683 - auc_23: 0.0000e+00 - val_loss: 153184304.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 152459344.00000\n",
      "Epoch 38/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 104654399.9868 - auc_23: 0.0000e+00 - val_loss: 359724000.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 152459344.00000\n",
      "Epoch 39/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 328022572.2914 - auc_23: 0.0000e+00 - val_loss: 119151720.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss improved from 152459344.00000 to 119151720.00000, saving model to ../model_weights39-119151720.0000.hdf5\n",
      "Epoch 40/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 85382077.7604 - auc_23: 0.0000e+00 - val_loss: 70107288.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss improved from 119151720.00000 to 70107288.00000, saving model to ../model_weights40-70107288.0000.hdf5\n",
      "Epoch 41/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 53297354.2686 - auc_23: 0.0000e+00 - val_loss: 168318640.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 70107288.00000\n",
      "Epoch 42/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 379473923.6253 - auc_23: 0.0000e+00 - val_loss: 349502368.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 70107288.00000\n",
      "Epoch 43/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 56159302.1285 - auc_23: 0.0000e+00 - val_loss: 96096056.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 70107288.00000\n",
      "Epoch 44/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 163037586.6195 - auc_23: 0.0000e+00 - val_loss: 15176803328.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 70107288.00000\n",
      "Epoch 45/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 3068118806753.6758 - auc_23: 0.0000e+00 - val_loss: 13198998528.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 70107288.00000\n",
      "Epoch 46/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 17600176014.9929 - auc_23: 0.0000e+00 - val_loss: 3816303616.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 70107288.00000\n",
      "Epoch 47/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 8260008578.1781 - auc_23: 0.0000e+00 - val_loss: 2375726336.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 70107288.00000\n",
      "Epoch 48/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4795161129.2358 - auc_23: 0.0000e+00 - val_loss: 2064434432.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 70107288.00000\n",
      "Epoch 49/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2871584491.1918 - auc_23: 0.0000e+00 - val_loss: 1726897152.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 70107288.00000\n",
      "Epoch 50/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1867044181.6223 - auc_23: 0.0000e+00 - val_loss: 1525308032.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 70107288.00000\n",
      "Epoch 51/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1256424591.4475 - auc_23: 0.0000e+00 - val_loss: 1452400128.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 70107288.00000\n",
      "Epoch 52/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 815492160.7824 - auc_23: 0.0000e+00 - val_loss: 1475395840.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 70107288.00000\n",
      "Epoch 53/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 552401180.2518 - auc_23: 0.0000e+00 - val_loss: 1328236544.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 70107288.00000\n",
      "Epoch 54/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 402355421.0712 - auc_23: 0.0000e+00 - val_loss: 1099307904.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 70107288.00000\n",
      "Epoch 55/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 299914908.4527 - auc_23: 0.0000e+00 - val_loss: 870502720.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 70107288.00000\n",
      "Epoch 56/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 223029514.8032 - auc_23: 0.0000e+00 - val_loss: 646289408.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 70107288.00000\n",
      "Epoch 57/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 161741140.6311 - auc_23: 0.0000e+00 - val_loss: 453607712.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 70107288.00000\n",
      "Epoch 58/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 111046417.9085 - auc_23: 0.0000e+00 - val_loss: 297813984.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 70107288.00000\n",
      "Epoch 59/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 73152222.6671 - auc_23: 0.0000e+00 - val_loss: 180148592.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 70107288.00000\n",
      "Epoch 60/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 46448403.2480 - auc_23: 0.0000e+00 - val_loss: 103283192.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 70107288.00000\n",
      "Epoch 61/144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193696/193696 [==============================] - 1s 4us/step - loss: 28635203.9141 - auc_23: 0.0000e+00 - val_loss: 57202292.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss improved from 70107288.00000 to 57202292.00000, saving model to ../model_weights61-57202292.0000.hdf5\n",
      "Epoch 62/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 18060934.1669 - auc_23: 0.0000e+00 - val_loss: 35158728.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss improved from 57202292.00000 to 35158728.00000, saving model to ../model_weights62-35158728.0000.hdf5\n",
      "Epoch 63/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 12160709.2911 - auc_23: 0.0000e+00 - val_loss: 24910534.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss improved from 35158728.00000 to 24910534.00000, saving model to ../model_weights63-24910534.0000.hdf5\n",
      "Epoch 64/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 8570349.2155 - auc_23: 0.0000e+00 - val_loss: 20630420.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss improved from 24910534.00000 to 20630420.00000, saving model to ../model_weights64-20630420.0000.hdf5\n",
      "Epoch 65/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 6240775.1967 - auc_23: 0.0000e+00 - val_loss: 18501710.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss improved from 20630420.00000 to 18501710.00000, saving model to ../model_weights65-18501710.0000.hdf5\n",
      "Epoch 66/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 4560975.0787 - auc_23: 0.0000e+00 - val_loss: 15242133.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss improved from 18501710.00000 to 15242133.00000, saving model to ../model_weights66-15242133.0000.hdf5\n",
      "Epoch 67/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2917988.0309 - auc_23: 0.0000e+00 - val_loss: 13238968.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss improved from 15242133.00000 to 13238968.00000, saving model to ../model_weights67-13238968.0000.hdf5\n",
      "Epoch 68/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2393654.1746 - auc_23: 0.0000e+00 - val_loss: 12456297.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss improved from 13238968.00000 to 12456297.00000, saving model to ../model_weights68-12456297.0000.hdf5\n",
      "Epoch 69/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2063604.1105 - auc_23: 0.0000e+00 - val_loss: 9934233.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss improved from 12456297.00000 to 9934233.00000, saving model to ../model_weights69-9934233.0000.hdf5\n",
      "Epoch 70/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1762863.0501 - auc_23: 0.0000e+00 - val_loss: 10977284.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 9934233.00000\n",
      "Epoch 71/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1937615.6403 - auc_23: 0.0000e+00 - val_loss: 6126987.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss improved from 9934233.00000 to 6126987.00000, saving model to ../model_weights71-6126987.0000.hdf5\n",
      "Epoch 72/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 11161260.0585 - auc_23: 0.0000e+00 - val_loss: 51151360.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 6126987.00000\n",
      "Epoch 73/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 13854288.4046 - auc_23: 0.0000e+00 - val_loss: 192395040.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 6126987.00000\n",
      "Epoch 74/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 4574436288302.2979 - auc_23: 0.0000e+00 - val_loss: 1058953088.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 6126987.00000\n",
      "Epoch 75/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 6847991817.0507 - auc_23: 0.0000e+00 - val_loss: 480886272.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 6126987.00000\n",
      "Epoch 76/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 3885409872.4837 - auc_23: 0.0000e+00 - val_loss: 224685440.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 6126987.00000\n",
      "Epoch 77/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2200610688.9304 - auc_23: 0.0000e+00 - val_loss: 121954600.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 6126987.00000\n",
      "Epoch 78/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1222065092.8320 - auc_23: 0.0000e+00 - val_loss: 97323456.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 6126987.00000\n",
      "Epoch 79/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 611434212.9324 - auc_23: 0.0000e+00 - val_loss: 175311984.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 6126987.00000\n",
      "Epoch 80/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 344083297.1683 - auc_23: 0.0000e+00 - val_loss: 156397856.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 6126987.00000\n",
      "Epoch 81/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 208836590.8872 - auc_23: 0.0000e+00 - val_loss: 137100144.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 6126987.00000\n",
      "Epoch 82/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 125984406.2660 - auc_23: 0.0000e+00 - val_loss: 100082984.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 6126987.00000\n",
      "Epoch 83/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 75030693.9508 - auc_23: 0.0000e+00 - val_loss: 103837496.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 6126987.00000\n",
      "Epoch 84/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 45265155.3392 - auc_23: 0.0000e+00 - val_loss: 106701632.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 6126987.00000\n",
      "Epoch 85/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 28880983.2523 - auc_23: 0.0000e+00 - val_loss: 107833296.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 6126987.00000\n",
      "Epoch 86/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 20765523.3600 - auc_23: 0.0000e+00 - val_loss: 106845336.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 6126987.00000\n",
      "Epoch 87/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 17052243.2941 - auc_23: 0.0000e+00 - val_loss: 103567432.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 6126987.00000\n",
      "Epoch 88/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 15210988.5057 - auc_23: 0.0000e+00 - val_loss: 97946824.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 6126987.00000\n",
      "Epoch 89/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 13891658.9965 - auc_23: 0.0000e+00 - val_loss: 90553392.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 6126987.00000\n",
      "Epoch 90/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 12600145.3213 - auc_23: 0.0000e+00 - val_loss: 81724880.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 6126987.00000\n",
      "Epoch 91/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 11187196.0388 - auc_23: 0.0000e+00 - val_loss: 72321280.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 6126987.00000\n",
      "Epoch 92/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 9731470.2121 - auc_23: 0.0000e+00 - val_loss: 61926084.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 6126987.00000\n",
      "Epoch 93/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 8228235.7578 - auc_23: 0.0000e+00 - val_loss: 52326280.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 6126987.00000\n",
      "Epoch 94/144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193696/193696 [==============================] - 1s 4us/step - loss: 6769477.6289 - auc_23: 0.0000e+00 - val_loss: 41466944.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 6126987.00000\n",
      "Epoch 95/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 5585569.1769 - auc_23: 0.0000e+00 - val_loss: 35573140.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 6126987.00000\n",
      "Epoch 96/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 19010172.0935 - auc_23: 0.0000e+00 - val_loss: 34474136.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 6126987.00000\n",
      "Epoch 97/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 35770587.4045 - auc_23: 0.0000e+00 - val_loss: 22486532.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 6126987.00000\n",
      "Epoch 98/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2724181.9321 - auc_23: 0.0000e+00 - val_loss: 12444838.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 6126987.00000\n",
      "Epoch 99/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 1301129.7729 - auc_23: 0.0000e+00 - val_loss: 6881114.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 6126987.00000\n",
      "Epoch 100/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 684166.9066 - auc_23: 0.0000e+00 - val_loss: 3846778.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss improved from 6126987.00000 to 3846778.50000, saving model to ../model_weights100-3846778.5000.hdf5\n",
      "Epoch 101/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 430452.5285 - auc_23: 0.0000e+00 - val_loss: 2330275.2500 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00101: val_loss improved from 3846778.50000 to 2330275.25000, saving model to ../model_weights101-2330275.2500.hdf5\n",
      "Epoch 102/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 335954.1273 - auc_23: 0.0000e+00 - val_loss: 1525016.2500 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00102: val_loss improved from 2330275.25000 to 1525016.25000, saving model to ../model_weights102-1525016.2500.hdf5\n",
      "Epoch 103/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 495608.3259 - auc_23: 0.0000e+00 - val_loss: 6967183.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1525016.25000\n",
      "Epoch 104/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 298409841846.0024 - auc_23: 0.0000e+00 - val_loss: 1162424483840.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1525016.25000\n",
      "Epoch 105/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 725085715727.2148 - auc_23: 0.0000e+00 - val_loss: 46801144.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1525016.25000\n",
      "Epoch 106/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 74950338.4234 - auc_23: 0.0000e+00 - val_loss: 2133480.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1525016.25000\n",
      "Epoch 107/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 6954624.6145 - auc_23: 0.0000e+00 - val_loss: 5060922.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1525016.25000\n",
      "Epoch 108/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4507899.1651 - auc_23: 0.0000e+00 - val_loss: 5995578.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1525016.25000\n",
      "Epoch 109/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4277114.4477 - auc_23: 0.0000e+00 - val_loss: 6193767.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1525016.25000\n",
      "Epoch 110/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4195023.4877 - auc_23: 0.0000e+00 - val_loss: 6172809.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1525016.25000\n",
      "Epoch 111/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4145350.4087 - auc_23: 0.0000e+00 - val_loss: 6147996.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1525016.25000\n",
      "Epoch 112/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 4101445.7312 - auc_23: 0.0000e+00 - val_loss: 5270713.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1525016.25000\n",
      "Epoch 113/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 7031014.5711 - auc_23: 0.0000e+00 - val_loss: 62503312.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1525016.25000\n",
      "Epoch 114/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 6816587081.1208 - auc_23: 0.0000e+00 - val_loss: 515078240.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1525016.25000\n",
      "Epoch 115/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 498965386.8501 - auc_23: 0.0000e+00 - val_loss: 9362028.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1525016.25000\n",
      "Epoch 116/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 4363291.2514 - auc_23: 0.0000e+00 - val_loss: 11730735.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1525016.25000\n",
      "Epoch 117/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 4087452.0708 - auc_23: 0.0000e+00 - val_loss: 9740918.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1525016.25000\n",
      "Epoch 118/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 8149244.4425 - auc_23: 0.0000e+00 - val_loss: 55774432.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1525016.25000\n",
      "Epoch 119/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 564279940.8095 - auc_23: 0.0000e+00 - val_loss: 247587776.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1525016.25000\n",
      "Epoch 120/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 69965708.7249 - auc_23: 0.0000e+00 - val_loss: 73692240.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1525016.25000\n",
      "Epoch 121/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 20510537.9539 - auc_23: 0.0000e+00 - val_loss: 26874600.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1525016.25000\n",
      "Epoch 122/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 8259534.7177 - auc_23: 0.0000e+00 - val_loss: 14388550.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1525016.25000\n",
      "Epoch 123/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 5088517.4787 - auc_23: 0.0000e+00 - val_loss: 8852048.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1525016.25000\n",
      "Epoch 124/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 3504034.7099 - auc_23: 0.0000e+00 - val_loss: 5480455.5000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1525016.25000\n",
      "Epoch 125/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 2487429.8431 - auc_23: 0.0000e+00 - val_loss: 3266116.2500 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1525016.25000\n",
      "Epoch 126/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 4476715.5983 - auc_23: 0.0000e+00 - val_loss: 25927450.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1525016.25000\n",
      "Epoch 127/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 1745475167053.1213 - auc_23: 0.0000e+00 - val_loss: 16123467776.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1525016.25000\n",
      "Epoch 128/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 17343729379.5791 - auc_23: 0.0000e+00 - val_loss: 74021360.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1525016.25000\n",
      "Epoch 129/144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193696/193696 [==============================] - 1s 4us/step - loss: 1035678602.9698 - auc_23: 0.0000e+00 - val_loss: 27026796.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1525016.25000\n",
      "Epoch 130/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 164436721.1181 - auc_23: 0.0000e+00 - val_loss: 9896664.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1525016.25000\n",
      "Epoch 131/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 42328483.3811 - auc_23: 0.0000e+00 - val_loss: 21236488.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1525016.25000\n",
      "Epoch 132/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 26447090.3126 - auc_23: 0.0000e+00 - val_loss: 23821110.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1525016.25000\n",
      "Epoch 133/144\n",
      "193696/193696 [==============================] - 1s 6us/step - loss: 19360343.3035 - auc_23: 0.0000e+00 - val_loss: 25571830.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1525016.25000\n",
      "Epoch 134/144\n",
      "193696/193696 [==============================] - 1s 6us/step - loss: 13804462.9559 - auc_23: 0.0000e+00 - val_loss: 26914146.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1525016.25000\n",
      "Epoch 135/144\n",
      "193696/193696 [==============================] - 1s 6us/step - loss: 11954341.3770 - auc_23: 0.0000e+00 - val_loss: 26764122.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1525016.25000\n",
      "Epoch 136/144\n",
      "193696/193696 [==============================] - 1s 6us/step - loss: 11203762.2478 - auc_23: 0.0000e+00 - val_loss: 28984138.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1525016.25000\n",
      "Epoch 137/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 19803891.7621 - auc_23: 0.0000e+00 - val_loss: 15388729.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1525016.25000\n",
      "Epoch 138/144\n",
      "193696/193696 [==============================] - 1s 6us/step - loss: 12286572792.5458 - auc_23: 0.0000e+00 - val_loss: 372019552.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1525016.25000\n",
      "Epoch 139/144\n",
      "193696/193696 [==============================] - 1s 7us/step - loss: 714366631.1819 - auc_23: 0.0000e+00 - val_loss: 127161968.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1525016.25000\n",
      "Epoch 140/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 54235996.2320 - auc_23: 0.0000e+00 - val_loss: 103820280.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1525016.25000\n",
      "Epoch 141/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 39700248.1189 - auc_23: 0.0000e+00 - val_loss: 78869088.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1525016.25000\n",
      "Epoch 142/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 28760275.7796 - auc_23: 0.0000e+00 - val_loss: 58962364.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1525016.25000\n",
      "Epoch 143/144\n",
      "193696/193696 [==============================] - 1s 5us/step - loss: 20963779.6937 - auc_23: 0.0000e+00 - val_loss: 44409260.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1525016.25000\n",
      "Epoch 144/144\n",
      "193696/193696 [==============================] - 1s 4us/step - loss: 15832322.3552 - auc_23: 0.0000e+00 - val_loss: 33582428.0000 - val_auc_23: 0.0000e+00\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1525016.25000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(inputs=input_cols, outputs=[y])\n",
    "\n",
    "# model.summary()\n",
    "model.compile(loss=\"mse\", optimizer=RMSprop(lr=lr), metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit([encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                       encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating], local_df['rating'], \n",
    "          batch_size=batch_size, epochs=epochs, validation_split=0.005,\n",
    "                   callbacks = [cb_checkpoint])\n",
    "# encoded_fch, encoded_category_l, encoded_lw\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.legend() \n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list: []\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(model_save_path)\n",
    "print('file_list: {}'.format(file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유사도 아이템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_to_vec(feature, model, location_df, h_size, input_features):\n",
    "    layer_name = feature\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "    test = input_features\n",
    "                             \n",
    "    locationId_latent_vector = intermediate_layer_model.predict(test)\n",
    "    \n",
    "    locationId_latent_vector = locationId_latent_vector.T.reshape(-1, h_size)\n",
    "    vec = pd.DataFrame(locationId_latent_vector)\n",
    "    location_df = location_df.reset_index()\n",
    "    vec['locationId'] = location_df['locationId']\n",
    "    \n",
    "    # 아이템별 의미 벡터 생성 \n",
    "    vec = vec.groupby('locationId').agg([('0','mean')]).reset_index()\n",
    "\n",
    "    vec = pd.DataFrame(vec.iloc[:,1:].values)\n",
    "    vec['locationId'] = location_df['locationId'].unique()\n",
    "    vec = vec.set_index('locationId')\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locationId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788542</th>\n",
       "      <td>-1537.253174</td>\n",
       "      <td>-1537.266357</td>\n",
       "      <td>-1537.279541</td>\n",
       "      <td>-1537.314453</td>\n",
       "      <td>-1447.767334</td>\n",
       "      <td>-1447.767334</td>\n",
       "      <td>-1447.780518</td>\n",
       "      <td>-1447.780518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077917</th>\n",
       "      <td>-830.337341</td>\n",
       "      <td>-871.947632</td>\n",
       "      <td>-871.627380</td>\n",
       "      <td>-765.864197</td>\n",
       "      <td>-765.837524</td>\n",
       "      <td>-750.090576</td>\n",
       "      <td>-662.776184</td>\n",
       "      <td>-685.335754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732387</th>\n",
       "      <td>-1109.489136</td>\n",
       "      <td>-1388.345825</td>\n",
       "      <td>-1144.588257</td>\n",
       "      <td>-1388.380493</td>\n",
       "      <td>-1137.427734</td>\n",
       "      <td>-1388.411743</td>\n",
       "      <td>-1388.431519</td>\n",
       "      <td>-1388.451294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13833720</th>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "      <td>-385.016907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977925</th>\n",
       "      <td>-804.521362</td>\n",
       "      <td>-1029.487427</td>\n",
       "      <td>-1029.499146</td>\n",
       "      <td>-1029.504883</td>\n",
       "      <td>-1029.516602</td>\n",
       "      <td>-1029.529663</td>\n",
       "      <td>-1029.542847</td>\n",
       "      <td>-1029.557495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597806</th>\n",
       "      <td>-148.596954</td>\n",
       "      <td>-153.404205</td>\n",
       "      <td>-153.406769</td>\n",
       "      <td>-35.644745</td>\n",
       "      <td>-153.408722</td>\n",
       "      <td>-153.411285</td>\n",
       "      <td>-148.605774</td>\n",
       "      <td>-200.125015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149130</th>\n",
       "      <td>-265.883179</td>\n",
       "      <td>-266.655426</td>\n",
       "      <td>-266.654724</td>\n",
       "      <td>-264.719025</td>\n",
       "      <td>-272.489685</td>\n",
       "      <td>-273.921692</td>\n",
       "      <td>-271.398651</td>\n",
       "      <td>-271.191956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595040</th>\n",
       "      <td>-184.902512</td>\n",
       "      <td>-172.722931</td>\n",
       "      <td>-172.722931</td>\n",
       "      <td>-172.728180</td>\n",
       "      <td>-172.728180</td>\n",
       "      <td>-172.726868</td>\n",
       "      <td>-223.797028</td>\n",
       "      <td>-172.732117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13369640</th>\n",
       "      <td>-539.402954</td>\n",
       "      <td>-539.408813</td>\n",
       "      <td>-543.603333</td>\n",
       "      <td>-548.325012</td>\n",
       "      <td>-601.862061</td>\n",
       "      <td>-601.862549</td>\n",
       "      <td>-601.864868</td>\n",
       "      <td>-601.870300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043495</th>\n",
       "      <td>-285.754547</td>\n",
       "      <td>-274.807343</td>\n",
       "      <td>-375.382904</td>\n",
       "      <td>-375.460602</td>\n",
       "      <td>-375.839478</td>\n",
       "      <td>-376.107117</td>\n",
       "      <td>-376.171600</td>\n",
       "      <td>-377.835449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15934 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1            2            3            4  \\\n",
       "locationId                                                                    \n",
       "788542     -1537.253174 -1537.266357 -1537.279541 -1537.314453 -1447.767334   \n",
       "4077917     -830.337341  -871.947632  -871.627380  -765.864197  -765.837524   \n",
       "9732387    -1109.489136 -1388.345825 -1144.588257 -1388.380493 -1137.427734   \n",
       "13833720    -385.016907  -385.016907  -385.016907  -385.016907  -385.016907   \n",
       "8977925     -804.521362 -1029.487427 -1029.499146 -1029.504883 -1029.516602   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "9597806     -148.596954  -153.404205  -153.406769   -35.644745  -153.408722   \n",
       "1149130     -265.883179  -266.655426  -266.654724  -264.719025  -272.489685   \n",
       "3595040     -184.902512  -172.722931  -172.722931  -172.728180  -172.728180   \n",
       "13369640    -539.402954  -539.408813  -543.603333  -548.325012  -601.862061   \n",
       "7043495     -285.754547  -274.807343  -375.382904  -375.460602  -375.839478   \n",
       "\n",
       "                      5            6            7  \n",
       "locationId                                         \n",
       "788542     -1447.767334 -1447.780518 -1447.780518  \n",
       "4077917     -750.090576  -662.776184  -685.335754  \n",
       "9732387    -1388.411743 -1388.431519 -1388.451294  \n",
       "13833720    -385.016907  -385.016907  -385.016907  \n",
       "8977925    -1029.529663 -1029.542847 -1029.557495  \n",
       "...                 ...          ...          ...  \n",
       "9597806     -153.411285  -148.605774  -200.125015  \n",
       "1149130     -273.921692  -271.398651  -271.191956  \n",
       "3595040     -172.726868  -223.797028  -172.732117  \n",
       "13369640    -601.862549  -601.864868  -601.870300  \n",
       "7043495     -376.107117  -376.171600  -377.835449  \n",
       "\n",
       "[15934 rows x 8 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = latent_to_vec('FM_locationId', model, local_df, 8, [encoded_userID, encoded_users_mean_rating, \n",
    "                             encoded_user_reviewcount, encoded_locationId, \n",
    "                             encoded_createdDate, encoded_photonum,\n",
    "                        encoded_rated_count,\n",
    "                                  encoded_average_photonum, encoded_average_rating])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.to_csv(os.path.join(\"..\",\"realtime_model\",'deepFM_local_vec.csv'))#, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosim_id(df, vec, item_id):\n",
    "    def cos_sim(A, B):\n",
    "           return dot(A, B)/(norm(A)*norm(B)) \n",
    "    new_vec = vec.copy() \n",
    "    sim = []\n",
    "    \n",
    "    # 인풋 호텔 정보 데이터에 없는 경우 종료 \n",
    "    if item_id not in vec.index.tolist():\n",
    "        return \n",
    "        \n",
    "    for i in range(len(vec)):\n",
    "        sim.append(cos_sim(vec.loc[item_id,:], vec.iloc[i,:]))\n",
    "\n",
    "    new_vec['sim'] = sim\n",
    "    # sim 높은 순 \n",
    "    new_vec = new_vec['sim'].reset_index().sort_values('sim', ascending=False)\n",
    "    sim_sorted = new_vec['locationId'].tolist()\n",
    "    # 인풋 호텔정보 빼고 유사도 높은 순대로 id \n",
    "    if item_id in sim_sorted:\n",
    "        sim_sorted.remove(item_id) \n",
    "    return sim_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sim_item(vec, df, item_id, top):\n",
    "    top_id = cosim_id(df, vec, item_id)\n",
    "    \n",
    "    if type(top_id) == list :\n",
    "        df = df.drop_duplicates(['locationId'], keep='last')\n",
    "        recommend_rst = []\n",
    "        for x in top_id:\n",
    "            if df.loc[df['locationId']==x].category.values[0]== 'EAT':\n",
    "                recommend_rst.append([df.loc[df['locationId']==x][['place.name', 'land.addr']]])\n",
    "\n",
    "        print('input hotel:', local_df.loc[local_df['locationId']==item_id]['place.name'].unique()[0])\n",
    "        print('-'*10)\n",
    "        for i in range(len(recommend_rst[:top])):\n",
    "            print('top', i+1, recommend_rst[i][0]['place.name'].values[0])\n",
    "            print('  주소', recommend_rst[i][0]['land.addr'].values[0])\n",
    "        \n",
    "    else:\n",
    "        answer_lst = ['해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.', '해당 호텔 정보가 없습니다. 다른 호텔을 추천받아보세요.']\n",
    "        x = random.randint(0, len(answer_lst)-1)\n",
    "        return answer_lst[x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Conrad Seoul\n",
      "----------\n",
      "top 1 김경애 떡방\n",
      "  주소 서울특별시 강남구 대치동 316 은마아파트\n",
      "top 2 오리올\n",
      "  주소 서울특별시 용산구 후암동 406-99\n",
      "top 3 블랑제리 더 플라자\n",
      "  주소 서울특별시 중구 태평로2가 23 더 플라자\n",
      "top 4 버거킹 센트럴시티점\n",
      "  주소 서울특별시 서초구 반포동 19-3 센트럴시티\n",
      "top 5 피자스쿨 신풍역점\n",
      "  주소 서울특별시 영등포구 신길동 3894\n",
      "top 6 라밥 노량진2호점\n",
      "  주소 서울특별시 동작구 노량진동 119-166\n",
      "top 7 영미네 곱창\n",
      "  주소 서울특별시 중구 황학동 1783\n",
      "top 8 삼미식당 홍대점\n",
      "  주소 서울특별시 마포구 서교동 347-24\n",
      "top 9 인생닭강정 장승백이점\n",
      "  주소 서울특별시 동작구 상도동 364-23\n",
      "top 10 성수동 대림창고\n",
      "  주소 서울특별시 성동구 성수동2가 322-32 대림창고\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 3477158, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'해당 호텔 정보가 없습니다. 다른 호텔을 입력해주세요.'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item(vec, local_df, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis styles Ambassador Seoul Gangnam\n",
      "----------\n",
      "top 1 감동식당\n",
      "  주소 서울특별시 노원구 상계동 434-49\n",
      "top 2 인하순대국\n",
      "  주소 서울특별시 서초구 서초동 1555-16\n",
      "top 3 라떼또뜨\n",
      "  주소 서울특별시 서초구 방배동 875-1\n",
      "top 4 상도늘보리 본점\n",
      "  주소 서울특별시 동작구 상도2동 367-6\n",
      "top 5 비파티세리\n",
      "  주소 서울특별시 강남구 신사동 546-17 인자빌딩\n",
      "top 6 매화반점\n",
      "  주소 서울특별시 광진구 자양4동 4-11\n",
      "top 7 등촌샤브칼국수\n",
      "  주소 서울특별시 송파구 문정동 76-3\n",
      "top 8 원조양평해장국직영점\n",
      "  주소 서울특별시 은평구 갈현동 460-18\n",
      "top 9 우리집김밥 서초점\n",
      "  주소 서울특별시 서초구 서초동 1330-11 금성상가\n",
      "top 10 일상밥상\n",
      "  주소 서울특별시 양천구 목동 905-22 목동트윈빌\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 299533, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Best Western Premier Seoul Garden Hotel\n",
      "----------\n",
      "top 1 미추원주추어탕서울본점\n",
      "  주소 서울특별시 관악구 봉천동 1595-8\n",
      "top 2 빠리가옥\n",
      "  주소 서울특별시 종로구 익선동 166-26\n",
      "top 3 다담\n",
      "  주소 서울특별시 강남구 청담동 97-1 M빌딩\n",
      "top 4 깐부치킨 신사역점\n",
      "  주소 서울특별시 강남구 신사동 514-5\n",
      "top 5 스위트스페이스 현대시티아루렛동대문점\n",
      "  주소 서울특별시 중구 을지로6가 17-2 현대시티타워\n",
      "top 6 크앙분식 - 혜화본점\n",
      "  주소 서울특별시 종로구 연건동 195-38\n",
      "top 7 호치킨 창동역점\n",
      "  주소 서울특별시 도봉구 창동 75-13\n",
      "top 8 Guksuga\n",
      "  주소 서울특별시 중구 충무로5가 86-3\n",
      "top 9 인생닭강정\n",
      "  주소 서울특별시 성북구 동선동1가 85-97\n",
      "top 10 소피스티케이크\n",
      "  주소 서울특별시 마포구 서교동 396-54\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 299152, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: ibis budget Ambassador Seoul Dongdaemun\n",
      "----------\n",
      "top 1 바나프레소 길동역점\n",
      "  주소 서울특별시 강동구 길동 366-5\n",
      "top 2 진대포\n",
      "  주소 서울특별시 용산구 갈월동 98-1\n",
      "top 3 충무로쭈꾸미불고기\n",
      "  주소 서울특별시 중구 필동1가 3-20\n",
      "top 4 마녀김밥 노들점\n",
      "  주소 서울특별시 용산구 이촌동 302-146\n",
      "top 5 홀리차우\n",
      "  주소 서울특별시 중구 명동1가 8-1\n",
      "top 6 스타벅스 쌍문역점\n",
      "  주소 서울특별시 도봉구 창동 659-5\n",
      "top 7 김밥천국\n",
      "  주소 서울특별시 마포구 망원동 395-4\n",
      "top 8 내고향횡성한우정육점식당\n",
      "  주소 서울특별시 송파구 방이동 66-3 석촌씨티빌딩\n",
      "top 9 가야랑\n",
      "  주소 서울특별시 용산구 이태원2동 239-4\n",
      "top 10 돈수작 건대점\n",
      "  주소 서울특별시 광진구 화양동 9-19\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 6998634, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Banyan Tree Club & Spa Seoul\n",
      "----------\n",
      "top 1 조아저씨김치찌개와막겹구이\n",
      "  주소 서울특별시 중구 서소문동 23\n",
      "top 2 탐앤탐스\n",
      "  주소 서울특별시 서초구 반포동 20-45 반포자이플라자\n",
      "top 3 황소고집\n",
      "  주소 서울특별시 종로구 관철동 11-11\n",
      "top 4 서울감자탕\n",
      "  주소 서울특별시 강동구 성내동 199-11\n",
      "top 5 써브웨이 상암DMC푸르지오시티점\n",
      "  주소 서울특별시 마포구 상암동 1596 상암DMC푸르지오시티, S-City\n",
      "top 6 밥이답이다 신촌세브란스병원점\n",
      "  주소 서울특별시 서대문구 신촌동 134 신촌세브란스병원\n",
      "top 7 모힝\n",
      "  주소 서울특별시 관악구 봉천동 1598-6\n",
      "top 8 푸주옥\n",
      "  주소 서울특별시 양천구 신정동 1290-2\n",
      "top 9 마포 갈매기\n",
      "  주소 서울특별시 마포구 도화동 194-8\n",
      "top 10 돈암동찌개\n",
      "  주소 서울특별시 강북구 수유동 191-66\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 1796658, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input hotel: Grand InterContinental Seoul Parnas\n",
      "----------\n",
      "top 1 곳온니플레이스\n",
      "  주소 서울특별시 영등포구 여의도동 17 여의도더샵아일랜드파크\n",
      "top 2 풀향기\n",
      "  주소 서울특별시 용산구 한남동 726-54 풀향기(음식점)\n",
      "top 3 센터커피\n",
      "  주소 서울 성동구 서울숲2길 28-11 2층\n",
      "top 4 그랜드뮤즈\n",
      "  주소 서울특별시 용산구 한남동 726-419\n",
      "top 5 달구벌반점\n",
      "  주소 서울특별시 성동구 성수동2가 278-25\n",
      "top 6 정성본 샤브수끼 칼국수 강남역점\n",
      "  주소 서울특별시 서초구 서초동 1321-9 풍림아이원매직\n",
      "top 7 브릭하우스76\n",
      "  주소 서울특별시 은평구 역촌동 35-29\n",
      "top 8 장군갈비\n",
      "  주소 서울특별시 영등포구 문래동3가 55-5 로데오 왘 쇼핑몰\n",
      "top 9 담소소사골순대육개장 가산디지털점\n",
      "  주소 서울특별시 금천구 가산동 60-11 스타밸리\n",
      "top 10 평양냉면\n",
      "  주소 서울특별시 구로구 오류동 13-55\n"
     ]
    }
   ],
   "source": [
    "sim_item(vec, local_df, 306118, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
