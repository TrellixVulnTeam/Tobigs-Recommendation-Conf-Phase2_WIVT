{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torchfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from torchfm.model.afi import AutomaticFeatureInteractionModel\n",
    "from torchfm.model.afm import AttentionalFactorizationMachineModel\n",
    "from torchfm.model.dcn import DeepCrossNetworkModel\n",
    "from torchfm.model.dfm import DeepFactorizationMachineModel\n",
    "from torchfm.model.ffm import FieldAwareFactorizationMachineModel\n",
    "from torchfm.model.fm import FactorizationMachineModel\n",
    "from torchfm.model.fnfm import FieldAwareNeuralFactorizationMachineModel\n",
    "from torchfm.model.fnn import FactorizationSupportedNeuralNetworkModel\n",
    "from torchfm.model.lr import LogisticRegressionModel\n",
    "from torchfm.model.ncf import NeuralCollaborativeFiltering\n",
    "from torchfm.model.nfm import NeuralFactorizationMachineModel\n",
    "from torchfm.model.pnn import ProductNeuralNetworkModel\n",
    "from torchfm.model.wd import WideAndDeepModel\n",
    "from torchfm.model.xdfm import ExtremeDeepFactorizationMachineModel\n",
    "from torchfm.model.afn import AdaptiveFactorizationNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (4,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.id</th>\n",
       "      <th>place.id</th>\n",
       "      <th>place.name</th>\n",
       "      <th>category</th>\n",
       "      <th>place.category</th>\n",
       "      <th>user.rating</th>\n",
       "      <th>place.rating</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>is_fch</th>\n",
       "      <th>photonum</th>\n",
       "      <th>review.count</th>\n",
       "      <th>language</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>land.addr</th>\n",
       "      <th>review</th>\n",
       "      <th>is_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4TXey</td>\n",
       "      <td>1.150710e+09</td>\n",
       "      <td>스타벅스 보라매공원R점</td>\n",
       "      <td>EAT</td>\n",
       "      <td>스타벅스</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.590717</td>\n",
       "      <td>2020-05-21 20:42:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158</td>\n",
       "      <td>ko</td>\n",
       "      <td>37.492103</td>\n",
       "      <td>126.92355</td>\n",
       "      <td>서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awWC</td>\n",
       "      <td>1.150710e+09</td>\n",
       "      <td>스타벅스 보라매공원R점</td>\n",
       "      <td>EAT</td>\n",
       "      <td>스타벅스</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.590717</td>\n",
       "      <td>2019-06-28 01:11:03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158</td>\n",
       "      <td>ko</td>\n",
       "      <td>37.492103</td>\n",
       "      <td>126.92355</td>\n",
       "      <td>서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Unzg</td>\n",
       "      <td>1.150710e+09</td>\n",
       "      <td>스타벅스 보라매공원R점</td>\n",
       "      <td>EAT</td>\n",
       "      <td>스타벅스</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.590717</td>\n",
       "      <td>2020-03-12 00:22:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158</td>\n",
       "      <td>ko</td>\n",
       "      <td>37.492103</td>\n",
       "      <td>126.92355</td>\n",
       "      <td>서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LRVl</td>\n",
       "      <td>1.150710e+09</td>\n",
       "      <td>스타벅스 보라매공원R점</td>\n",
       "      <td>EAT</td>\n",
       "      <td>스타벅스</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.590717</td>\n",
       "      <td>2020-02-16 17:06:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158</td>\n",
       "      <td>ko</td>\n",
       "      <td>37.492103</td>\n",
       "      <td>126.92355</td>\n",
       "      <td>서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESN1</td>\n",
       "      <td>1.150710e+09</td>\n",
       "      <td>스타벅스 보라매공원R점</td>\n",
       "      <td>EAT</td>\n",
       "      <td>스타벅스</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.590717</td>\n",
       "      <td>2019-03-11 00:08:48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158</td>\n",
       "      <td>ko</td>\n",
       "      <td>37.492103</td>\n",
       "      <td>126.92355</td>\n",
       "      <td>서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT</td>\n",
       "      <td>2019.03.06\\nHH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user.id      place.id    place.name category place.category  user.rating  \\\n",
       "0   4TXey  1.150710e+09  스타벅스 보라매공원R점      EAT           스타벅스          4.5   \n",
       "1    awWC  1.150710e+09  스타벅스 보라매공원R점      EAT           스타벅스          5.0   \n",
       "2   1Unzg  1.150710e+09  스타벅스 보라매공원R점      EAT           스타벅스          5.0   \n",
       "3    LRVl  1.150710e+09  스타벅스 보라매공원R점      EAT           스타벅스          5.0   \n",
       "4    ESN1  1.150710e+09  스타벅스 보라매공원R점      EAT           스타벅스          5.0   \n",
       "\n",
       "   place.rating          createdDate  is_fch  photonum  review.count language  \\\n",
       "0      4.590717  2020-05-21 20:42:00       1       0.0           158       ko   \n",
       "1      4.590717  2019-06-28 01:11:03       1       0.0           158       ko   \n",
       "2      4.590717  2020-03-12 00:22:00       1       0.0           158       ko   \n",
       "3      4.590717  2020-02-16 17:06:00       1       0.0           158       ko   \n",
       "4      4.590717  2019-03-11 00:08:48       1       0.0           158       ko   \n",
       "\n",
       "         lat        lng                             land.addr          review  \\\n",
       "0  37.492103  126.92355  서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT             NaN   \n",
       "1  37.492103  126.92355  서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT            none   \n",
       "2  37.492103  126.92355  서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT             NaN   \n",
       "3  37.492103  126.92355  서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT             NaN   \n",
       "4  37.492103  126.92355  서울특별시 동작구 신대방동 395-65 파크스퀘어,보라매현대APT  2019.03.06\\nHH   \n",
       "\n",
       "   is_local  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(os.path.join(\"..\",\"..\",\"data\",\"input_data.csv\"))\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>rated_count</th>\n",
       "      <th>average_photonum</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>userID</th>\n",
       "      <th>users_mean_rating</th>\n",
       "      <th>user_reviewcount</th>\n",
       "      <th>rating</th>\n",
       "      <th>location_name</th>\n",
       "      <th>placeType</th>\n",
       "      <th>createdDate</th>\n",
       "      <th>islocal</th>\n",
       "      <th>photonum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299152</td>\n",
       "      <td>13</td>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>4842</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>Best Western Premier Seoul Garden Hotel</td>\n",
       "      <td>ACCOMMODATION</td>\n",
       "      <td>20171009</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299152</td>\n",
       "      <td>13</td>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>9212</td>\n",
       "      <td>3.791667</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>Best Western Premier Seoul Garden Hotel</td>\n",
       "      <td>ACCOMMODATION</td>\n",
       "      <td>20180306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299152</td>\n",
       "      <td>13</td>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>14262</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Best Western Premier Seoul Garden Hotel</td>\n",
       "      <td>ACCOMMODATION</td>\n",
       "      <td>20121220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299152</td>\n",
       "      <td>13</td>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>20235</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Western Premier Seoul Garden Hotel</td>\n",
       "      <td>ACCOMMODATION</td>\n",
       "      <td>20161127</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>299152</td>\n",
       "      <td>13</td>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>21432</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Best Western Premier Seoul Garden Hotel</td>\n",
       "      <td>ACCOMMODATION</td>\n",
       "      <td>20120416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationId  rated_count  average_photonum  average_rating  userID  \\\n",
       "0      299152           13          2.846154        3.692308    4842   \n",
       "1      299152           13          2.846154        3.692308    9212   \n",
       "2      299152           13          2.846154        3.692308   14262   \n",
       "3      299152           13          2.846154        3.692308   20235   \n",
       "4      299152           13          2.846154        3.692308   21432   \n",
       "\n",
       "   users_mean_rating  user_reviewcount  rating  \\\n",
       "0           3.677083                96       5   \n",
       "1           3.791667               240       3   \n",
       "2           4.500000                 2       4   \n",
       "3           3.000000                 4       1   \n",
       "4           4.200000                 5       4   \n",
       "\n",
       "                             location_name      placeType  createdDate  \\\n",
       "0  Best Western Premier Seoul Garden Hotel  ACCOMMODATION     20171009   \n",
       "1  Best Western Premier Seoul Garden Hotel  ACCOMMODATION     20180306   \n",
       "2  Best Western Premier Seoul Garden Hotel  ACCOMMODATION     20121220   \n",
       "3  Best Western Premier Seoul Garden Hotel  ACCOMMODATION     20161127   \n",
       "4  Best Western Premier Seoul Garden Hotel  ACCOMMODATION     20120416   \n",
       "\n",
       "   islocal  photonum  \n",
       "0        1        12  \n",
       "1        1         0  \n",
       "2        0         1  \n",
       "3        0         4  \n",
       "4        0         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(os.path.join(\"..\",\"..\",\"data\",\"TA_User_Reviws_Korea_all_v2_new_df.csv\"))\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['locationId', 'rated_count', 'average_photonum', 'average_rating',\n",
       "       'userID', 'users_mean_rating', 'user_reviewcount', 'rating',\n",
       "       'location_name', 'placeType', 'createdDate', 'islocal', 'photonum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['locationId', 'rated_count', 'average_photonum', 'average_rating',\n",
    "       'userID', 'users_mean_rating', 'user_reviewcount', \n",
    "        'createdDate', 'photonum']\n",
    "y = 'rating'\n",
    "\n",
    "groups = []\n",
    "labels = []\n",
    "\n",
    "for i in range(new_df.shape[0]):\n",
    "    groupsa.append(new_df.iloc[i,x])\n",
    "    labels.append(new_df.iloc[i,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locationId\n",
      "rated_count\n",
      "average_photonum\n",
      "average_rating\n",
      "userID\n",
      "users_mean_rating\n",
      "user_reviewcount\n",
      "rating\n",
      "location_name\n",
      "placeType\n",
      "createdDate\n",
      "islocal\n",
      "photonum\n"
     ]
    }
   ],
   "source": [
    "for x in new_df.iloc[:3,:]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    if name == 'TripAdvisor':\n",
    "        new_df = pd.read_csv(os.path.join(\"..\",\"..\",\"data\",\"TA_User_Reviws_Korea_all_v2_new_df.csv\"))\n",
    "        new_df = new_df.drop(['location_name'], axis=1)\n",
    "        return new_df\n",
    "    elif name == \"FinalData\":\n",
    "        new_df = pd.read_csv(os.path.join(\"..\",\"..\",\"data\",\"input_data.csv\"))\n",
    "#         new_df = new_df.drop(['location_name'], axis=1)\n",
    "        return new_df\n",
    "    else:\n",
    "        raise ValueError('unknown dataset name: ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name, dataset):\n",
    "    \"\"\"\n",
    "    Hyperparameters are empirically determined, not opitmized.\n",
    "    \"\"\"\n",
    "    field_dims = dataset.field_dims\n",
    "    if name == 'lr':\n",
    "        return LogisticRegressionModel(field_dims)\n",
    "    elif name == 'fm':\n",
    "        return FactorizationMachineModel(field_dims, embed_dim=16)\n",
    "    elif name == 'ffm':\n",
    "        return FieldAwareFactorizationMachineModel(field_dims, embed_dim=4)\n",
    "    elif name == 'fnn':\n",
    "        return FactorizationSupportedNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'wd':\n",
    "        return WideAndDeepModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'ipnn':\n",
    "        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method='inner', dropout=0.2)\n",
    "    elif name == 'opnn':\n",
    "        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method='outer', dropout=0.2)\n",
    "    elif name == 'dcn':\n",
    "        return DeepCrossNetworkModel(field_dims, embed_dim=16, num_layers=3, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'nfm':\n",
    "        return NeuralFactorizationMachineModel(field_dims, embed_dim=64, mlp_dims=(64,), dropouts=(0.2, 0.2))\n",
    "    elif name == 'ncf':\n",
    "        # only supports MovieLens dataset because for other datasets user/item colums are indistinguishable\n",
    "        assert isinstance(dataset, MovieLens20MDataset) or isinstance(dataset, MovieLens1MDataset)\n",
    "        return NeuralCollaborativeFiltering(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2,\n",
    "                                            user_field_idx=dataset.user_field_idx,\n",
    "                                            item_field_idx=dataset.item_field_idx)\n",
    "    elif name == 'fnfm':\n",
    "        return FieldAwareNeuralFactorizationMachineModel(field_dims, embed_dim=4, mlp_dims=(64,), dropouts=(0.2, 0.2))\n",
    "    elif name == 'dfm':\n",
    "        return DeepFactorizationMachineModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'xdfm':\n",
    "        return ExtremeDeepFactorizationMachineModel(\n",
    "            field_dims, embed_dim=16, cross_layer_sizes=(16, 16), split_half=False, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'afm':\n",
    "        return AttentionalFactorizationMachineModel(field_dims, embed_dim=16, attn_size=16, dropouts=(0.2, 0.2))\n",
    "    elif name == 'afi':\n",
    "        return AutomaticFeatureInteractionModel(\n",
    "             field_dims, embed_dim=16, atten_embed_dim=64, num_heads=2, num_layers=3, mlp_dims=(400, 400), dropouts=(0, 0, 0))\n",
    "    elif name == 'afn':\n",
    "        print(\"Model:AFN\")\n",
    "        return AdaptiveFactorizationNetwork(\n",
    "            field_dims, embed_dim=16, LNN_dim=1500, mlp_dims=(400,400,400), dropouts=(0, 0, 0))\n",
    "    else:\n",
    "        raise ValueError('unknown model name: ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, criterion, device, log_interval=1000):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (fields, target) in enumerate(tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0)):\n",
    "        fields, target = fields.to(device), target.to(device)\n",
    "        y = model(fields)\n",
    "        loss = criterion(y, target.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            print('    - loss:', total_loss / log_interval)\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "dataset_name= 'TripAdvisor'\n",
    "model_name= 'afm',\n",
    "epoch= 2400,\n",
    "learning_rate= 1e-4,\n",
    "batch_size= 2400,\n",
    "weight_decay= 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137490 123741 13749\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(dataset_name)\n",
    "train_length = int(len(dataset) * 0.9)\n",
    "valid_length = int(len(dataset) * 0.1)\n",
    "\n",
    "print(len(dataset), train_length, valid_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, (train_length, valid_length))\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size[0], num_workers=8)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size[0], num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'field_dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8b942765d4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-244a041c3cd6>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(name, dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mHyperparameters\u001b[0m \u001b[0mare\u001b[0m \u001b[0mempirically\u001b[0m \u001b[0mdetermined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopitmized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfield_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLogisticRegressionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'field_dims'"
     ]
    }
   ],
   "source": [
    "model = get_model(model_name, dataset).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.RMSprop(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_i in range(epoch):\n",
    "    train(model, optimizer, train_data_loader, criterion, device)\n",
    "    print('epoch:', epoch_i, 'validation: auc:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(dataset_name, model_name, epoch, learning_rate, batch_size, weight_decay, device):\n",
    "#     device = torch.device(device)\n",
    "#     dataset = get_dataset(dataset_name)\n",
    "#     train_length = int(len(dataset) * 0.9)\n",
    "#     valid_length = int(len(dataset) * 0.1)\n",
    "# #     test_length = len(dataset) - train_length - valid_length\n",
    "#     train_dataset, valid_dataset = torch.utils.data.random_split(\n",
    "#         dataset, (train_length, valid_length))\n",
    "#     train_data_loader = DataLoader(train_dataset, batch_size=batch_size[0], num_workers=8)\n",
    "#     valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size[0], num_workers=8)\n",
    "# #     test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8)\n",
    "#     model = get_model(model_name, dataset).to(device)\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "#     optimizer = torch.optim.RMSprop(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     for epoch_i in range(epoch):\n",
    "#         train(model, optimizer, train_data_loader, criterion, device)\n",
    "# #         auc = test(model, valid_data_loader, device)\n",
    "#         print('epoch:', epoch_i, 'validation: auc:', auc)\n",
    "# #     auc = test(model, test_data_loader, device)\n",
    "# #     print('test auc:', auc)\n",
    "# #     torch.save(model, f'{save_dir}/{model_name}.pt')\n",
    "\n",
    "# main(dataset_name, model_name, epoch,\n",
    "#          learning_rate, batch_size, weight_decay, device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
