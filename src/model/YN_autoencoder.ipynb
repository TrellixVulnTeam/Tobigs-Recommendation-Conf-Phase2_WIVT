{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import add\n",
    "from BaseModel import BaseModel\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation= selu\n",
    "batch=64 \n",
    "dropout=0.8 \n",
    "epochs=50 \n",
    "layers='[512,256,512]' \n",
    "lr=0.0001 \n",
    "reg=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(self, interactions, user_item_matrix):\n",
    "    '''\n",
    "    Create a Input to Model\n",
    "    '''\n",
    "\n",
    "    # Params\n",
    "    #   integer encode the documents\n",
    "    vocab_size   = 100\n",
    "    #   pad documents to a max length of 4 words\n",
    "    max_length   = 50\n",
    "\n",
    "\n",
    "    def split_str(val):\n",
    "      '''\n",
    "      Split and Join Array(Array(str))\n",
    "      '''\n",
    "      tokens = []\n",
    "      for v in val:\n",
    "          tokens.extend(v.split(' '))\n",
    "      return ' '.join(tokens)\n",
    "\n",
    "    #  Order users in matrix interactions\n",
    "    users_ids  = list(user_item_matrix.index)\n",
    "    \n",
    "    # Dataset with User X Content information\n",
    "    user_games = interactions.groupby('user_id')['game'].apply(list).loc[users_ids].reset_index()\n",
    "    user_games['tokens'] = user_games['game'].apply(split_str)\n",
    "\n",
    "    # Prepare input layer\n",
    "    encoded_tokens = [one_hot(d, vocab_size) for d in user_games.tokens]\n",
    "    padded_tokens  = pad_sequences(encoded_tokens, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Input  \n",
    "    X = [user_item_matrix.values, padded_tokens]\n",
    "    y = user_item_matrix.values\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fit(self, X, y):\n",
    "    '''\n",
    "    Train Model\n",
    "    '''\n",
    "\n",
    "    # Build model\n",
    "    model = self.build_model(X)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr=self.lr), \n",
    "                    loss='mse')#'mean_absolute_error'\n",
    "\n",
    "    # train\n",
    "    hist = model.fit(x=X, y=y,\n",
    "                      epochs=self.epochs,\n",
    "                      batch_size=self.batch,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=self.callbacks_list())\n",
    "\n",
    "    # Melhor peso\n",
    "    model.load_weights(self.WEIGHT_MODEL)\n",
    "    self.model = model\n",
    "\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "\n",
    "    # Predict\n",
    "    pred = self.model.predict(X)\n",
    "\n",
    "    # remove watched items from predictions\n",
    "    pred = pred * (X[0] == 0) \n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(self, X):\n",
    "    '''\n",
    "    Autoencoder for Collaborative Filter Model\n",
    "    '''\n",
    "\n",
    "    # Params\n",
    "    users_items_matrix, content_info = X\n",
    "\n",
    "    # Input\n",
    "    input_layer   = x = Input(shape=(users_items_matrix.shape[1],), name='UserScore')\n",
    "    input_content = Input(shape=(content_info.shape[1],), name='Itemcontent')\n",
    "\n",
    "    # Encoder\n",
    "    k = int(len(self.layers)/2)\n",
    "    i = 0\n",
    "    for l in self.layers[:k]:\n",
    "      x = Dense(l, activation=self.activation, \n",
    "                      name='EncLayer{}'.format(i))(x)\n",
    "      i = i+1\n",
    "\n",
    "    # Latent Space\n",
    "    x = Dense(self.layers[k], activation=self.activation, \n",
    "                                name='UserLatentSpace')(x)\n",
    "\n",
    "    # Content Information\n",
    "    x_content = Embedding(100, self.layers[k], \n",
    "                        input_length=content_info.shape[1])(input_content)\n",
    "    x_content = Flatten()(x_content)\n",
    "    x_content = Dense(self.layers[k], activation=self.activation, \n",
    "                                name='ItemLatentSpace')(x_content)\n",
    "    # Concatenate\n",
    "    x = add([x, x_content], name='LatentSpace')\n",
    "\n",
    "    # Dropout\n",
    "    x = Dropout(self.dropout)(x)\n",
    "\n",
    "    # Decoder\n",
    "    for l in self.layers[k+1:]:\n",
    "      i = i-1\n",
    "      x = Dense(l, activation=self.activation, \n",
    "                      name='DecLayer{}'.format(i))(x)\n",
    "\n",
    "    # Output\n",
    "    output_layer = Dense(users_items_matrix.shape[1], activation='linear', name='UserScorePred')(x)\n",
    "\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    model = Model([input_layer, input_content], output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-1.8.0-py3-none-any.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 196 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.4.2.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 135 kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docker>=4.0.0\n",
      "  Downloading docker-4.2.1-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[K     |████████████████████████████████| 143 kB 142 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.13.0.tar.gz (18 kB)\n",
      "Collecting gunicorn; platform_system != \"Windows\"\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 201 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (2.22.0)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: click>=7.0 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (7.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (2.8.1)\n",
      "Collecting gorilla\n",
      "  Downloading gorilla-0.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy<=1.3.13 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.3.13)\n",
      "Collecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4.tar.gz (5.5 kB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.11.0.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 226 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: pyyaml in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (5.3)\n",
      "Requirement already satisfied: Flask in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.1.1)\n",
      "Requirement already satisfied: numpy in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.18.1)\n",
      "Collecting sqlparse\n",
      "  Downloading sqlparse-0.3.1-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 204 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.0.1)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.17.0-cp37-cp37m-macosx_10_14_x86_64.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 150 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (3.11.3)\n",
      "Requirement already satisfied: entrypoints in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: cloudpickle in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.3.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 173 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 206 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: prometheus_client in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow) (0.7.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from gunicorn; platform_system != \"Windows\"->mlflow) (46.0.0.post20200309)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2.8)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (4.0.5)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (1.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (2.11.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from pandas->mlflow) (2019.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from Mako->alembic->mlflow) (1.1.1)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /Users/apple/opt/anaconda3/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (3.0.4)\n",
      "Building wheels for collected packages: alembic, prometheus-flask-exporter, querystring-parser, databricks-cli\n",
      "  Building wheel for alembic (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.2-py2.py3-none-any.whl size=159543 sha256=e5649b8011a3f652056e3637ab4b108113ec856aff3d85c0d9a595513617af87\n",
      "  Stored in directory: /Users/apple/Library/Caches/pip/wheels/4e/b5/00/f93fe1c90b3d501774e91e2e99987f49d16019e40e4bd3afc3\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.13.0-py3-none-any.whl size=14944 sha256=7838d24a6cd2222445e99e52580d53c44fd69be6153d96399d06acdc49fc7729\n",
      "  Stored in directory: /Users/apple/Library/Caches/pip/wheels/2e/ba/02/e222fb4f349a6d1f99c1f5ccaaa7cd0be66e8206a60992400b\n",
      "  Building wheel for querystring-parser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for querystring-parser: filename=querystring_parser-1.2.4-py3-none-any.whl size=7076 sha256=460507d8e0b8681cc309f7910b89b4cb6436f3482ec23e750111c227bc2f1d93\n",
      "  Stored in directory: /Users/apple/Library/Caches/pip/wheels/69/38/7a/072b5863ca334d012821a287fd1d066cea33abdcda3ef2f878\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.11.0-py3-none-any.whl size=90300 sha256=0cc8b2a42e4e547c1f254199eb55164bd6821752c6fa6170876e461e233b61ce\n",
      "  Stored in directory: /Users/apple/Library/Caches/pip/wheels/81/3f/18/5678c9d403583e583a251463196998b17852b98de34aa9ab51\n",
      "Successfully built alembic prometheus-flask-exporter querystring-parser databricks-cli\n",
      "Installing collected packages: Mako, python-editor, alembic, websocket-client, docker, prometheus-flask-exporter, gunicorn, gorilla, querystring-parser, tabulate, databricks-cli, sqlparse, simplejson, mlflow\n",
      "Successfully installed Mako-1.1.3 alembic-1.4.2 databricks-cli-0.11.0 docker-4.2.1 gorilla-0.3.0 gunicorn-20.0.4 mlflow-1.8.0 prometheus-flask-exporter-0.13.0 python-editor-1.0.4 querystring-parser-1.2.4 simplejson-3.17.0 sqlparse-0.3.1 tabulate-0.8.7 websocket-client-0.57.0\n"
     ]
    }
   ],
   "source": [
    "! pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/06/11 17:01:43 ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===\r\n"
     ]
    }
   ],
   "source": [
    "! mlflow run . \\\n",
    "          -P activation=selu \\\n",
    "          -P batch=64 \\\n",
    "          -P dropout=0.8 \\\n",
    "          -P epochs=50 \\\n",
    "          -P layers='[512,256,512]' \\\n",
    "          -P lr=0.0001 \\\n",
    "          -P name=auto_enc \\\n",
    "          -P reg=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
